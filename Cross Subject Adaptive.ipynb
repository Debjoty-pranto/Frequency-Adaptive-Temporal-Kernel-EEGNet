{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6893531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode\n",
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from braindecode.datautil import create_from_mne_epochs\n",
    "from braindecode.preprocessing import exponential_moving_standardize\n",
    "from braindecode.models import EEGNetv4\n",
    "from braindecode import EEGClassifier\n",
    "from skorch.callbacks import LRScheduler\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cde9bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU check\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba3e9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reproducibility\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd5da9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "window_size = 1024   # 2 sec\n",
    "window_stride = 64   # 125 ms\n",
    "low_cut_hz = 8.\n",
    "high_cut_hz = 32.\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "n_epochs = 25\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92eefcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "mne.set_log_level(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd81c831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 10\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\User\\Documents\\GitHub\\Frequency-Adaptive-Temporal-Kernel-EEGNet\\Data\"\n",
    "training_files = glob.glob(data_path + \"/*T.mat\")\n",
    "print(\"Number of training files:\", len(training_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff8aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects loaded: 10\n"
     ]
    }
   ],
   "source": [
    "def get_mne_epochs(filepath, t_start=2, fs=512):\n",
    "    mat_data = loadmat(filepath)\n",
    "    eeg_data = mat_data['RawEEGData'][:, :, fs*t_start:]  # drop first t_start sec\n",
    "    labels = mat_data['Labels'].ravel() - 1  # 0/1 labels\n",
    "\n",
    "    ch_names = ['F3','FC3','C3','CP3','P3','FCz','CPz','F4','FC4','C4','CP4','P4']\n",
    "    info = mne.create_info(ch_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, tmin=-0.5)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None)\n",
    "    epochs.events[:, 2] = labels\n",
    "    return epochs\n",
    "\n",
    "epochs_list_train = [get_mne_epochs(f) for f in training_files]\n",
    "print(\"Number of subjects loaded:\", len(epochs_list_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c26a6fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects (datasets): 10\n",
      "Windows in first subject: 1360\n"
     ]
    }
   ],
   "source": [
    "window_size = 1024  # samples (2 sec)\n",
    "window_stride = 64  # samples (125 ms)\n",
    "\n",
    "windows_datasets_list = []\n",
    "\n",
    "for epochs in epochs_list_train:\n",
    "    cropped_epoch = epochs.crop(tmin=0.5, tmax=4.5, include_tmax=False)\n",
    "    windows_dataset = create_from_mne_epochs(\n",
    "        [cropped_epoch],\n",
    "        window_size_samples=window_size,\n",
    "        window_stride_samples=window_stride,\n",
    "        drop_last_window=False\n",
    "    )\n",
    "    windows_datasets_list.append(windows_dataset)\n",
    "\n",
    "print(\"Subjects (datasets):\", len(windows_datasets_list))\n",
    "print(\"Windows in first subject:\", len(windows_datasets_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb04f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 12 Window size: 1024\n"
     ]
    }
   ],
   "source": [
    "# Get the first dataset for the first subject\n",
    "first_dataset = windows_datasets_list[0]\n",
    "\n",
    "# Get the actual EEG data from the first window\n",
    "first_window = first_dataset.datasets[0].windows  # this is MNE Epochs object\n",
    "first_window_data = first_window.get_data()        # NumPy array: (trials, channels, samples)\n",
    "\n",
    "# Number of channels and window size\n",
    "n_chans = first_window_data.shape[1]\n",
    "window_size = first_window_data.shape[2]\n",
    "\n",
    "print(\"Channels:\", n_chans, \"Window size:\", window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb81e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cut_hz = 8.\n",
    "high_cut_hz = 32.\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs):\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        data[i] = exponential_moving_standardize(data[i],\n",
    "                                                 factor_new=factor_new,\n",
    "                                                 init_block_size=init_block_size)\n",
    "    epochs._data = data\n",
    "    return epochs\n",
    "\n",
    "for windows_dataset in windows_datasets_list:\n",
    "    epochs = windows_dataset.datasets[0].windows\n",
    "    epochs.load_data()   # âœ… forces preload\n",
    "    epochs.pick_types(eeg=True)\n",
    "    epochs.filter(l_freq=8., h_freq=32.)\n",
    "    custom_exp_moving_std_fn(epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99cdab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Frequency_Adaptive_model import AdaptiveEEGNet \n",
    "# Deterministic training setup \n",
    "torch.backends.cudnn.deterministic = True \n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Model hyperparameters\n",
    "\n",
    "n_classes = 2\n",
    "n_chans = windows_datasets_list[0][0][0].shape[0]      # EEG channels\n",
    "input_window_samples = windows_datasets_list[0][0][0].shape[1]  # time samples\n",
    "\n",
    "# Instantiate AdaptiveEEGNet\n",
    "model = AdaptiveEEGNet(\n",
    "    nb_classes=n_classes,\n",
    "    Chans=n_chans,\n",
    "    Samples=input_window_samples,\n",
    "    kernLength=128,\n",
    "    F1=16,\n",
    "    D=2,\n",
    "    F2=32,\n",
    "    dropoutRate=0.3,\n",
    "    sample_rate=512\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54974e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from braindecode import EEGClassifier\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from copy import deepcopy\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def training_cross_subject_adaptive_val (windows_datasets_list, base_model,\n",
    "                                                   n_epochs=25, batch_size=32, val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Cross-subject AdaptiveEEGNet training (no reinit per epoch).\n",
    "    Tracks best validation kappa for each subject, prints clean summary table.\n",
    "    \"\"\"\n",
    "    n_subjects = len(windows_datasets_list)\n",
    "    all_val_acc, all_val_kappa = [], []\n",
    "\n",
    "    print(f\"\\n{'='*20} CROSS-SUBJECT VALIDATION {'='*20}\\n\")\n",
    "\n",
    "    for test_idx in range(n_subjects):\n",
    "        print(f\"\\nðŸ§© Subject {test_idx+1}/{n_subjects}\")\n",
    "\n",
    "        # ----- Prepare data -----\n",
    "        train_datasets = [windows_datasets_list[i] for i in range(n_subjects) if i != test_idx]\n",
    "        X_train, y_train = [], []\n",
    "        for ds in train_datasets:\n",
    "            for d in ds.datasets:\n",
    "                X_train.append(d.windows)\n",
    "                y_train.append(d.y)\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "        # Split into train/validation\n",
    "        X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=val_ratio, stratify=y_train, random_state=42\n",
    "        )\n",
    "\n",
    "        train_tensor = TensorDataset(torch.tensor(X_tr, dtype=torch.float32),\n",
    "                                     torch.tensor(y_tr, dtype=torch.long))\n",
    "        val_tensor = TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                                   torch.tensor(y_val, dtype=torch.long))\n",
    "\n",
    "        # Fresh model copy\n",
    "        model = deepcopy(base_model)\n",
    "\n",
    "        # EEG classifier setup\n",
    "        clf = EEGClassifier(\n",
    "            model,\n",
    "            criterion=torch.nn.CrossEntropyLoss,\n",
    "            optimizer=torch.optim.AdamW,\n",
    "            optimizer__lr=0.02,\n",
    "            optimizer__weight_decay=0.0005,\n",
    "            batch_size=batch_size,\n",
    "            train_split=predefined_split(val_tensor),\n",
    "            callbacks=[(\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=n_epochs-1))],\n",
    "            device=device,\n",
    "            iterator_train__shuffle=True\n",
    "        )\n",
    "\n",
    "        # ---- Train all epochs ----\n",
    "        clf.fit(train_tensor, y=None, epochs=n_epochs)\n",
    "\n",
    "        # ---- Evaluate on validation ----\n",
    "        val_loader = DataLoader(val_tensor, batch_size=batch_size, shuffle=False)\n",
    "        clf.module_.eval()\n",
    "        val_preds, val_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                out = clf.module_(Xb.to(device))\n",
    "                val_preds.extend(out.argmax(1).cpu().numpy())\n",
    "                val_true.extend(yb.numpy())\n",
    "\n",
    "        val_acc = accuracy_score(val_true, val_preds)\n",
    "        val_kappa = cohen_kappa_score(val_true, val_preds)\n",
    "\n",
    "        all_val_acc.append(val_acc)\n",
    "        all_val_kappa.append(val_kappa)\n",
    "\n",
    "        print(f\"âœ… Val Accuracy: {val_acc:.3f} | Val Îºappa: {val_kappa:.3f}\")\n",
    "\n",
    "    # ---- Final Summary ----\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"CROSS-SUBJECT VALIDATION SUMMARY\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    print(f\"Mean Val Accuracy : {np.mean(all_val_acc):.3f} Â± {np.std(all_val_acc):.3f}\")\n",
    "    print(f\"Mean Val Kappa    : {np.mean(all_val_kappa):.3f} Â± {np.std(all_val_kappa):.3f}\")\n",
    "    print(f\"{'='*60}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71d5d5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== CROSS-SUBJECT VALIDATION ====================\n",
      "\n",
      "\n",
      "ðŸ§© Subject 1/10\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.8327\u001b[0m       \u001b[32m0.4996\u001b[0m        \u001b[35m0.7208\u001b[0m  0.0200  26.4959\n",
      "      2        \u001b[36m0.7061\u001b[0m       0.4951        \u001b[35m0.6905\u001b[0m  0.0199  21.0705\n",
      "      3        \u001b[36m0.7033\u001b[0m       0.4959        0.7043  0.0197  21.0665\n",
      "      4        0.7043       \u001b[32m0.5217\u001b[0m        0.6983  0.0192  21.1727\n",
      "      5        0.7076       0.5004        0.7430  0.0187  21.1126\n",
      "      6        0.7046       0.5074        0.6976  0.0179  21.0469\n",
      "      7        \u001b[36m0.7026\u001b[0m       0.5139        0.6944  0.0171  21.2490\n",
      "      8        \u001b[36m0.7025\u001b[0m       0.5012        0.7019  0.0161  21.1715\n",
      "      9        0.7102       0.5098        0.7002  0.0150  21.0844\n",
      "     10        \u001b[36m0.7004\u001b[0m       0.5053        \u001b[35m0.6903\u001b[0m  0.0138  21.1815\n",
      "     11        \u001b[36m0.6953\u001b[0m       \u001b[32m0.5433\u001b[0m        \u001b[35m0.6809\u001b[0m  0.0126  21.2062\n",
      "     12        \u001b[36m0.6889\u001b[0m       0.5167        0.7081  0.0113  21.1315\n",
      "     13        \u001b[36m0.6751\u001b[0m       \u001b[32m0.6050\u001b[0m        \u001b[35m0.6535\u001b[0m  0.0100  21.1418\n",
      "     14        \u001b[36m0.6325\u001b[0m       \u001b[32m0.6283\u001b[0m        0.6569  0.0087  21.1992\n",
      "     15        \u001b[36m0.5995\u001b[0m       \u001b[32m0.7026\u001b[0m        \u001b[35m0.5903\u001b[0m  0.0074  21.1157\n",
      "     16        \u001b[36m0.5874\u001b[0m       \u001b[32m0.7112\u001b[0m        \u001b[35m0.5716\u001b[0m  0.0062  21.0991\n",
      "     17        \u001b[36m0.5654\u001b[0m       \u001b[32m0.7361\u001b[0m        \u001b[35m0.5412\u001b[0m  0.0050  21.4734\n",
      "     18        \u001b[36m0.5510\u001b[0m       \u001b[32m0.7586\u001b[0m        \u001b[35m0.5177\u001b[0m  0.0039  21.4009\n",
      "     19        \u001b[36m0.5277\u001b[0m       \u001b[32m0.7749\u001b[0m        \u001b[35m0.5009\u001b[0m  0.0029  21.1421\n",
      "     20        \u001b[36m0.4962\u001b[0m       0.7749        \u001b[35m0.4795\u001b[0m  0.0021  21.2173\n",
      "     21        \u001b[36m0.4834\u001b[0m       \u001b[32m0.7790\u001b[0m        \u001b[35m0.4736\u001b[0m  0.0013  21.1192\n",
      "     22        \u001b[36m0.4743\u001b[0m       0.7627        0.4832  0.0008  21.1012\n",
      "     23        \u001b[36m0.4699\u001b[0m       \u001b[32m0.7900\u001b[0m        \u001b[35m0.4572\u001b[0m  0.0003  21.1446\n",
      "     24        \u001b[36m0.4661\u001b[0m       0.7896        \u001b[35m0.4530\u001b[0m  0.0001  21.1606\n",
      "     25        \u001b[36m0.4581\u001b[0m       0.7896        0.4557  0.0000  21.1730\n",
      "âœ… Val Accuracy: 0.790 | Val Îºappa: 0.579\n",
      "\n",
      "ðŸ§© Subject 2/10\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.7834\u001b[0m       \u001b[32m0.5372\u001b[0m        \u001b[35m0.7069\u001b[0m  0.0200  21.2211\n",
      "      2        \u001b[36m0.7095\u001b[0m       0.5025        \u001b[35m0.7045\u001b[0m  0.0199  21.1839\n",
      "      3        \u001b[36m0.7060\u001b[0m       0.4992        0.7183  0.0197  21.1469\n",
      "      4        0.7062       0.5082        \u001b[35m0.6934\u001b[0m  0.0192  21.1489\n",
      "      5        0.7061       0.5090        0.6993  0.0187  21.1500\n",
      "      6        0.7096       0.5025        0.6951  0.0179  21.0985\n",
      "      7        0.7106       0.4988        0.6998  0.0171  21.2819\n",
      "      8        0.7063       0.5000        0.7242  0.0161  21.3914\n",
      "      9        0.7116       0.4955        0.6991  0.0150  21.3497\n",
      "     10        \u001b[36m0.7051\u001b[0m       0.4902        0.6941  0.0138  21.2328\n",
      "     11        0.7052       0.5078        \u001b[35m0.6920\u001b[0m  0.0126  21.1234\n",
      "     12        \u001b[36m0.7011\u001b[0m       0.5302        \u001b[35m0.6901\u001b[0m  0.0113  21.0610\n",
      "     13        \u001b[36m0.6957\u001b[0m       0.5351        0.6941  0.0100  21.2319\n",
      "     14        \u001b[36m0.6908\u001b[0m       0.5098        0.7151  0.0087  21.1923\n",
      "     15        \u001b[36m0.6821\u001b[0m       \u001b[32m0.5792\u001b[0m        \u001b[35m0.6828\u001b[0m  0.0074  21.0478\n",
      "     16        \u001b[36m0.6730\u001b[0m       0.5302        0.7562  0.0062  21.1470\n",
      "     17        \u001b[36m0.6499\u001b[0m       0.5082        1.2057  0.0050  21.4871\n",
      "     18        \u001b[36m0.6231\u001b[0m       \u001b[32m0.6687\u001b[0m        \u001b[35m0.6218\u001b[0m  0.0039  21.3660\n",
      "     19        \u001b[36m0.6062\u001b[0m       0.5641        0.7038  0.0029  21.4958\n",
      "     20        \u001b[36m0.5836\u001b[0m       0.5870        0.7203  0.0021  21.2365\n",
      "     21        \u001b[36m0.5567\u001b[0m       \u001b[32m0.6732\u001b[0m        \u001b[35m0.5831\u001b[0m  0.0013  21.3374\n",
      "     22        \u001b[36m0.5354\u001b[0m       \u001b[32m0.7402\u001b[0m        \u001b[35m0.5398\u001b[0m  0.0008  21.3233\n",
      "     23        \u001b[36m0.5314\u001b[0m       0.7010        0.5694  0.0003  21.1979\n",
      "     24        \u001b[36m0.5273\u001b[0m       \u001b[32m0.7529\u001b[0m        \u001b[35m0.5264\u001b[0m  0.0001  21.0713\n",
      "     25        \u001b[36m0.5222\u001b[0m       0.7373        0.5395  0.0000  21.0485\n",
      "âœ… Val Accuracy: 0.737 | Val Îºappa: 0.475\n",
      "\n",
      "ðŸ§© Subject 3/10\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.7670\u001b[0m       \u001b[32m0.5004\u001b[0m        \u001b[35m0.6986\u001b[0m  0.0200  21.2439\n",
      "      2        \u001b[36m0.7104\u001b[0m       0.5000        0.7459  0.0199  21.1473\n",
      "      3        \u001b[36m0.7091\u001b[0m       \u001b[32m0.5237\u001b[0m        \u001b[35m0.6941\u001b[0m  0.0197  21.1594\n",
      "      4        \u001b[36m0.7079\u001b[0m       0.5004        0.6960  0.0192  21.1836\n",
      "      5        0.7119       0.5123        0.6994  0.0187  21.0929\n",
      "      6        0.7117       0.4963        0.7020  0.0179  21.0726\n",
      "      7        0.7087       0.5139        \u001b[35m0.6913\u001b[0m  0.0171  21.1974\n",
      "      8        \u001b[36m0.7042\u001b[0m       0.5012        0.7386  0.0161  21.1271\n",
      "      9        \u001b[36m0.7033\u001b[0m       \u001b[32m0.5719\u001b[0m        \u001b[35m0.6721\u001b[0m  0.0150  21.1289\n",
      "     10        \u001b[36m0.6903\u001b[0m       0.5016        1.0057  0.0138  21.9294\n",
      "     11        \u001b[36m0.6302\u001b[0m       \u001b[32m0.6924\u001b[0m        \u001b[35m0.5787\u001b[0m  0.0126  21.4660\n",
      "     12        \u001b[36m0.5892\u001b[0m       0.5180        1.5289  0.0113  21.1048\n",
      "     13        \u001b[36m0.5697\u001b[0m       \u001b[32m0.7002\u001b[0m        \u001b[35m0.5783\u001b[0m  0.0100  21.2409\n",
      "     14        \u001b[36m0.5607\u001b[0m       0.6993        0.5904  0.0087  21.2413\n",
      "     15        \u001b[36m0.5478\u001b[0m       \u001b[32m0.7688\u001b[0m        \u001b[35m0.5066\u001b[0m  0.0074  21.1505\n",
      "     16        \u001b[36m0.5266\u001b[0m       0.7553        0.5103  0.0062  21.1498\n",
      "     17        \u001b[36m0.5138\u001b[0m       0.6912        0.5930  0.0050  21.1731\n",
      "     18        \u001b[36m0.4928\u001b[0m       0.6879        0.6209  0.0039  21.2005\n",
      "     19        \u001b[36m0.4745\u001b[0m       0.6426        0.7003  0.0029  21.1347\n",
      "     20        \u001b[36m0.4623\u001b[0m       \u001b[32m0.8051\u001b[0m        \u001b[35m0.4439\u001b[0m  0.0021  21.2057\n",
      "     21        \u001b[36m0.4470\u001b[0m       \u001b[32m0.8321\u001b[0m        \u001b[35m0.4178\u001b[0m  0.0013  21.1608\n",
      "     22        \u001b[36m0.4403\u001b[0m       0.8231        \u001b[35m0.4151\u001b[0m  0.0008  21.0894\n",
      "     23        0.4430       \u001b[32m0.8350\u001b[0m        \u001b[35m0.4123\u001b[0m  0.0003  21.1742\n",
      "     24        0.4433       0.8292        \u001b[35m0.4100\u001b[0m  0.0001  21.1286\n",
      "     25        \u001b[36m0.4325\u001b[0m       0.8252        0.4110  0.0000  21.1259\n",
      "âœ… Val Accuracy: 0.825 | Val Îºappa: 0.650\n",
      "\n",
      "ðŸ§© Subject 4/10\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.8063\u001b[0m       \u001b[32m0.5004\u001b[0m        \u001b[35m0.7336\u001b[0m  0.0200  21.2972\n",
      "      2        \u001b[36m0.7096\u001b[0m       0.4882        \u001b[35m0.6973\u001b[0m  0.0199  21.1498\n",
      "      3        \u001b[36m0.7040\u001b[0m       0.5000        0.7155  0.0197  19.5451\n",
      "      4        \u001b[36m0.7009\u001b[0m       \u001b[32m0.5294\u001b[0m        0.7036  0.0192  18.0899\n",
      "      5        0.7073       0.5008        0.8033  0.0187  17.8606\n",
      "      6        0.7065       \u001b[32m0.5568\u001b[0m        \u001b[35m0.6946\u001b[0m  0.0179  17.8703\n",
      "      7        \u001b[36m0.6996\u001b[0m       0.5074        0.7654  0.0171  17.8405\n",
      "      8        \u001b[36m0.6734\u001b[0m       \u001b[32m0.6213\u001b[0m        \u001b[35m0.6481\u001b[0m  0.0161  17.9411\n",
      "      9        \u001b[36m0.6453\u001b[0m       \u001b[32m0.6332\u001b[0m        0.6488  0.0150  17.8572\n",
      "     10        \u001b[36m0.6116\u001b[0m       \u001b[32m0.6483\u001b[0m        \u001b[35m0.6364\u001b[0m  0.0138  17.9069\n",
      "     11        \u001b[36m0.5888\u001b[0m       0.5290        1.1117  0.0126  17.8257\n",
      "     12        \u001b[36m0.5622\u001b[0m       \u001b[32m0.7533\u001b[0m        \u001b[35m0.5259\u001b[0m  0.0113  17.7868\n",
      "     13        \u001b[36m0.5396\u001b[0m       0.5846        0.8870  0.0100  17.7676\n",
      "     14        \u001b[36m0.5234\u001b[0m       0.7308        0.5521  0.0087  17.9909\n",
      "     15        \u001b[36m0.4787\u001b[0m       \u001b[32m0.8056\u001b[0m        \u001b[35m0.4516\u001b[0m  0.0074  17.4296\n",
      "     16        \u001b[36m0.4707\u001b[0m       0.7594        0.5002  0.0062  17.4024\n",
      "     17        \u001b[36m0.4597\u001b[0m       \u001b[32m0.8084\u001b[0m        \u001b[35m0.4477\u001b[0m  0.0050  17.9863\n",
      "     18        \u001b[36m0.4539\u001b[0m       0.7128        0.5801  0.0039  17.7594\n",
      "     19        \u001b[36m0.4451\u001b[0m       0.7921        0.4668  0.0029  18.0493\n",
      "     20        \u001b[36m0.4312\u001b[0m       \u001b[32m0.8256\u001b[0m        \u001b[35m0.4187\u001b[0m  0.0021  18.0337\n",
      "     21        \u001b[36m0.4270\u001b[0m       0.8256        \u001b[35m0.4031\u001b[0m  0.0013  18.0565\n",
      "     22        \u001b[36m0.4139\u001b[0m       0.8239        0.4180  0.0008  18.0976\n",
      "     23        0.4149       \u001b[32m0.8317\u001b[0m        0.4112  0.0003  17.5716\n",
      "     24        \u001b[36m0.4132\u001b[0m       \u001b[32m0.8346\u001b[0m        \u001b[35m0.4003\u001b[0m  0.0001  17.4762\n",
      "     25        0.4158       \u001b[32m0.8370\u001b[0m        \u001b[35m0.3878\u001b[0m  0.0000  17.7214\n",
      "âœ… Val Accuracy: 0.837 | Val Îºappa: 0.674\n",
      "\n",
      "ðŸ§© Subject 5/10\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.7772\u001b[0m       \u001b[32m0.5045\u001b[0m        \u001b[35m0.7063\u001b[0m  0.0200  30.7546\n",
      "      2        \u001b[36m0.7102\u001b[0m       0.5041        0.7295  0.0199  38.6431\n",
      "      3        \u001b[36m0.7066\u001b[0m       \u001b[32m0.5069\u001b[0m        \u001b[35m0.6918\u001b[0m  0.0197  40.1347\n",
      "      4        0.7087       0.5033        0.7838  0.0192  40.2302\n",
      "      5        0.7132       0.5012        0.6936  0.0187  41.3632\n",
      "      6        0.7078       0.4996        0.6979  0.0179  41.9297\n",
      "      7        0.7090       \u001b[32m0.5110\u001b[0m        0.7465  0.0171  40.7058\n",
      "      8        0.7074       \u001b[32m0.5319\u001b[0m        0.6948  0.0161  39.4035\n",
      "      9        0.7109       0.5004        0.7127  0.0150  19.0941\n",
      "     10        \u001b[36m0.7037\u001b[0m       0.5020        0.7159  0.0138  18.4737\n",
      "     11        \u001b[36m0.7003\u001b[0m       0.5012        0.7771  0.0126  18.4146\n",
      "     12        \u001b[36m0.6961\u001b[0m       \u001b[32m0.5568\u001b[0m        \u001b[35m0.6911\u001b[0m  0.0113  18.5290\n",
      "     13        \u001b[36m0.6908\u001b[0m       0.5400        \u001b[35m0.6854\u001b[0m  0.0100  19.7634\n",
      "     14        \u001b[36m0.6825\u001b[0m       0.5249        0.6952  0.0087  20.9677\n",
      "     15        \u001b[36m0.6460\u001b[0m       0.5527        0.7072  0.0074  21.3469\n",
      "     16        \u001b[36m0.5860\u001b[0m       \u001b[32m0.7124\u001b[0m        \u001b[35m0.5584\u001b[0m  0.0062  21.0996\n",
      "     17        \u001b[36m0.5513\u001b[0m       \u001b[32m0.7431\u001b[0m        \u001b[35m0.5516\u001b[0m  0.0050  20.3721\n",
      "     18        \u001b[36m0.5329\u001b[0m       \u001b[32m0.7525\u001b[0m        \u001b[35m0.5272\u001b[0m  0.0039  18.5644\n",
      "     19        \u001b[36m0.5175\u001b[0m       \u001b[32m0.7651\u001b[0m        \u001b[35m0.5154\u001b[0m  0.0029  18.5949\n",
      "     20        \u001b[36m0.5060\u001b[0m       0.7618        \u001b[35m0.5106\u001b[0m  0.0021  21.0168\n",
      "     21        \u001b[36m0.4947\u001b[0m       0.7525        0.5388  0.0013  20.9611\n",
      "     22        \u001b[36m0.4883\u001b[0m       \u001b[32m0.7770\u001b[0m        \u001b[35m0.4894\u001b[0m  0.0008  20.8787\n",
      "     23        \u001b[36m0.4857\u001b[0m       0.7733        \u001b[35m0.4794\u001b[0m  0.0003  21.1733\n",
      "     24        0.4881       \u001b[32m0.7827\u001b[0m        \u001b[35m0.4732\u001b[0m  0.0001  21.1021\n",
      "     25        \u001b[36m0.4815\u001b[0m       \u001b[32m0.7851\u001b[0m        \u001b[35m0.4682\u001b[0m  0.0000  19.3309\n",
      "âœ… Val Accuracy: 0.785 | Val Îºappa: 0.570\n",
      "\n",
      "ðŸ§© Subject 6/10\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.8729\u001b[0m       \u001b[32m0.5323\u001b[0m        \u001b[35m0.6966\u001b[0m  0.0200  18.7472\n",
      "      2        \u001b[36m0.7070\u001b[0m       0.5188        0.7088  0.0199  18.7285\n",
      "      3        \u001b[36m0.7002\u001b[0m       0.5286        0.7081  0.0197  18.7750\n",
      "      4        0.7008       0.5237        0.7054  0.0192  18.6829\n",
      "      5        \u001b[36m0.6995\u001b[0m       0.5000        0.7135  0.0187  18.4693\n",
      "      6        0.7026       \u001b[32m0.5470\u001b[0m        \u001b[35m0.6870\u001b[0m  0.0179  18.7993\n",
      "      7        \u001b[36m0.6969\u001b[0m       0.4988        0.7293  0.0171  18.5392\n",
      "      8        0.6991       0.5012        0.7159  0.0161  18.0935\n",
      "      9        \u001b[36m0.6955\u001b[0m       0.5012        0.7290  0.0150  17.7568\n",
      "     10        \u001b[36m0.6917\u001b[0m       0.5163        0.7032  0.0138  17.8332\n",
      "     11        \u001b[36m0.6886\u001b[0m       0.5331        0.6951  0.0126  17.8641\n",
      "     12        \u001b[36m0.6660\u001b[0m       \u001b[32m0.5645\u001b[0m        \u001b[35m0.6613\u001b[0m  0.0113  17.8148\n",
      "     13        \u001b[36m0.6379\u001b[0m       \u001b[32m0.6556\u001b[0m        \u001b[35m0.6524\u001b[0m  0.0100  17.8508\n",
      "     14        \u001b[36m0.5975\u001b[0m       0.5809        0.7804  0.0087  18.4184\n",
      "     15        \u001b[36m0.5727\u001b[0m       0.5686        0.6806  0.0074  18.5259\n",
      "     16        \u001b[36m0.5609\u001b[0m       0.5225        0.9912  0.0062  18.8621\n",
      "     17        \u001b[36m0.5494\u001b[0m       0.6303        0.6558  0.0050  18.7459\n",
      "     18        \u001b[36m0.5373\u001b[0m       \u001b[32m0.7328\u001b[0m        \u001b[35m0.5390\u001b[0m  0.0039  18.3881\n",
      "     19        \u001b[36m0.5294\u001b[0m       \u001b[32m0.7406\u001b[0m        \u001b[35m0.5321\u001b[0m  0.0029  22.1401\n",
      "     20        \u001b[36m0.5213\u001b[0m       0.7202        0.5562  0.0021  22.1404\n",
      "     21        \u001b[36m0.5139\u001b[0m       \u001b[32m0.7676\u001b[0m        \u001b[35m0.5102\u001b[0m  0.0013  32.0022\n",
      "     22        \u001b[36m0.5103\u001b[0m       0.7349        0.5336  0.0008  32.1408\n",
      "     23        \u001b[36m0.5073\u001b[0m       0.7606        0.5164  0.0003  21.1783\n",
      "     24        \u001b[36m0.5016\u001b[0m       0.7565        0.5188  0.0001  21.0176\n",
      "     25        \u001b[36m0.4978\u001b[0m       \u001b[32m0.7717\u001b[0m        \u001b[35m0.5092\u001b[0m  0.0000  21.0621\n",
      "âœ… Val Accuracy: 0.772 | Val Îºappa: 0.543\n",
      "\n",
      "ðŸ§© Subject 7/10\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.7940\u001b[0m       \u001b[32m0.4971\u001b[0m        \u001b[35m0.7386\u001b[0m  0.0200  24.4497\n",
      "      2        \u001b[36m0.7079\u001b[0m       \u001b[32m0.5004\u001b[0m        \u001b[35m0.7098\u001b[0m  0.0199  23.4223\n",
      "      3        \u001b[36m0.7061\u001b[0m       0.5000        0.7891  0.0197  22.7672\n",
      "      4        0.7064       \u001b[32m0.5106\u001b[0m        \u001b[35m0.7009\u001b[0m  0.0192  22.4465\n",
      "      5        \u001b[36m0.7051\u001b[0m       \u001b[32m0.5237\u001b[0m        \u001b[35m0.6948\u001b[0m  0.0187  22.3048\n",
      "      6        0.7078       0.5000        0.7686  0.0179  22.7058\n",
      "      7        \u001b[36m0.7013\u001b[0m       \u001b[32m0.5535\u001b[0m        \u001b[35m0.6887\u001b[0m  0.0171  22.7505\n",
      "      8        0.7081       0.5008        0.8208  0.0161  22.6073\n",
      "      9        \u001b[36m0.6898\u001b[0m       \u001b[32m0.5903\u001b[0m        0.7281  0.0150  22.7520\n",
      "     10        \u001b[36m0.6458\u001b[0m       \u001b[32m0.6123\u001b[0m        \u001b[35m0.6826\u001b[0m  0.0138  22.0636\n",
      "     11        \u001b[36m0.6055\u001b[0m       \u001b[32m0.6299\u001b[0m        0.7017  0.0126  21.8375\n",
      "     12        \u001b[36m0.5676\u001b[0m       \u001b[32m0.7443\u001b[0m        \u001b[35m0.5612\u001b[0m  0.0113  21.3372\n",
      "     13        \u001b[36m0.5424\u001b[0m       \u001b[32m0.7602\u001b[0m        \u001b[35m0.5336\u001b[0m  0.0100  21.3734\n",
      "     14        \u001b[36m0.5142\u001b[0m       \u001b[32m0.7933\u001b[0m        \u001b[35m0.5037\u001b[0m  0.0087  21.4466\n",
      "     15        \u001b[36m0.4876\u001b[0m       0.7896        \u001b[35m0.4706\u001b[0m  0.0074  21.5750\n",
      "     16        \u001b[36m0.4745\u001b[0m       0.6904        0.5716  0.0062  23.4878\n",
      "     17        \u001b[36m0.4536\u001b[0m       \u001b[32m0.8019\u001b[0m        \u001b[35m0.4432\u001b[0m  0.0050  22.9664\n",
      "     18        \u001b[36m0.4448\u001b[0m       \u001b[32m0.8056\u001b[0m        0.4445  0.0039  22.3762\n",
      "     19        \u001b[36m0.4362\u001b[0m       0.7868        0.4785  0.0029  22.1650\n",
      "     20        \u001b[36m0.4288\u001b[0m       \u001b[32m0.8117\u001b[0m        \u001b[35m0.4302\u001b[0m  0.0021  22.2395\n",
      "     21        \u001b[36m0.4209\u001b[0m       \u001b[32m0.8141\u001b[0m        \u001b[35m0.4215\u001b[0m  0.0013  22.4638\n",
      "     22        0.4231       \u001b[32m0.8170\u001b[0m        \u001b[35m0.4176\u001b[0m  0.0008  23.6208\n",
      "     23        \u001b[36m0.4204\u001b[0m       0.8158        0.4296  0.0003  21.3186\n",
      "     24        \u001b[36m0.4189\u001b[0m       0.8092        0.4446  0.0001  18.7180\n",
      "     25        \u001b[36m0.4165\u001b[0m       \u001b[32m0.8174\u001b[0m        0.4227  0.0000  18.0647\n",
      "âœ… Val Accuracy: 0.817 | Val Îºappa: 0.635\n",
      "\n",
      "ðŸ§© Subject 8/10\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.8555\u001b[0m       \u001b[32m0.5033\u001b[0m        \u001b[35m0.7608\u001b[0m  0.0200  18.4062\n",
      "      2        \u001b[36m0.7069\u001b[0m       0.5016        \u001b[35m0.7348\u001b[0m  0.0199  18.0349\n",
      "      3        \u001b[36m0.7068\u001b[0m       \u001b[32m0.5127\u001b[0m        \u001b[35m0.6893\u001b[0m  0.0197  18.0915\n",
      "      4        \u001b[36m0.7013\u001b[0m       0.5029        0.7323  0.0192  18.0741\n",
      "      5        0.7033       0.5069        0.7091  0.0187  18.0554\n",
      "      6        0.7035       0.5037        0.6940  0.0179  18.0982\n",
      "      7        \u001b[36m0.6988\u001b[0m       \u001b[32m0.5699\u001b[0m        0.6914  0.0171  18.0374\n",
      "      8        \u001b[36m0.6987\u001b[0m       0.5380        \u001b[35m0.6856\u001b[0m  0.0161  18.1360\n",
      "      9        \u001b[36m0.6952\u001b[0m       \u001b[32m0.5866\u001b[0m        \u001b[35m0.6762\u001b[0m  0.0150  18.0419\n",
      "     10        \u001b[36m0.6883\u001b[0m       0.5817        0.6764  0.0138  18.1168\n",
      "     11        \u001b[36m0.6544\u001b[0m       \u001b[32m0.6569\u001b[0m        \u001b[35m0.6510\u001b[0m  0.0126  18.0975\n",
      "     12        \u001b[36m0.5900\u001b[0m       0.5233        0.8760  0.0113  19.9708\n",
      "     13        \u001b[36m0.5329\u001b[0m       0.6225        0.7835  0.0100  21.3572\n",
      "     14        \u001b[36m0.4953\u001b[0m       \u001b[32m0.6765\u001b[0m        \u001b[35m0.5860\u001b[0m  0.0087  20.6395\n",
      "     15        \u001b[36m0.4700\u001b[0m       \u001b[32m0.7757\u001b[0m        \u001b[35m0.4704\u001b[0m  0.0074  17.7722\n",
      "     16        \u001b[36m0.4572\u001b[0m       0.6605        0.6123  0.0062  17.5287\n",
      "     17        \u001b[36m0.4421\u001b[0m       \u001b[32m0.8117\u001b[0m        \u001b[35m0.4381\u001b[0m  0.0050  17.9744\n",
      "     18        0.4437       0.6499        0.6288  0.0039  18.0109\n",
      "     19        \u001b[36m0.4257\u001b[0m       0.7823        0.4859  0.0029  18.0246\n",
      "     20        \u001b[36m0.4124\u001b[0m       0.7810        0.4791  0.0021  18.0371\n",
      "     21        \u001b[36m0.4105\u001b[0m       \u001b[32m0.8243\u001b[0m        \u001b[35m0.4151\u001b[0m  0.0013  18.1066\n",
      "     22        \u001b[36m0.3987\u001b[0m       0.7704        0.4910  0.0008  18.1176\n",
      "     23        0.4003       \u001b[32m0.8264\u001b[0m        0.4154  0.0003  18.0437\n",
      "     24        \u001b[36m0.3958\u001b[0m       0.8064        0.4335  0.0001  18.0734\n",
      "     25        0.3980       0.8243        0.4178  0.0000  18.0473\n",
      "âœ… Val Accuracy: 0.824 | Val Îºappa: 0.649\n",
      "\n",
      "ðŸ§© Subject 9/10\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ------------  ------  -------\n",
      "      1        \u001b[36m1.0141\u001b[0m       \u001b[32m0.5568\u001b[0m        \u001b[35m0.7023\u001b[0m  0.0200  18.1334\n",
      "      2        \u001b[36m0.7015\u001b[0m       0.5037        0.7077  0.0199  18.0265\n",
      "      3        \u001b[36m0.6985\u001b[0m       0.5000        0.7093  0.0197  18.6049\n",
      "      4        0.6988       0.5417        \u001b[35m0.6887\u001b[0m  0.0192  21.1950\n",
      "      5        \u001b[36m0.6920\u001b[0m       \u001b[32m0.5621\u001b[0m        0.6900  0.0187  21.1794\n",
      "      6        0.6951       0.5061        0.7175  0.0179  21.3502\n",
      "      7        \u001b[36m0.6684\u001b[0m       \u001b[32m0.6246\u001b[0m        \u001b[35m0.6462\u001b[0m  0.0171  21.1425\n",
      "      8        \u001b[36m0.6355\u001b[0m       0.5016        4.5743  0.0161  21.2682\n",
      "      9        \u001b[36m0.6063\u001b[0m       0.5539        0.6697  0.0150  21.2077\n",
      "     10        \u001b[36m0.5716\u001b[0m       \u001b[32m0.7165\u001b[0m        \u001b[35m0.5569\u001b[0m  0.0138  21.1768\n",
      "     11        \u001b[36m0.5564\u001b[0m       0.6164        0.6847  0.0126  21.2294\n",
      "     12        \u001b[36m0.5228\u001b[0m       0.6863        0.6086  0.0113  21.2752\n",
      "     13        \u001b[36m0.5029\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5380\u001b[0m  0.0100  21.1702\n",
      "     14        \u001b[36m0.4656\u001b[0m       \u001b[32m0.7688\u001b[0m        \u001b[35m0.4707\u001b[0m  0.0087  21.2215\n",
      "     15        \u001b[36m0.4443\u001b[0m       \u001b[32m0.8170\u001b[0m        \u001b[35m0.4156\u001b[0m  0.0074  21.2605\n",
      "     16        \u001b[36m0.4241\u001b[0m       0.7120        0.6542  0.0062  20.9524\n",
      "     17        \u001b[36m0.4166\u001b[0m       0.7631        0.4656  0.0050  18.1328\n",
      "     18        \u001b[36m0.4018\u001b[0m       0.7819        0.4414  0.0039  18.0297\n",
      "     19        \u001b[36m0.3977\u001b[0m       0.7798        0.4863  0.0029  18.0741\n",
      "     20        \u001b[36m0.3943\u001b[0m       \u001b[32m0.8194\u001b[0m        \u001b[35m0.3848\u001b[0m  0.0021  18.0805\n",
      "     21        \u001b[36m0.3903\u001b[0m       \u001b[32m0.8301\u001b[0m        \u001b[35m0.3798\u001b[0m  0.0013  18.0457\n",
      "     22        \u001b[36m0.3793\u001b[0m       0.8297        \u001b[35m0.3678\u001b[0m  0.0008  18.0468\n",
      "     23        \u001b[36m0.3783\u001b[0m       0.8284        \u001b[35m0.3674\u001b[0m  0.0003  18.2380\n",
      "     24        0.3804       0.8292        0.3677  0.0001  20.1429\n",
      "     25        \u001b[36m0.3720\u001b[0m       \u001b[32m0.8305\u001b[0m        0.3710  0.0000  20.1698\n",
      "âœ… Val Accuracy: 0.830 | Val Îºappa: 0.661\n",
      "\n",
      "ðŸ§© Subject 10/10\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.7839\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6957\u001b[0m  0.0200  30.2276\n",
      "      2        \u001b[36m0.7065\u001b[0m       0.5000        0.7828  0.0199  32.2892\n",
      "      3        \u001b[36m0.7048\u001b[0m       \u001b[32m0.5029\u001b[0m        0.7843  0.0197  44.7611\n",
      "      4        0.7085       \u001b[32m0.5053\u001b[0m        0.7354  0.0192  31.2241\n",
      "      5        0.7057       0.5004        0.7447  0.0187  21.1750\n",
      "      6        \u001b[36m0.7030\u001b[0m       \u001b[32m0.5372\u001b[0m        \u001b[35m0.6932\u001b[0m  0.0179  20.8992\n",
      "      7        0.7055       0.4918        0.7107  0.0171  20.8486\n",
      "      8        0.7032       0.5049        0.6998  0.0161  20.8319\n",
      "      9        \u001b[36m0.7001\u001b[0m       \u001b[32m0.5735\u001b[0m        \u001b[35m0.6903\u001b[0m  0.0150  21.3327\n",
      "     10        \u001b[36m0.6949\u001b[0m       0.5257        0.7006  0.0138  21.1326\n",
      "     11        \u001b[36m0.6928\u001b[0m       0.5053        0.7336  0.0126  21.1799\n",
      "     12        \u001b[36m0.6883\u001b[0m       0.5000        1.3833  0.0113  21.1694\n",
      "     13        \u001b[36m0.6798\u001b[0m       0.5041        0.7504  0.0100  21.2373\n",
      "     14        \u001b[36m0.6545\u001b[0m       0.5000        1.0218  0.0087  20.8585\n",
      "     15        \u001b[36m0.6018\u001b[0m       0.5004        1.1516  0.0074  20.7865\n",
      "     16        \u001b[36m0.5782\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m0.6702\u001b[0m  0.0062  20.8900\n",
      "     17        \u001b[36m0.5630\u001b[0m       0.6401        0.6863  0.0050  21.0289\n",
      "     18        \u001b[36m0.5488\u001b[0m       0.5082        1.0099  0.0039  20.8960\n",
      "     19        \u001b[36m0.5470\u001b[0m       0.5257        0.8331  0.0029  21.0272\n",
      "     20        \u001b[36m0.5366\u001b[0m       \u001b[32m0.7574\u001b[0m        \u001b[35m0.5176\u001b[0m  0.0021  20.9670\n",
      "     21        \u001b[36m0.5324\u001b[0m       0.6981        0.5594  0.0013  20.9027\n",
      "     22        \u001b[36m0.5321\u001b[0m       0.6981        0.5662  0.0008  20.9979\n",
      "     23        \u001b[36m0.5237\u001b[0m       0.7574        \u001b[35m0.5146\u001b[0m  0.0003  20.9724\n",
      "     24        0.5254       \u001b[32m0.7614\u001b[0m        \u001b[35m0.5077\u001b[0m  0.0001  20.8951\n",
      "     25        \u001b[36m0.5232\u001b[0m       0.7610        \u001b[35m0.5046\u001b[0m  0.0000  20.8925\n",
      "âœ… Val Accuracy: 0.761 | Val Îºappa: 0.522\n",
      "\n",
      "============================================================\n",
      "CROSS-SUBJECT VALIDATION SUMMARY\n",
      "------------------------------------------------------------\n",
      "Mean Val Accuracy : 0.798 Â± 0.032\n",
      "Mean Val Kappa    : 0.596 Â± 0.064\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_cross_subject_adaptive_val(windows_datasets_list, model, n_epochs=25, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
