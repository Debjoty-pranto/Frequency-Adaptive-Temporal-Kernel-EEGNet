{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6893531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MILAKUL\\anaconda3\\envs\\torch\\lib\\site-packages\\braindecode\\datautil\\__init__.py:24: UserWarning: create_from_mne_epochs has been moved to datasets, please use from braindecode.datasets import create_from_mne_epochs\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import braindecode\n",
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from braindecode.datautil import create_from_mne_epochs\n",
    "from braindecode.preprocessing import exponential_moving_standardize\n",
    "from braindecode.models import EEGNetv4\n",
    "from braindecode import EEGClassifier\n",
    "from skorch.callbacks import LRScheduler\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc75de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cde9bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU check\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba3e9f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MILAKUL\\anaconda3\\envs\\torch\\lib\\site-packages\\braindecode\\util.py:52: UserWarning: torch.backends.cudnn.benchmark was set to True which may results in lack of reproducibility. In some cases to ensure reproducibility you may need to set torch.backends.cudnn.benchmark to False.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reproducibility\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5da9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "window_size = 1024   # 2 sec\n",
    "window_stride = 64   # 125 ms\n",
    "low_cut_hz = 8.\n",
    "high_cut_hz = 32.\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "n_epochs = 25\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92eefcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "mne.set_log_level(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd81c831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 8\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\MILAKUL\\Documents\\Thesis\\clinicalBCI\"\n",
    "training_files = glob.glob(data_path + \"/*T.mat\")\n",
    "print(\"Number of training files:\", len(training_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff8aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects loaded: 8\n"
     ]
    }
   ],
   "source": [
    "def get_mne_epochs(filepath, t_start=2, fs=512):\n",
    "    mat_data = loadmat(filepath)\n",
    "    eeg_data = mat_data['RawEEGData'][:, :, fs*t_start:]  # drop first t_start sec\n",
    "    labels = mat_data['Labels'].ravel() - 1  # 0/1 labels\n",
    "\n",
    "    ch_names = ['F3','FC3','C3','CP3','P3','FCz','CPz','F4','FC4','C4','CP4','P4']\n",
    "    info = mne.create_info(ch_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, tmin=-0.5)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None)\n",
    "    epochs.events[:, 2] = labels\n",
    "    return epochs\n",
    "\n",
    "epochs_list_train = [get_mne_epochs(f) for f in training_files]\n",
    "print(\"Number of subjects loaded:\", len(epochs_list_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c26a6fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects (datasets): 8\n",
      "Windows in first subject: 1360\n"
     ]
    }
   ],
   "source": [
    "window_size = 1024  # samples (2 sec)\n",
    "window_stride = 64  # samples (125 ms)\n",
    "\n",
    "windows_datasets_list = []\n",
    "\n",
    "for epochs in epochs_list_train:\n",
    "    cropped_epoch = epochs.crop(tmin=0.5, tmax=4.5, include_tmax=False)\n",
    "    windows_dataset = create_from_mne_epochs(\n",
    "        [cropped_epoch],\n",
    "        window_size_samples=window_size,\n",
    "        window_stride_samples=window_stride,\n",
    "        drop_last_window=False\n",
    "    )\n",
    "    windows_datasets_list.append(windows_dataset)\n",
    "\n",
    "print(\"Subjects (datasets):\", len(windows_datasets_list))\n",
    "print(\"Windows in first subject:\", len(windows_datasets_list[0]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb04f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 12 Window size: 1024\n"
     ]
    }
   ],
   "source": [
    "# Get the first dataset for the first subject\n",
    "first_dataset = windows_datasets_list[0]\n",
    "\n",
    "# Get the actual EEG data from the first window\n",
    "first_window = first_dataset.datasets[0].windows  # this is MNE Epochs object\n",
    "first_window_data = first_window.get_data()        # NumPy array: (trials, channels, samples)\n",
    "\n",
    "# Number of channels and window size\n",
    "n_chans = first_window_data.shape[1]\n",
    "window_size = first_window_data.shape[2]\n",
    "\n",
    "print(\"Channels:\", n_chans, \"Window size:\", window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb81e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cut_hz = 8.\n",
    "high_cut_hz = 32.\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs):\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        data[i] = exponential_moving_standardize(data[i],\n",
    "                                                 factor_new=factor_new,\n",
    "                                                 init_block_size=init_block_size)\n",
    "    epochs._data = data\n",
    "    return epochs\n",
    "\n",
    "for windows_dataset in windows_datasets_list:\n",
    "    epochs = windows_dataset.datasets[0].windows\n",
    "    epochs.load_data()   # âœ… forces preload\n",
    "    epochs.pick_types(eeg=True)\n",
    "    epochs.filter(l_freq=8., h_freq=32.)\n",
    "    custom_exp_moving_std_fn(epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99cdab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Frequency_Adaptive_model import AdaptiveEEGNet \n",
    "# Deterministic training setup \n",
    "torch.backends.cudnn.deterministic = True \n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Model hyperparameters\n",
    "\n",
    "n_classes = 2\n",
    "n_chans = windows_datasets_list[0][0][0].shape[0]      # EEG channels\n",
    "input_window_samples = windows_datasets_list[0][0][0].shape[1]  # time samples\n",
    "\n",
    "# Instantiate AdaptiveEEGNet\n",
    "model = AdaptiveEEGNet(\n",
    "    nb_classes=n_classes,\n",
    "    Chans=n_chans,\n",
    "    Samples=input_window_samples,\n",
    "    kernLength=128,\n",
    "    F1=16,\n",
    "    D=2,\n",
    "    F2=32,\n",
    "    dropoutRate=0.3,\n",
    "    sample_rate=512\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54974e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from braindecode import EEGClassifier\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from copy import deepcopy\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def training_cross_subject_adaptive_val (windows_datasets_list, base_model,\n",
    "                                                   n_epochs=25, batch_size=32, val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Cross-subject AdaptiveEEGNet training (no reinit per epoch).\n",
    "    Tracks best validation kappa for each subject, prints clean summary table.\n",
    "    \"\"\"\n",
    "    n_subjects = len(windows_datasets_list)\n",
    "    all_val_acc, all_val_kappa = [], []\n",
    "\n",
    "    print(f\"\\n{'='*20} CROSS-SUBJECT VALIDATION {'='*20}\\n\")\n",
    "\n",
    "    for test_idx in range(n_subjects):\n",
    "        print(f\"\\nðŸ§© Subject {test_idx+1}/{n_subjects}\")\n",
    "\n",
    "        # ----- Prepare data -----\n",
    "        train_datasets = [windows_datasets_list[i] for i in range(n_subjects) if i != test_idx]\n",
    "        X_train, y_train = [], []\n",
    "        for ds in train_datasets:\n",
    "            for d in ds.datasets:\n",
    "                X_train.append(d.windows)\n",
    "                y_train.append(d.y)\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "        # Split into train/validation\n",
    "        X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=val_ratio, stratify=y_train, random_state=42\n",
    "        )\n",
    "\n",
    "        train_tensor = TensorDataset(torch.tensor(X_tr, dtype=torch.float32),\n",
    "                                     torch.tensor(y_tr, dtype=torch.long))\n",
    "        val_tensor = TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                                   torch.tensor(y_val, dtype=torch.long))\n",
    "\n",
    "        # Fresh model copy\n",
    "        model = deepcopy(base_model)\n",
    "\n",
    "        # EEG classifier setup\n",
    "        clf = EEGClassifier(\n",
    "            model,\n",
    "            criterion=torch.nn.CrossEntropyLoss,\n",
    "            optimizer=torch.optim.AdamW,\n",
    "            optimizer__lr=0.02,\n",
    "            optimizer__weight_decay=0.0005,\n",
    "            batch_size=batch_size,\n",
    "            train_split=predefined_split(val_tensor),\n",
    "            callbacks=[(\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=n_epochs-1))],\n",
    "            device=device,\n",
    "            iterator_train__shuffle=True\n",
    "        )\n",
    "\n",
    "        # ---- Train all epochs ----\n",
    "        clf.fit(train_tensor, y=None, epochs=n_epochs)\n",
    "\n",
    "        # ---- Evaluate on validation ----\n",
    "        val_loader = DataLoader(val_tensor, batch_size=batch_size, shuffle=False)\n",
    "        clf.module_.eval()\n",
    "        val_preds, val_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                out = clf.module_(Xb.to(device))\n",
    "                val_preds.extend(out.argmax(1).cpu().numpy())\n",
    "                val_true.extend(yb.numpy())\n",
    "\n",
    "        val_acc = accuracy_score(val_true, val_preds)\n",
    "        val_kappa = cohen_kappa_score(val_true, val_preds)\n",
    "\n",
    "        all_val_acc.append(val_acc)\n",
    "        all_val_kappa.append(val_kappa)\n",
    "\n",
    "        print(f\"âœ… Val Accuracy: {val_acc:.3f} | Val Îºappa: {val_kappa:.3f}\")\n",
    "\n",
    "    # ---- Final Summary ----\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"CROSS-SUBJECT VALIDATION SUMMARY\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    print(f\"Mean Val Accuracy : {np.mean(all_val_acc):.3f} Â± {np.std(all_val_acc):.3f}\")\n",
    "    print(f\"Mean Val Kappa    : {np.mean(all_val_kappa):.3f} Â± {np.std(all_val_kappa):.3f}\")\n",
    "    print(f\"{'='*60}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71d5d5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== CROSS-SUBJECT VALIDATION ====================\n",
      "\n",
      "\n",
      "ðŸ§© Subject 1/8\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.8448\u001b[0m       \u001b[32m0.5509\u001b[0m        \u001b[35m0.7424\u001b[0m  0.0200  5.9711\n",
      "      2        \u001b[36m0.7216\u001b[0m       0.4953        0.7553  0.0199  5.1591\n",
      "      3        \u001b[36m0.7067\u001b[0m       0.5158        \u001b[35m0.7177\u001b[0m  0.0197  5.1451\n",
      "      4        \u001b[36m0.7024\u001b[0m       0.5116        \u001b[35m0.7034\u001b[0m  0.0192  5.0679\n",
      "      5        0.7043       0.4842        0.7526  0.0187  5.1386\n",
      "      6        0.7090       \u001b[32m0.6024\u001b[0m        \u001b[35m0.6905\u001b[0m  0.0179  5.0889\n",
      "      7        \u001b[36m0.6956\u001b[0m       0.5494        0.7203  0.0171  5.0972\n",
      "      8        0.6988       0.5294        0.7427  0.0161  5.2352\n",
      "      9        \u001b[36m0.6857\u001b[0m       0.5000        0.9848  0.0150  5.0860\n",
      "     10        \u001b[36m0.6849\u001b[0m       0.5678        0.7496  0.0138  5.0680\n",
      "     11        \u001b[36m0.6669\u001b[0m       \u001b[32m0.6255\u001b[0m        0.7139  0.0126  4.9652\n",
      "     12        \u001b[36m0.6608\u001b[0m       0.5415        0.7378  0.0113  4.9404\n",
      "     13        \u001b[36m0.6554\u001b[0m       0.5221        0.8353  0.0100  4.0195\n",
      "     14        \u001b[36m0.6474\u001b[0m       0.5583        0.7688  0.0087  3.7029\n",
      "     15        \u001b[36m0.6076\u001b[0m       \u001b[32m0.7001\u001b[0m        \u001b[35m0.5929\u001b[0m  0.0074  3.7759\n",
      "     16        \u001b[36m0.5388\u001b[0m       0.5483        0.7347  0.0062  3.7471\n",
      "     17        \u001b[36m0.5229\u001b[0m       \u001b[32m0.7763\u001b[0m        \u001b[35m0.5386\u001b[0m  0.0050  3.7182\n",
      "     18        \u001b[36m0.5079\u001b[0m       \u001b[32m0.7925\u001b[0m        \u001b[35m0.4747\u001b[0m  0.0039  3.7132\n",
      "     19        \u001b[36m0.4929\u001b[0m       0.7106        0.5449  0.0029  3.7648\n",
      "     20        \u001b[36m0.4802\u001b[0m       0.7715        0.5102  0.0021  3.6183\n",
      "     21        \u001b[36m0.4726\u001b[0m       \u001b[32m0.8167\u001b[0m        \u001b[35m0.4510\u001b[0m  0.0013  3.7114\n",
      "     22        \u001b[36m0.4654\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.4314\u001b[0m  0.0008  3.6449\n",
      "     23        \u001b[36m0.4627\u001b[0m       0.8225        0.4324  0.0003  3.7727\n",
      "     24        \u001b[36m0.4571\u001b[0m       0.8220        0.4423  0.0001  3.7006\n",
      "     25        \u001b[36m0.4545\u001b[0m       0.7826        0.4899  0.0000  3.7862\n",
      "âœ… Val Accuracy: 0.783 | Val Îºappa: 0.565\n",
      "\n",
      "ðŸ§© Subject 2/8\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.9272\u001b[0m       \u001b[32m0.5053\u001b[0m        \u001b[35m0.7479\u001b[0m  0.0200  3.9153\n",
      "      2        \u001b[36m0.7090\u001b[0m       \u001b[32m0.5152\u001b[0m        \u001b[35m0.6986\u001b[0m  0.0199  3.6899\n",
      "      3        \u001b[36m0.7032\u001b[0m       \u001b[32m0.5231\u001b[0m        \u001b[35m0.6951\u001b[0m  0.0197  3.6566\n",
      "      4        \u001b[36m0.6998\u001b[0m       0.5210        \u001b[35m0.6949\u001b[0m  0.0192  3.6575\n",
      "      5        0.7025       \u001b[32m0.5499\u001b[0m        \u001b[35m0.6863\u001b[0m  0.0187  3.6752\n",
      "      6        \u001b[36m0.6995\u001b[0m       0.5000        0.7276  0.0179  3.6772\n",
      "      7        \u001b[36m0.6985\u001b[0m       0.5147        0.6950  0.0171  3.6805\n",
      "      8        \u001b[36m0.6984\u001b[0m       \u001b[32m0.5762\u001b[0m        \u001b[35m0.6761\u001b[0m  0.0161  3.6447\n",
      "      9        \u001b[36m0.6905\u001b[0m       0.5699        0.6782  0.0150  3.7147\n",
      "     10        \u001b[36m0.6842\u001b[0m       0.5320        0.7128  0.0138  3.6527\n",
      "     11        \u001b[36m0.6772\u001b[0m       0.5137        0.9258  0.0126  3.7303\n",
      "     12        \u001b[36m0.6555\u001b[0m       0.5756        0.7907  0.0113  3.7231\n",
      "     13        \u001b[36m0.6336\u001b[0m       0.5226        0.7099  0.0100  3.6309\n",
      "     14        \u001b[36m0.5986\u001b[0m       0.5425        0.6978  0.0087  3.6907\n",
      "     15        \u001b[36m0.5693\u001b[0m       \u001b[32m0.6087\u001b[0m        0.6762  0.0074  3.6032\n",
      "     16        \u001b[36m0.5266\u001b[0m       \u001b[32m0.7652\u001b[0m        \u001b[35m0.5015\u001b[0m  0.0062  3.7357\n",
      "     17        \u001b[36m0.5049\u001b[0m       0.6261        0.7159  0.0050  3.6556\n",
      "     18        \u001b[36m0.4917\u001b[0m       \u001b[32m0.7946\u001b[0m        \u001b[35m0.4535\u001b[0m  0.0039  3.7155\n",
      "     19        \u001b[36m0.4693\u001b[0m       0.5961        0.8159  0.0029  3.6686\n",
      "     20        \u001b[36m0.4585\u001b[0m       0.6150        0.7437  0.0021  3.6584\n",
      "     21        0.4586       0.7736        0.4634  0.0013  3.6726\n",
      "     22        \u001b[36m0.4561\u001b[0m       0.7857        \u001b[35m0.4508\u001b[0m  0.0008  3.6213\n",
      "     23        \u001b[36m0.4367\u001b[0m       \u001b[32m0.8267\u001b[0m        \u001b[35m0.4027\u001b[0m  0.0003  3.6153\n",
      "     24        0.4460       0.7521        0.4792  0.0001  3.6441\n",
      "     25        0.4447       0.8235        0.4075  0.0000  3.6253\n",
      "âœ… Val Accuracy: 0.824 | Val Îºappa: 0.647\n",
      "\n",
      "ðŸ§© Subject 3/8\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.7823\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m0.7358\u001b[0m  0.0200  3.8162\n",
      "      2        \u001b[36m0.7084\u001b[0m       \u001b[32m0.5137\u001b[0m        \u001b[35m0.7161\u001b[0m  0.0199  3.6442\n",
      "      3        0.7156       \u001b[32m0.5436\u001b[0m        \u001b[35m0.6925\u001b[0m  0.0197  3.6376\n",
      "      4        \u001b[36m0.7018\u001b[0m       \u001b[32m0.5446\u001b[0m        \u001b[35m0.6882\u001b[0m  0.0192  3.7154\n",
      "      5        0.7030       \u001b[32m0.5583\u001b[0m        \u001b[35m0.6799\u001b[0m  0.0187  3.6257\n",
      "      6        \u001b[36m0.6999\u001b[0m       \u001b[32m0.5609\u001b[0m        0.6857  0.0179  3.6280\n",
      "      7        0.7029       \u001b[32m0.5814\u001b[0m        \u001b[35m0.6722\u001b[0m  0.0171  3.7472\n",
      "      8        \u001b[36m0.6438\u001b[0m       0.5525        1.2393  0.0161  3.6604\n",
      "      9        \u001b[36m0.5773\u001b[0m       \u001b[32m0.7521\u001b[0m        \u001b[35m0.5315\u001b[0m  0.0150  3.6594\n",
      "     10        \u001b[36m0.5510\u001b[0m       0.6182        0.6257  0.0138  3.6153\n",
      "     11        \u001b[36m0.5261\u001b[0m       \u001b[32m0.7920\u001b[0m        \u001b[35m0.4578\u001b[0m  0.0126  3.6957\n",
      "     12        \u001b[36m0.5088\u001b[0m       0.7852        0.4632  0.0113  3.7797\n",
      "     13        \u001b[36m0.4811\u001b[0m       0.7831        \u001b[35m0.4552\u001b[0m  0.0100  3.6447\n",
      "     14        \u001b[36m0.4621\u001b[0m       \u001b[32m0.8141\u001b[0m        \u001b[35m0.4096\u001b[0m  0.0087  3.7600\n",
      "     15        \u001b[36m0.4435\u001b[0m       \u001b[32m0.8157\u001b[0m        \u001b[35m0.4007\u001b[0m  0.0074  3.7206\n",
      "     16        \u001b[36m0.4382\u001b[0m       \u001b[32m0.8283\u001b[0m        \u001b[35m0.3871\u001b[0m  0.0062  3.6655\n",
      "     17        \u001b[36m0.4282\u001b[0m       \u001b[32m0.8361\u001b[0m        \u001b[35m0.3808\u001b[0m  0.0050  3.6758\n",
      "     18        \u001b[36m0.4197\u001b[0m       \u001b[32m0.8372\u001b[0m        0.3840  0.0039  3.7898\n",
      "     19        \u001b[36m0.4169\u001b[0m       \u001b[32m0.8435\u001b[0m        \u001b[35m0.3649\u001b[0m  0.0029  3.7148\n",
      "     20        \u001b[36m0.4050\u001b[0m       0.8335        0.3737  0.0021  3.6603\n",
      "     21        \u001b[36m0.4046\u001b[0m       \u001b[32m0.8451\u001b[0m        \u001b[35m0.3638\u001b[0m  0.0013  3.7032\n",
      "     22        \u001b[36m0.3979\u001b[0m       0.8409        \u001b[35m0.3583\u001b[0m  0.0008  3.7223\n",
      "     23        \u001b[36m0.3934\u001b[0m       \u001b[32m0.8482\u001b[0m        \u001b[35m0.3503\u001b[0m  0.0003  3.7267\n",
      "     24        \u001b[36m0.3923\u001b[0m       \u001b[32m0.8498\u001b[0m        0.3509  0.0001  3.6170\n",
      "     25        0.3937       0.8498        0.3514  0.0000  3.6585\n",
      "âœ… Val Accuracy: 0.850 | Val Îºappa: 0.700\n",
      "\n",
      "ðŸ§© Subject 4/8\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.8475\u001b[0m       \u001b[32m0.4926\u001b[0m        \u001b[35m0.7496\u001b[0m  0.0200  3.8449\n",
      "      2        \u001b[36m0.7101\u001b[0m       \u001b[32m0.5221\u001b[0m        \u001b[35m0.7056\u001b[0m  0.0199  3.6491\n",
      "      3        \u001b[36m0.6998\u001b[0m       \u001b[32m0.5720\u001b[0m        \u001b[35m0.7048\u001b[0m  0.0197  3.6658\n",
      "      4        \u001b[36m0.6934\u001b[0m       0.5168        \u001b[35m0.6906\u001b[0m  0.0192  3.6599\n",
      "      5        \u001b[36m0.6933\u001b[0m       0.5436        \u001b[35m0.6849\u001b[0m  0.0187  3.6746\n",
      "      6        \u001b[36m0.6908\u001b[0m       0.5599        0.6898  0.0179  3.6451\n",
      "      7        \u001b[36m0.6788\u001b[0m       \u001b[32m0.5851\u001b[0m        \u001b[35m0.6690\u001b[0m  0.0171  3.7097\n",
      "      8        \u001b[36m0.6677\u001b[0m       \u001b[32m0.6014\u001b[0m        0.6780  0.0161  3.7779\n",
      "      9        \u001b[36m0.6626\u001b[0m       \u001b[32m0.6423\u001b[0m        \u001b[35m0.6603\u001b[0m  0.0150  3.7818\n",
      "     10        \u001b[36m0.6539\u001b[0m       0.6171        0.6649  0.0138  3.7389\n",
      "     11        \u001b[36m0.6453\u001b[0m       \u001b[32m0.6586\u001b[0m        \u001b[35m0.6501\u001b[0m  0.0126  3.7841\n",
      "     12        \u001b[36m0.6327\u001b[0m       \u001b[32m0.6817\u001b[0m        \u001b[35m0.6417\u001b[0m  0.0113  3.6562\n",
      "     13        \u001b[36m0.5918\u001b[0m       0.6266        0.7807  0.0100  3.7709\n",
      "     14        \u001b[36m0.5011\u001b[0m       \u001b[32m0.7300\u001b[0m        \u001b[35m0.5452\u001b[0m  0.0087  3.7035\n",
      "     15        \u001b[36m0.4740\u001b[0m       0.6991        \u001b[35m0.5335\u001b[0m  0.0074  3.6355\n",
      "     16        \u001b[36m0.4483\u001b[0m       \u001b[32m0.7957\u001b[0m        \u001b[35m0.4334\u001b[0m  0.0062  3.6331\n",
      "     17        \u001b[36m0.4272\u001b[0m       0.7820        0.4593  0.0050  3.6167\n",
      "     18        \u001b[36m0.4168\u001b[0m       \u001b[32m0.8398\u001b[0m        \u001b[35m0.3840\u001b[0m  0.0039  3.7199\n",
      "     19        \u001b[36m0.3943\u001b[0m       \u001b[32m0.8461\u001b[0m        \u001b[35m0.3635\u001b[0m  0.0029  3.6234\n",
      "     20        \u001b[36m0.3892\u001b[0m       0.8340        0.4003  0.0021  3.7248\n",
      "     21        \u001b[36m0.3829\u001b[0m       \u001b[32m0.8493\u001b[0m        0.3639  0.0013  3.7001\n",
      "     22        \u001b[36m0.3808\u001b[0m       \u001b[32m0.8519\u001b[0m        0.3651  0.0008  3.7028\n",
      "     23        \u001b[36m0.3774\u001b[0m       0.8519        \u001b[35m0.3490\u001b[0m  0.0003  3.7790\n",
      "     24        \u001b[36m0.3738\u001b[0m       \u001b[32m0.8550\u001b[0m        \u001b[35m0.3450\u001b[0m  0.0001  3.6359\n",
      "     25        0.3744       \u001b[32m0.8556\u001b[0m        0.3487  0.0000  3.6665\n",
      "âœ… Val Accuracy: 0.856 | Val Îºappa: 0.711\n",
      "\n",
      "ðŸ§© Subject 5/8\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.8574\u001b[0m       \u001b[32m0.4764\u001b[0m        \u001b[35m0.7032\u001b[0m  0.0200  3.9443\n",
      "      2        \u001b[36m0.7027\u001b[0m       \u001b[32m0.5058\u001b[0m        \u001b[35m0.6994\u001b[0m  0.0199  3.6159\n",
      "      3        0.7051       \u001b[32m0.5231\u001b[0m        \u001b[35m0.6946\u001b[0m  0.0197  3.7283\n",
      "      4        \u001b[36m0.7005\u001b[0m       \u001b[32m0.5609\u001b[0m        \u001b[35m0.6897\u001b[0m  0.0192  3.6030\n",
      "      5        \u001b[36m0.6989\u001b[0m       0.5131        0.7002  0.0187  3.6417\n",
      "      6        \u001b[36m0.6945\u001b[0m       0.5462        \u001b[35m0.6866\u001b[0m  0.0179  3.6383\n",
      "      7        \u001b[36m0.6930\u001b[0m       0.5095        0.7347  0.0171  3.6109\n",
      "      8        0.6941       0.5000        1.0961  0.0161  3.6364\n",
      "      9        \u001b[36m0.6820\u001b[0m       0.5011        0.7906  0.0150  3.6355\n",
      "     10        \u001b[36m0.6731\u001b[0m       \u001b[32m0.6061\u001b[0m        \u001b[35m0.6755\u001b[0m  0.0138  3.6385\n",
      "     11        \u001b[36m0.6694\u001b[0m       0.5966        \u001b[35m0.6739\u001b[0m  0.0126  3.6299\n",
      "     12        \u001b[36m0.6575\u001b[0m       \u001b[32m0.6360\u001b[0m        \u001b[35m0.6628\u001b[0m  0.0113  3.7342\n",
      "     13        \u001b[36m0.6350\u001b[0m       0.5667        0.7151  0.0100  3.7642\n",
      "     14        \u001b[36m0.5831\u001b[0m       \u001b[32m0.7232\u001b[0m        \u001b[35m0.5887\u001b[0m  0.0087  3.7293\n",
      "     15        \u001b[36m0.5002\u001b[0m       0.6675        0.6640  0.0074  3.8077\n",
      "     16        \u001b[36m0.4671\u001b[0m       0.5966        0.7589  0.0062  3.8412\n",
      "     17        \u001b[36m0.4485\u001b[0m       \u001b[32m0.7967\u001b[0m        \u001b[35m0.4535\u001b[0m  0.0050  3.7603\n",
      "     18        \u001b[36m0.4309\u001b[0m       0.7794        0.4929  0.0039  3.6809\n",
      "     19        \u001b[36m0.4109\u001b[0m       0.7726        0.4680  0.0029  3.7202\n",
      "     20        \u001b[36m0.4014\u001b[0m       \u001b[32m0.8335\u001b[0m        \u001b[35m0.3991\u001b[0m  0.0021  3.7858\n",
      "     21        \u001b[36m0.3915\u001b[0m       0.8114        0.4095  0.0013  3.7496\n",
      "     22        \u001b[36m0.3779\u001b[0m       \u001b[32m0.8419\u001b[0m        \u001b[35m0.3852\u001b[0m  0.0008  3.6425\n",
      "     23        \u001b[36m0.3733\u001b[0m       \u001b[32m0.8440\u001b[0m        0.3954  0.0003  3.6253\n",
      "     24        0.3789       0.8130        0.4192  0.0001  3.7579\n",
      "     25        \u001b[36m0.3652\u001b[0m       0.8340        0.3980  0.0000  3.7097\n",
      "âœ… Val Accuracy: 0.834 | Val Îºappa: 0.668\n",
      "\n",
      "ðŸ§© Subject 6/8\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.7660\u001b[0m       \u001b[32m0.5053\u001b[0m        \u001b[35m0.7774\u001b[0m  0.0200  3.8347\n",
      "      2        \u001b[36m0.7121\u001b[0m       0.4958        \u001b[35m0.6955\u001b[0m  0.0199  3.6852\n",
      "      3        \u001b[36m0.7077\u001b[0m       0.5000        0.7307  0.0197  3.6183\n",
      "      4        0.7079       \u001b[32m0.5063\u001b[0m        0.6969  0.0192  3.6415\n",
      "      5        \u001b[36m0.7049\u001b[0m       0.5000        0.7264  0.0187  3.6468\n",
      "      6        0.7076       0.5000        0.8784  0.0179  3.6664\n",
      "      7        0.7088       \u001b[32m0.5735\u001b[0m        0.7054  0.0171  3.6155\n",
      "      8        0.7077       0.5116        0.7547  0.0161  3.7236\n",
      "      9        \u001b[36m0.7001\u001b[0m       0.5236        \u001b[35m0.6925\u001b[0m  0.0150  3.6986\n",
      "     10        \u001b[36m0.6986\u001b[0m       0.4911        0.6993  0.0138  3.6698\n",
      "     11        \u001b[36m0.6943\u001b[0m       \u001b[32m0.5961\u001b[0m        0.7005  0.0126  3.6603\n",
      "     12        0.6949       0.5058        0.6958  0.0113  3.6754\n",
      "     13        \u001b[36m0.6889\u001b[0m       \u001b[32m0.6134\u001b[0m        0.6981  0.0100  3.5819\n",
      "     14        \u001b[36m0.6831\u001b[0m       0.5546        0.6962  0.0087  3.4953\n",
      "     15        \u001b[36m0.6750\u001b[0m       0.5814        \u001b[35m0.6785\u001b[0m  0.0074  3.6810\n",
      "     16        \u001b[36m0.6720\u001b[0m       0.5972        \u001b[35m0.6559\u001b[0m  0.0062  3.6154\n",
      "     17        \u001b[36m0.6601\u001b[0m       0.5289        0.6915  0.0050  3.6940\n",
      "     18        \u001b[36m0.6476\u001b[0m       0.5074        0.7871  0.0039  3.6604\n",
      "     19        \u001b[36m0.6316\u001b[0m       \u001b[32m0.6492\u001b[0m        \u001b[35m0.6125\u001b[0m  0.0029  3.7284\n",
      "     20        \u001b[36m0.6112\u001b[0m       \u001b[32m0.6539\u001b[0m        0.6193  0.0021  3.7340\n",
      "     21        \u001b[36m0.5974\u001b[0m       0.6287        0.6339  0.0013  3.7318\n",
      "     22        \u001b[36m0.5823\u001b[0m       \u001b[32m0.6954\u001b[0m        \u001b[35m0.5751\u001b[0m  0.0008  3.7057\n",
      "     23        \u001b[36m0.5763\u001b[0m       0.6907        0.5780  0.0003  3.7646\n",
      "     24        \u001b[36m0.5758\u001b[0m       0.6928        \u001b[35m0.5745\u001b[0m  0.0001  3.6977\n",
      "     25        \u001b[36m0.5736\u001b[0m       \u001b[32m0.7043\u001b[0m        \u001b[35m0.5689\u001b[0m  0.0000  3.8511\n",
      "âœ… Val Accuracy: 0.704 | Val Îºappa: 0.409\n",
      "\n",
      "ðŸ§© Subject 7/8\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.8210\u001b[0m       \u001b[32m0.4932\u001b[0m        \u001b[35m0.7114\u001b[0m  0.0200  3.9275\n",
      "      2        \u001b[36m0.7067\u001b[0m       \u001b[32m0.4984\u001b[0m        0.7284  0.0199  3.6453\n",
      "      3        \u001b[36m0.7059\u001b[0m       \u001b[32m0.5000\u001b[0m        0.7123  0.0197  3.7202\n",
      "      4        \u001b[36m0.7040\u001b[0m       \u001b[32m0.5047\u001b[0m        0.7118  0.0192  3.8122\n",
      "      5        \u001b[36m0.7033\u001b[0m       \u001b[32m0.5179\u001b[0m        \u001b[35m0.7057\u001b[0m  0.0187  3.7358\n",
      "      6        \u001b[36m0.6983\u001b[0m       0.5068        0.7146  0.0179  3.8708\n",
      "      7        0.6998       0.5105        \u001b[35m0.6976\u001b[0m  0.0171  3.6866\n",
      "      8        \u001b[36m0.6974\u001b[0m       \u001b[32m0.5357\u001b[0m        \u001b[35m0.6954\u001b[0m  0.0161  3.6515\n",
      "      9        \u001b[36m0.6966\u001b[0m       \u001b[32m0.5688\u001b[0m        \u001b[35m0.6923\u001b[0m  0.0150  3.6917\n",
      "     10        \u001b[36m0.6948\u001b[0m       0.5147        0.6962  0.0138  3.6546\n",
      "     11        \u001b[36m0.6935\u001b[0m       0.5630        \u001b[35m0.6844\u001b[0m  0.0126  3.7971\n",
      "     12        \u001b[36m0.6854\u001b[0m       0.5079        \u001b[35m0.6832\u001b[0m  0.0113  4.0620\n",
      "     13        \u001b[36m0.6791\u001b[0m       0.5530        0.6835  0.0100  3.9370\n",
      "     14        \u001b[36m0.6739\u001b[0m       0.5184        0.7450  0.0087  3.6282\n",
      "     15        \u001b[36m0.6663\u001b[0m       \u001b[32m0.6208\u001b[0m        \u001b[35m0.6677\u001b[0m  0.0074  3.8181\n",
      "     16        \u001b[36m0.6452\u001b[0m       0.6129        0.6999  0.0062  3.6838\n",
      "     17        \u001b[36m0.5354\u001b[0m       \u001b[32m0.7542\u001b[0m        \u001b[35m0.4866\u001b[0m  0.0050  3.7736\n",
      "     18        \u001b[36m0.4673\u001b[0m       \u001b[32m0.8067\u001b[0m        \u001b[35m0.4405\u001b[0m  0.0039  3.9426\n",
      "     19        \u001b[36m0.4473\u001b[0m       0.7967        \u001b[35m0.4398\u001b[0m  0.0029  3.7298\n",
      "     20        \u001b[36m0.4225\u001b[0m       0.8025        0.4419  0.0021  3.7570\n",
      "     21        \u001b[36m0.4107\u001b[0m       0.8036        \u001b[35m0.4174\u001b[0m  0.0013  3.7891\n",
      "     22        \u001b[36m0.4047\u001b[0m       \u001b[32m0.8330\u001b[0m        \u001b[35m0.3885\u001b[0m  0.0008  3.6849\n",
      "     23        \u001b[36m0.3974\u001b[0m       0.8262        \u001b[35m0.3841\u001b[0m  0.0003  3.6304\n",
      "     24        0.3992       0.8319        0.3912  0.0001  3.6451\n",
      "     25        0.3981       0.8304        \u001b[35m0.3833\u001b[0m  0.0000  3.6279\n",
      "âœ… Val Accuracy: 0.830 | Val Îºappa: 0.661\n",
      "\n",
      "ðŸ§© Subject 8/8\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.7871\u001b[0m       \u001b[32m0.5147\u001b[0m        \u001b[35m0.7171\u001b[0m  0.0200  3.8175\n",
      "      2        \u001b[36m0.7115\u001b[0m       \u001b[32m0.6087\u001b[0m        \u001b[35m0.6963\u001b[0m  0.0199  3.6788\n",
      "      3        \u001b[36m0.7015\u001b[0m       0.5000        0.7471  0.0197  3.7363\n",
      "      4        0.7043       0.4800        \u001b[35m0.6912\u001b[0m  0.0192  3.6451\n",
      "      5        0.7023       0.5137        0.7196  0.0187  3.7201\n",
      "      6        0.7030       0.5236        0.7190  0.0179  3.7116\n",
      "      7        0.7073       0.5284        0.6962  0.0171  3.7286\n",
      "      8        \u001b[36m0.7005\u001b[0m       0.5667        \u001b[35m0.6864\u001b[0m  0.0161  3.6573\n",
      "      9        \u001b[36m0.6933\u001b[0m       0.5047        1.0187  0.0150  3.7330\n",
      "     10        \u001b[36m0.6875\u001b[0m       \u001b[32m0.6381\u001b[0m        \u001b[35m0.6619\u001b[0m  0.0138  3.6800\n",
      "     11        \u001b[36m0.5932\u001b[0m       \u001b[32m0.6702\u001b[0m        \u001b[35m0.5987\u001b[0m  0.0126  3.6460\n",
      "     12        \u001b[36m0.5235\u001b[0m       \u001b[32m0.7511\u001b[0m        \u001b[35m0.5687\u001b[0m  0.0113  3.6873\n",
      "     13        \u001b[36m0.4992\u001b[0m       \u001b[32m0.7574\u001b[0m        \u001b[35m0.5148\u001b[0m  0.0100  3.7273\n",
      "     14        \u001b[36m0.4953\u001b[0m       \u001b[32m0.7668\u001b[0m        \u001b[35m0.4959\u001b[0m  0.0087  3.6930\n",
      "     15        \u001b[36m0.4786\u001b[0m       0.6843        0.5706  0.0074  3.7634\n",
      "     16        \u001b[36m0.4743\u001b[0m       0.7085        0.5599  0.0062  3.7099\n",
      "     17        \u001b[36m0.4601\u001b[0m       0.6481        0.6266  0.0050  3.7136\n",
      "     18        \u001b[36m0.4492\u001b[0m       \u001b[32m0.8099\u001b[0m        \u001b[35m0.4415\u001b[0m  0.0039  3.7216\n",
      "     19        \u001b[36m0.4458\u001b[0m       0.7658        0.4794  0.0029  3.8724\n",
      "     20        \u001b[36m0.4358\u001b[0m       \u001b[32m0.8146\u001b[0m        \u001b[35m0.4186\u001b[0m  0.0021  3.8494\n",
      "     21        \u001b[36m0.4355\u001b[0m       0.7983        0.4416  0.0013  3.7086\n",
      "     22        \u001b[36m0.4251\u001b[0m       0.8072        0.4259  0.0008  3.6898\n",
      "     23        \u001b[36m0.4235\u001b[0m       \u001b[32m0.8267\u001b[0m        \u001b[35m0.4014\u001b[0m  0.0003  3.7211\n",
      "     24        \u001b[36m0.4184\u001b[0m       0.8204        0.4119  0.0001  3.7638\n",
      "     25        0.4290       0.8225        0.4099  0.0000  3.8218\n",
      "âœ… Val Accuracy: 0.822 | Val Îºappa: 0.645\n",
      "\n",
      "============================================================\n",
      "CROSS-SUBJECT VALIDATION SUMMARY\n",
      "------------------------------------------------------------\n",
      "Mean Val Accuracy : 0.813 Â± 0.046\n",
      "Mean Val Kappa    : 0.626 Â± 0.092\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_cross_subject_adaptive_val(windows_datasets_list, model, n_epochs=25, batch_size=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8590e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
