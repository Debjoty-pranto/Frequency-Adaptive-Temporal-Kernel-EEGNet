{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6893531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode\n",
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from braindecode.datautil import create_from_mne_epochs\n",
    "from braindecode.preprocessing import exponential_moving_standardize\n",
    "from braindecode.models import EEGNetv4\n",
    "from braindecode import EEGClassifier\n",
    "from skorch.callbacks import LRScheduler\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cde9bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU check\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba3e9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reproducibility\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd5da9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "window_size = 1024   # 2 sec\n",
    "window_stride = 64   # 125 ms\n",
    "low_cut_hz = 8.\n",
    "high_cut_hz = 32.\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "n_epochs = 25\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92eefcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "mne.set_log_level(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd81c831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 10\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\User\\Documents\\GitHub\\Frequency-Adaptive-Temporal-Kernel-EEGNet\\Data\"\n",
    "training_files = glob.glob(data_path + \"/*T.mat\")\n",
    "print(\"Number of training files:\", len(training_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eff8aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects loaded: 10\n"
     ]
    }
   ],
   "source": [
    "def get_mne_epochs(filepath, t_start=2, fs=512):\n",
    "    mat_data = loadmat(filepath)\n",
    "    eeg_data = mat_data['RawEEGData'][:, :, fs*t_start:]  # drop first t_start sec\n",
    "    labels = mat_data['Labels'].ravel() - 1  # 0/1 labels\n",
    "\n",
    "    ch_names = ['F3','FC3','C3','CP3','P3','FCz','CPz','F4','FC4','C4','CP4','P4']\n",
    "    info = mne.create_info(ch_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, tmin=-0.5)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None)\n",
    "    epochs.events[:, 2] = labels\n",
    "    return epochs\n",
    "\n",
    "epochs_list_train = [get_mne_epochs(f) for f in training_files]\n",
    "print(\"Number of subjects loaded:\", len(epochs_list_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c26a6fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects (datasets): 10\n",
      "Windows in first subject: 1360\n"
     ]
    }
   ],
   "source": [
    "window_size = 1024  # samples (2 sec)\n",
    "window_stride = 64  # samples (125 ms)\n",
    "\n",
    "windows_datasets_list = []\n",
    "\n",
    "for epochs in epochs_list_train:\n",
    "    cropped_epoch = epochs.crop(tmin=0.5, tmax=4.5, include_tmax=False)\n",
    "    windows_dataset = create_from_mne_epochs(\n",
    "        [cropped_epoch],\n",
    "        window_size_samples=window_size,\n",
    "        window_stride_samples=window_stride,\n",
    "        drop_last_window=False\n",
    "    )\n",
    "    windows_datasets_list.append(windows_dataset)\n",
    "\n",
    "print(\"Subjects (datasets):\", len(windows_datasets_list))\n",
    "print(\"Windows in first subject:\", len(windows_datasets_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfb04f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 12 Window size: 1024\n"
     ]
    }
   ],
   "source": [
    "# Get the first dataset for the first subject\n",
    "first_dataset = windows_datasets_list[0]\n",
    "\n",
    "# Get the actual EEG data from the first window\n",
    "first_window = first_dataset.datasets[0].windows  # this is MNE Epochs object\n",
    "first_window_data = first_window.get_data()        # NumPy array: (trials, channels, samples)\n",
    "\n",
    "# Number of channels and window size\n",
    "n_chans = first_window_data.shape[1]\n",
    "window_size = first_window_data.shape[2]\n",
    "\n",
    "print(\"Channels:\", n_chans, \"Window size:\", window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb81e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cut_hz = 8.\n",
    "high_cut_hz = 32.\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs):\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        data[i] = exponential_moving_standardize(data[i],\n",
    "                                                 factor_new=factor_new,\n",
    "                                                 init_block_size=init_block_size)\n",
    "    epochs._data = data\n",
    "    return epochs\n",
    "\n",
    "for windows_dataset in windows_datasets_list:\n",
    "    epochs = windows_dataset.datasets[0].windows\n",
    "    epochs.load_data()   # âœ… forces preload\n",
    "    epochs.pick_types(eeg=True)\n",
    "    epochs.filter(l_freq=8., h_freq=32.)\n",
    "    custom_exp_moving_std_fn(epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99cdab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Frequency_Adaptive_model import AdaptiveEEGNet \n",
    "# Deterministic training setup \n",
    "torch.backends.cudnn.deterministic = True \n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Model hyperparameters\n",
    "\n",
    "n_classes = 2\n",
    "n_chans = windows_datasets_list[0][0][0].shape[0]      # EEG channels\n",
    "input_window_samples = windows_datasets_list[0][0][0].shape[1]  # time samples\n",
    "\n",
    "# Instantiate AdaptiveEEGNet\n",
    "model = AdaptiveEEGNet(\n",
    "    nb_classes=n_classes,\n",
    "    Chans=n_chans,\n",
    "    Samples=input_window_samples,\n",
    "    kernLength=128,\n",
    "    F1=16,\n",
    "    D=2,\n",
    "    F2=32,\n",
    "    dropoutRate=0.3,\n",
    "    sample_rate=512\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54974e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from braindecode import EEGClassifier\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from copy import deepcopy\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def training_cross_subject_adaptive_val (windows_datasets_list, base_model,\n",
    "                                                   n_epochs=25, batch_size=32, val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Cross-subject AdaptiveEEGNet training (no reinit per epoch).\n",
    "    Tracks best validation kappa for each subject, prints clean summary table.\n",
    "    \"\"\"\n",
    "    n_subjects = len(windows_datasets_list)\n",
    "    all_val_acc, all_val_kappa = [], []\n",
    "\n",
    "    print(f\"\\n{'='*20} CROSS-SUBJECT VALIDATION {'='*20}\\n\")\n",
    "\n",
    "    for test_idx in range(n_subjects):\n",
    "        print(f\"\\nðŸ§© Subject {test_idx+1}/{n_subjects}\")\n",
    "\n",
    "        # ----- Prepare data -----\n",
    "        train_datasets = [windows_datasets_list[i] for i in range(n_subjects) if i != test_idx]\n",
    "        X_train, y_train = [], []\n",
    "        for ds in train_datasets:\n",
    "            for d in ds.datasets:\n",
    "                X_train.append(d.windows)\n",
    "                y_train.append(d.y)\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "        # Split into train/validation\n",
    "        X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=val_ratio, stratify=y_train, random_state=42\n",
    "        )\n",
    "\n",
    "        train_tensor = TensorDataset(torch.tensor(X_tr, dtype=torch.float32),\n",
    "                                     torch.tensor(y_tr, dtype=torch.long))\n",
    "        val_tensor = TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                                   torch.tensor(y_val, dtype=torch.long))\n",
    "\n",
    "        # Fresh model copy\n",
    "        model = deepcopy(base_model)\n",
    "\n",
    "        # EEG classifier setup\n",
    "        clf = EEGClassifier(\n",
    "            model,\n",
    "            criterion=torch.nn.CrossEntropyLoss,\n",
    "            optimizer=torch.optim.AdamW,\n",
    "            optimizer__lr=0.02,\n",
    "            optimizer__weight_decay=0.0005,\n",
    "            batch_size=batch_size,\n",
    "            train_split=predefined_split(val_tensor),\n",
    "            callbacks=[(\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=n_epochs-1))],\n",
    "            device=device,\n",
    "            iterator_train__shuffle=True\n",
    "        )\n",
    "\n",
    "        # ---- Train all epochs ----\n",
    "        clf.fit(train_tensor, y=None, epochs=n_epochs)\n",
    "\n",
    "        # ---- Evaluate on validation ----\n",
    "        val_loader = DataLoader(val_tensor, batch_size=batch_size, shuffle=False)\n",
    "        clf.module_.eval()\n",
    "        val_preds, val_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                out = clf.module_(Xb.to(device))\n",
    "                val_preds.extend(out.argmax(1).cpu().numpy())\n",
    "                val_true.extend(yb.numpy())\n",
    "\n",
    "        val_acc = accuracy_score(val_true, val_preds)\n",
    "        val_kappa = cohen_kappa_score(val_true, val_preds)\n",
    "\n",
    "        all_val_acc.append(val_acc)\n",
    "        all_val_kappa.append(val_kappa)\n",
    "\n",
    "        print(f\"âœ… Val Accuracy: {val_acc:.3f} | Val Îºappa: {val_kappa:.3f}\")\n",
    "\n",
    "    # ---- Final Summary ----\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"CROSS-SUBJECT VALIDATION SUMMARY\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    print(f\"Mean Val Accuracy : {np.mean(all_val_acc):.3f} Â± {np.std(all_val_acc):.3f}\")\n",
    "    print(f\"Mean Val Kappa    : {np.mean(all_val_kappa):.3f} Â± {np.std(all_val_kappa):.3f}\")\n",
    "    print(f\"{'='*60}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d5d5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== CROSS-SUBJECT VALIDATION ====================\n",
      "\n",
      "\n",
      "ðŸ§© Subject 1/10\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.8332\u001b[0m       \u001b[32m0.5053\u001b[0m        \u001b[35m0.7117\u001b[0m  0.0200  21.0073\n",
      "      2        \u001b[36m0.7058\u001b[0m       0.5008        \u001b[35m0.6973\u001b[0m  0.0199  20.9949\n",
      "      3        \u001b[36m0.7033\u001b[0m       \u001b[32m0.5069\u001b[0m        0.6999  0.0197  29.5304\n",
      "      4        \u001b[36m0.7030\u001b[0m       \u001b[32m0.5274\u001b[0m        0.6992  0.0192  37.6693\n",
      "      5        0.7050       \u001b[32m0.5323\u001b[0m        \u001b[35m0.6892\u001b[0m  0.0187  20.5372\n",
      "      6        0.7079       0.5159        \u001b[35m0.6884\u001b[0m  0.0179  40.0745\n",
      "      7        0.7044       0.5180        0.6962  0.0171  41.2592\n",
      "      8        \u001b[36m0.7000\u001b[0m       \u001b[32m0.5429\u001b[0m        0.6919  0.0161  42.7927\n",
      "      9        0.7026       \u001b[32m0.5723\u001b[0m        \u001b[35m0.6805\u001b[0m  0.0150  42.7690\n",
      "     10        \u001b[36m0.6845\u001b[0m       0.5000        0.7803  0.0138  42.4759\n",
      "     11        \u001b[36m0.6428\u001b[0m       \u001b[32m0.6618\u001b[0m        \u001b[35m0.6076\u001b[0m  0.0126  42.5840\n",
      "     12        \u001b[36m0.6118\u001b[0m       0.6013        0.7287  0.0113  41.3458\n",
      "     13        \u001b[36m0.5925\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m0.5581\u001b[0m  0.0100  41.2585\n",
      "     14        \u001b[36m0.5553\u001b[0m       \u001b[32m0.7353\u001b[0m        \u001b[35m0.5268\u001b[0m  0.0087  41.2901\n",
      "     15        \u001b[36m0.5291\u001b[0m       \u001b[32m0.7545\u001b[0m        \u001b[35m0.5127\u001b[0m  0.0074  41.2530\n",
      "     16        \u001b[36m0.5159\u001b[0m       \u001b[32m0.7586\u001b[0m        \u001b[35m0.5105\u001b[0m  0.0062  41.3639\n",
      "     17        \u001b[36m0.5007\u001b[0m       \u001b[32m0.7655\u001b[0m        \u001b[35m0.4907\u001b[0m  0.0050  35.2218\n",
      "     18        \u001b[36m0.4860\u001b[0m       \u001b[32m0.7827\u001b[0m        \u001b[35m0.4633\u001b[0m  0.0039  19.6982\n",
      "     19        \u001b[36m0.4759\u001b[0m       \u001b[32m0.7851\u001b[0m        \u001b[35m0.4619\u001b[0m  0.0029  20.7046\n",
      "     20        \u001b[36m0.4623\u001b[0m       \u001b[32m0.7872\u001b[0m        \u001b[35m0.4527\u001b[0m  0.0021  20.7794\n",
      "     21        \u001b[36m0.4549\u001b[0m       \u001b[32m0.7888\u001b[0m        0.4556  0.0013  20.7315\n",
      "     22        \u001b[36m0.4538\u001b[0m       \u001b[32m0.7929\u001b[0m        \u001b[35m0.4525\u001b[0m  0.0008  20.7318\n",
      "     23        \u001b[36m0.4450\u001b[0m       \u001b[32m0.7966\u001b[0m        \u001b[35m0.4416\u001b[0m  0.0003  20.6722\n",
      "     24        \u001b[36m0.4402\u001b[0m       0.7949        \u001b[35m0.4374\u001b[0m  0.0001  20.7117\n",
      "     25        \u001b[36m0.4389\u001b[0m       \u001b[32m0.7970\u001b[0m        0.4401  0.0000  19.0260\n",
      "âœ… Val Accuracy: 0.797 | Val Îºappa: 0.594\n",
      "\n",
      "ðŸ§© Subject 2/10\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.7817\u001b[0m       \u001b[32m0.5147\u001b[0m        \u001b[35m0.7394\u001b[0m  0.0200  19.1204\n",
      "      2        \u001b[36m0.7119\u001b[0m       0.5012        \u001b[35m0.7138\u001b[0m  0.0199  23.4890\n",
      "      3        \u001b[36m0.7064\u001b[0m       0.4996        0.7226  0.0197  45.8018\n",
      "      4        0.7067       0.4992        \u001b[35m0.6950\u001b[0m  0.0192  38.8735\n",
      "      5        0.7074       \u001b[32m0.5453\u001b[0m        \u001b[35m0.6882\u001b[0m  0.0187  32.8273\n",
      "      6        0.7078       0.5172        0.6976  0.0179  19.5515\n",
      "      7        0.7087       0.5110        0.6970  0.0171  20.9427\n",
      "      8        0.7079       0.5000        0.7295  0.0161  19.4239\n",
      "      9        \u001b[36m0.7043\u001b[0m       0.5437        \u001b[35m0.6865\u001b[0m  0.0150  19.4472\n",
      "âœ… Val Accuracy: 0.534 | Val Îºappa: 0.069\n",
      "\n",
      "ðŸ§© Subject 3/10\n"
     ]
    }
   ],
   "source": [
    "training_cross_subject_adaptive_val(windows_datasets_list, model, n_epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8590e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
