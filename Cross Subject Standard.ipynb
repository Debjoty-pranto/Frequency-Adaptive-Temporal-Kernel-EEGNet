{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from mne.decoding import CSP\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, LeaveOneGroupOut, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False                    # global variable to suppress output display of MNE functions\n",
    "mne.set_log_level(verbose=verbose) # to suppress large info outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = None  # for multicore parallel processing, set it to 1 if cause memory issues, for full utilization set to -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Conversion to MNE Datatypes\n",
    "[Mike Cohen Tutorials link for EEG Preprocessing](https://www.youtube.com/watch?v=uWB5tjhataY&list=PLn0OLiymPak2gDD-VDA90w9_iGDgOOb2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = globals()['_dh'][0]  # a hack to get path of current folder in which jupyter file is located\n",
    "data_path = os.path.join(current_folder, r'C:\\Users\\User\\Documents\\GitHub\\Frequency-Adaptive-Temporal-Kernel-EEGNet\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_files   = glob.glob(data_path + '/*T.mat')\n",
    "len(training_files)     # if  return zero,then no file is loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Append Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mne_epochs_complete(files_paths, verbose=verbose, t_start=2, fs=512, mode='train'):\n",
    "    '''\n",
    "    similar to get_mne_epochs, just appends data from all relevant files together to give a single\n",
    "    epoch object\n",
    "    '''\n",
    "    eeg_data = []\n",
    "    for filepath in files_paths:\n",
    "        mat_data = loadmat(filepath)\n",
    "        eeg_data.extend(mat_data['RawEEGData'])\n",
    "\n",
    "    idx_start = fs*t_start      # fs*ts\n",
    "    eeg_data = np.array(eeg_data)\n",
    "    eeg_data = eeg_data[:, :, idx_start:]\n",
    "    event_id = {'left-hand': 0, 'right-hand': 1} # pytorch expects labels in [0, n_classes-1]\n",
    "    channel_names = ['F3', 'FC3', 'C3', 'CP3', 'P3', 'FCz', 'CPz', 'F4', 'FC4', 'C4', 'CP4', 'P4']\n",
    "    info = mne.create_info(ch_names=channel_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, verbose=verbose, tmin=t_start-3.0)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None) # required be ICA, (7-30 Hz) later\n",
    "    epochs.apply_baseline(baseline=(-.250, 0)) # linear baseline correction\n",
    "    \n",
    "    if mode == 'train': # this in only applicable for training data\n",
    "        labels = []\n",
    "        for filepath in files_paths:\n",
    "            mat_data = loadmat(filepath)\n",
    "            labels.extend(mat_data['Labels'].ravel() - 1)\n",
    "        epochs.event_id = event_id\n",
    "        epochs.events[:,2] = labels    \n",
    "    return epochs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading with Band Pass Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading relevant files\n",
    "training_epochs_all = get_mne_epochs_complete(training_files).filter(7,32) # for all training subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG Data:  (800, 12, 3072) \t Shape of Labels:  (800,)\n"
     ]
    }
   ],
   "source": [
    "epochs = training_epochs_all.copy()\n",
    "data, labels = epochs.get_data(), epochs.events[:,-1]\n",
    "print('Shape of EEG Data: ', data.shape, '\\t Shape of Labels: ', labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Braindecode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's Training Time with [0.5, 4.5] sec and 2sec window with 1 sec stride (using leave one group out cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = training_epochs_all.copy()\n",
    "epochs = epochs.crop(tmin=0.5, tmax=4.5, include_tmax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil import create_from_mne_epochs\n",
    "\n",
    "# convert epochs to braindecode compatible datastructure \n",
    "# 2sec windows with 0.125 sec stride\n",
    "window_size = 1024 #1024 #1024 #50 # 3072\n",
    "window_stride = 512 #512 #256 # 50\n",
    "\n",
    "windows_datasets = create_from_mne_epochs(\n",
    "            [epochs], # expects list of epochs\n",
    "            window_size_samples = window_size,\n",
    "            window_stride_samples = window_stride,\n",
    "            drop_last_window = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows_datasets_labels(windows_dataset):\n",
    "    labels = []\n",
    "    for i in range(len(windows_dataset.datasets)):\n",
    "        labels.extend(windows_dataset.datasets[i].y)\n",
    "    return np.array(labels) \n",
    "\n",
    "windows_datasets.update_description = pd.DataFrame(data=get_windows_datasets_labels(windows_datasets), \n",
    "                                           columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Windows in a whole Dataset:  2400\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Windows in a whole Dataset: \", len(windows_datasets.update_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<braindecode.datasets.base.BaseConcatDataset at 0x1c072a28500>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from braindecode.preprocessing import exponential_moving_standardize\n",
    "from braindecode.preprocessing import Preprocessor, preprocess\n",
    "\n",
    "low_cut_hz = 8.  # low cut frequency for filtering\n",
    "high_cut_hz = 32.  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "# FIXED: Function receives numpy array, not epochs object\n",
    "def custom_exp_moving_std_fn(data, factor_new=factor_new, init_block_size=init_block_size):\n",
    "    \"\"\"\n",
    "    Apply exponential moving standardization to each trial.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Shape (n_epochs, n_channels, n_times) or (n_channels, n_times)\n",
    "    \"\"\"\n",
    "    # Handle both 2D and 3D arrays\n",
    "    if data.ndim == 3:\n",
    "        # For windowed data: (n_epochs, n_channels, n_times)\n",
    "        for i in range(len(data)):\n",
    "            data[i] = exponential_moving_standardize(\n",
    "                data[i], \n",
    "                factor_new=factor_new, \n",
    "                init_block_size=init_block_size\n",
    "            )\n",
    "    else:\n",
    "        # For continuous data: (n_channels, n_times)\n",
    "        data = exponential_moving_standardize(\n",
    "            data, \n",
    "            factor_new=factor_new, \n",
    "            init_block_size=init_block_size\n",
    "        )\n",
    "    return data\n",
    "\n",
    "preprocessors = [\n",
    "    # keep only EEG sensors\n",
    "    Preprocessor(fn='pick_types', eeg=True, meg=False, stim=False),\n",
    "    # bandpass filter\n",
    "    Preprocessor(fn='filter', l_freq=low_cut_hz, h_freq=high_cut_hz),\n",
    "    # exponential moving standardization\n",
    "    Preprocessor(fn=custom_exp_moving_std_fn, factor_new=factor_new,\n",
    "        init_block_size=init_block_size)\n",
    "]\n",
    "\n",
    "# Apply preprocessing\n",
    "preprocess(windows_datasets, preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess(windows_datasets, preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #64\n",
    "n_epochs = 25 #25 #25 #25 #25 #20 #25 use few epochs for quick verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, EEGNetv4\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes = 2\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_chans = windows_datasets[0][0].shape[0]\n",
    "input_window_samples = windows_datasets[0][0].shape[1]\n",
    "\n",
    "model = EEGNetv4(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    n_times=input_window_samples,  # Changed from input_window_samples= to n_times=\n",
    "    final_conv_length='auto',\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = LeaveOneGroupOut()\n",
    "# group parameter for leave one group out cross validation in sklearn, each subject is given unique identifier\n",
    "group_list = []\n",
    "for subject in np.linspace(1,8,8):\n",
    "    group_list.extend([subject for _ in range(len(windows_datasets)//8)]) #since total 8 subjects\n",
    "groups = np.array(group_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time\n",
    "import skorch\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "lr = 1 * 0.02  # 0.01 \n",
    "weight_decay = 0.5 * 0.001\n",
    "\n",
    "# Option 1: Simple validation split (recommended for most cases)\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=skorch.dataset.ValidSplit(cv=5),  # 5-fold validation split\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\", \n",
    "        (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######################### Cross Subject Training: ######################### \n",
      "\n",
      "Found 2 classes: [0 1]\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5005\u001b[0m        \u001b[32m0.7266\u001b[0m       \u001b[35m0.5000\u001b[0m            \u001b[31m0.5000\u001b[0m        \u001b[94m3.1844\u001b[0m  0.0200  1.8979\n",
      "      2            \u001b[36m0.7547\u001b[0m        \u001b[32m0.5908\u001b[0m       \u001b[35m0.7688\u001b[0m            \u001b[31m0.7688\u001b[0m        \u001b[94m0.5207\u001b[0m  0.0199  1.7886\n",
      "      3            0.7354        \u001b[32m0.5639\u001b[0m       0.7063            0.7063        0.7900  0.0197  1.8100\n",
      "      4            0.5156        0.5754       0.5104            0.5104        2.0035  0.0192  1.7825\n",
      "      5            \u001b[36m0.7562\u001b[0m        \u001b[32m0.5269\u001b[0m       0.7583            0.7583        \u001b[94m0.4736\u001b[0m  0.0187  1.7215\n",
      "      6            0.7307        \u001b[32m0.5201\u001b[0m       0.6813            0.6813        0.5607  0.0179  4.4028\n",
      "      7            \u001b[36m0.7922\u001b[0m        0.5357       0.7479            0.7479        0.5227  0.0171  10.6360\n",
      "      8            \u001b[36m0.8042\u001b[0m        \u001b[32m0.5106\u001b[0m       0.7458            0.7458        0.5082  0.0161  10.9632\n",
      "      9            0.7937        \u001b[32m0.5003\u001b[0m       0.7333            0.7333        0.5499  0.0150  11.1573\n",
      "     10            \u001b[36m0.8083\u001b[0m        0.5069       0.7562            0.7562        0.5002  0.0138  7.7620\n",
      "     11            0.7839        \u001b[32m0.4625\u001b[0m       0.6958            0.6958        0.5594  0.0126  1.7141\n",
      "     12            0.7510        0.4661       0.7021            0.7021        0.6602  0.0113  1.7132\n",
      "     13            0.6932        \u001b[32m0.4481\u001b[0m       0.6562            0.6562        0.8412  0.0100  1.7326\n",
      "     14            \u001b[36m0.8344\u001b[0m        \u001b[32m0.4408\u001b[0m       0.7562            0.7562        0.5265  0.0087  1.7285\n",
      "     15            0.7396        \u001b[32m0.4316\u001b[0m       0.6792            0.6792        0.6084  0.0074  1.7282\n",
      "     16            \u001b[36m0.8583\u001b[0m        \u001b[32m0.4316\u001b[0m       0.7167            0.7167        0.5156  0.0062  1.7106\n",
      "     17            0.7031        \u001b[32m0.4086\u001b[0m       0.6625            0.6625        0.6953  0.0050  1.7537\n",
      "     18            \u001b[36m0.8797\u001b[0m        \u001b[32m0.3922\u001b[0m       0.7354            0.7354        0.5067  0.0039  1.7594\n",
      "     19            \u001b[36m0.8802\u001b[0m        \u001b[32m0.3912\u001b[0m       0.7292            0.7292        0.5040  0.0029  1.7539\n",
      "     20            0.8370        0.3983       0.7208            0.7208        0.5301  0.0021  1.7313\n",
      "     21            0.8745        \u001b[32m0.3832\u001b[0m       0.7375            0.7375        0.5065  0.0013  1.6935\n",
      "     22            0.8802        \u001b[32m0.3736\u001b[0m       0.7354            0.7354        0.5083  0.0008  1.7328\n",
      "     23            \u001b[36m0.8828\u001b[0m        \u001b[32m0.3569\u001b[0m       0.7375            0.7375        0.5067  0.0003  1.7061\n",
      "     24            \u001b[36m0.8844\u001b[0m        0.3721       0.7354            0.7354        0.5062  0.0001  7.5188\n",
      "     25            0.8844        \u001b[32m0.3470\u001b[0m       0.7354            0.7354        0.5062  0.0000  1.9693\n",
      "Best Cross Validation Kappa Score: 0.77\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>&lt;class &#x27;braindecode.classifier.EEGClassifier&#x27;&gt;[initialized](\n",
       "  module_=================================================================================================================================================================\n",
       "  Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "  ================================================================================================================================================================\n",
       "  EEGNetv4 (EEGNetv4)                                          [1, 12, 1024]             [1, 2]                    --                        --\n",
       "  ├─Ensure4d (ensuredims): 1-1                                 [1, 12, 1024]             [1, 12, 1024, 1]          --                        --\n",
       "  ├─Rearrange (dimshuffle): 1-2                                [1, 12, 1024, 1]          [1, 1, 12, 1024]          --                        --\n",
       "  ├─Conv2d (conv_temporal): 1-3                                [1, 1, 12, 1024]          [1, 8, 12, 1025]          512                       [1, 64]\n",
       "  ├─BatchNorm2d (bnorm_temporal): 1-4                          [1, 8, 12, 1025]          [1, 8, 12, 1025]          16                        --\n",
       "  ├─ParametrizedConv2dWithConstraint (conv_spatial): 1-5       [1, 8, 12, 1025]          [1, 16, 1, 1025]          --                        [12, 1]\n",
       "  │    └─ModuleDict (parametrizations): 2-1                    --                        --                        --                        --\n",
       "  │    │    └─ParametrizationList (weight): 3-1                --                        [16, 1, 12, 1]            192                       --\n",
       "  ├─BatchNorm2d (bnorm_1): 1-6                                 [1, 16, 1, 1025]          [1, 16, 1, 1025]          32                        --\n",
       "  ├─ELU (elu_1): 1-7                                           [1, 16, 1, 1025]          [1, 16, 1, 1025]          --                        --\n",
       "  ├─AvgPool2d (pool_1): 1-8                                    [1, 16, 1, 1025]          [1, 16, 1, 256]           --                        [1, 4]\n",
       "  ├─Dropout (drop_1): 1-9                                      [1, 16, 1, 256]           [1, 16, 1, 256]           --                        --\n",
       "  ├─Conv2d (conv_separable_depth): 1-10                        [1, 16, 1, 256]           [1, 16, 1, 257]           256                       [1, 16]\n",
       "  ├─Conv2d (conv_separable_point): 1-11                        [1, 16, 1, 257]           [1, 16, 1, 257]           256                       [1, 1]\n",
       "  ├─BatchNorm2d (bnorm_2): 1-12                                [1, 16, 1, 257]           [1, 16, 1, 257]           32                        --\n",
       "  ├─ELU (elu_2): 1-13                                          [1, 16, 1, 257]           [1, 16, 1, 257]           --                        --\n",
       "  ├─AvgPool2d (pool_2): 1-14                                   [1, 16, 1, 257]           [1, 16, 1, 32]            --                        [1, 8]\n",
       "  ├─Dropout (drop_2): 1-15                                     [1, 16, 1, 32]            [1, 16, 1, 32]            --                        --\n",
       "  ├─Sequential (final_layer): 1-16                             [1, 16, 1, 32]            [1, 2]                    --                        --\n",
       "  │    └─Conv2d (conv_classifier): 2-2                         [1, 16, 1, 32]            [1, 2, 1, 1]              1,026                     [1, 32]\n",
       "  │    └─Rearrange (permute_back): 2-3                         [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
       "  │    └─SqueezeFinalOutput (squeeze): 2-4                     [1, 2, 1, 1]              [1, 2]                    --                        --\n",
       "  │    │    └─Rearrange (squeeze): 3-2                         [1, 2, 1, 1]              [1, 2, 1]                 --                        --\n",
       "  ================================================================================================================================================================\n",
       "  Total params: 2,322\n",
       "  Trainable params: 2,322\n",
       "  Non-trainable params: 0\n",
       "  Total mult-adds (Units.MEGABYTES): 6.43\n",
       "  ================================================================================================================================================================\n",
       "  Input size (MB): 0.05\n",
       "  Forward/backward pass size (MB): 1.80\n",
       "  Params size (MB): 0.01\n",
       "  Estimated Total Size (MB): 1.86\n",
       "  ================================================================================================================================================================,\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;EEGClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>&lt;class &#x27;braindecode.classifier.EEGClassifier&#x27;&gt;[initialized](\n",
       "  module_=================================================================================================================================================================\n",
       "  Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "  ================================================================================================================================================================\n",
       "  EEGNetv4 (EEGNetv4)                                          [1, 12, 1024]             [1, 2]                    --                        --\n",
       "  ├─Ensure4d (ensuredims): 1-1                                 [1, 12, 1024]             [1, 12, 1024, 1]          --                        --\n",
       "  ├─Rearrange (dimshuffle): 1-2                                [1, 12, 1024, 1]          [1, 1, 12, 1024]          --                        --\n",
       "  ├─Conv2d (conv_temporal): 1-3                                [1, 1, 12, 1024]          [1, 8, 12, 1025]          512                       [1, 64]\n",
       "  ├─BatchNorm2d (bnorm_temporal): 1-4                          [1, 8, 12, 1025]          [1, 8, 12, 1025]          16                        --\n",
       "  ├─ParametrizedConv2dWithConstraint (conv_spatial): 1-5       [1, 8, 12, 1025]          [1, 16, 1, 1025]          --                        [12, 1]\n",
       "  │    └─ModuleDict (parametrizations): 2-1                    --                        --                        --                        --\n",
       "  │    │    └─ParametrizationList (weight): 3-1                --                        [16, 1, 12, 1]            192                       --\n",
       "  ├─BatchNorm2d (bnorm_1): 1-6                                 [1, 16, 1, 1025]          [1, 16, 1, 1025]          32                        --\n",
       "  ├─ELU (elu_1): 1-7                                           [1, 16, 1, 1025]          [1, 16, 1, 1025]          --                        --\n",
       "  ├─AvgPool2d (pool_1): 1-8                                    [1, 16, 1, 1025]          [1, 16, 1, 256]           --                        [1, 4]\n",
       "  ├─Dropout (drop_1): 1-9                                      [1, 16, 1, 256]           [1, 16, 1, 256]           --                        --\n",
       "  ├─Conv2d (conv_separable_depth): 1-10                        [1, 16, 1, 256]           [1, 16, 1, 257]           256                       [1, 16]\n",
       "  ├─Conv2d (conv_separable_point): 1-11                        [1, 16, 1, 257]           [1, 16, 1, 257]           256                       [1, 1]\n",
       "  ├─BatchNorm2d (bnorm_2): 1-12                                [1, 16, 1, 257]           [1, 16, 1, 257]           32                        --\n",
       "  ├─ELU (elu_2): 1-13                                          [1, 16, 1, 257]           [1, 16, 1, 257]           --                        --\n",
       "  ├─AvgPool2d (pool_2): 1-14                                   [1, 16, 1, 257]           [1, 16, 1, 32]            --                        [1, 8]\n",
       "  ├─Dropout (drop_2): 1-15                                     [1, 16, 1, 32]            [1, 16, 1, 32]            --                        --\n",
       "  ├─Sequential (final_layer): 1-16                             [1, 16, 1, 32]            [1, 2]                    --                        --\n",
       "  │    └─Conv2d (conv_classifier): 2-2                         [1, 16, 1, 32]            [1, 2, 1, 1]              1,026                     [1, 32]\n",
       "  │    └─Rearrange (permute_back): 2-3                         [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
       "  │    └─SqueezeFinalOutput (squeeze): 2-4                     [1, 2, 1, 1]              [1, 2]                    --                        --\n",
       "  │    │    └─Rearrange (squeeze): 3-2                         [1, 2, 1, 1]              [1, 2, 1]                 --                        --\n",
       "  ================================================================================================================================================================\n",
       "  Total params: 2,322\n",
       "  Trainable params: 2,322\n",
       "  Non-trainable params: 0\n",
       "  Total mult-adds (Units.MEGABYTES): 6.43\n",
       "  ================================================================================================================================================================\n",
       "  Input size (MB): 0.05\n",
       "  Forward/backward pass size (MB): 1.80\n",
       "  Params size (MB): 0.01\n",
       "  Estimated Total Size (MB): 1.86\n",
       "  ================================================================================================================================================================,\n",
       ")</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
       "  module_=================================================================================================================================================================\n",
       "  Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "  ================================================================================================================================================================\n",
       "  EEGNetv4 (EEGNetv4)                                          [1, 12, 1024]             [1, 2]                    --                        --\n",
       "  ├─Ensure4d (ensuredims): 1-1                                 [1, 12, 1024]             [1, 12, 1024, 1]          --                        --\n",
       "  ├─Rearrange (dimshuffle): 1-2                                [1, 12, 1024, 1]          [1, 1, 12, 1024]          --                        --\n",
       "  ├─Conv2d (conv_temporal): 1-3                                [1, 1, 12, 1024]          [1, 8, 12, 1025]          512                       [1, 64]\n",
       "  ├─BatchNorm2d (bnorm_temporal): 1-4                          [1, 8, 12, 1025]          [1, 8, 12, 1025]          16                        --\n",
       "  ├─ParametrizedConv2dWithConstraint (conv_spatial): 1-5       [1, 8, 12, 1025]          [1, 16, 1, 1025]          --                        [12, 1]\n",
       "  │    └─ModuleDict (parametrizations): 2-1                    --                        --                        --                        --\n",
       "  │    │    └─ParametrizationList (weight): 3-1                --                        [16, 1, 12, 1]            192                       --\n",
       "  ├─BatchNorm2d (bnorm_1): 1-6                                 [1, 16, 1, 1025]          [1, 16, 1, 1025]          32                        --\n",
       "  ├─ELU (elu_1): 1-7                                           [1, 16, 1, 1025]          [1, 16, 1, 1025]          --                        --\n",
       "  ├─AvgPool2d (pool_1): 1-8                                    [1, 16, 1, 1025]          [1, 16, 1, 256]           --                        [1, 4]\n",
       "  ├─Dropout (drop_1): 1-9                                      [1, 16, 1, 256]           [1, 16, 1, 256]           --                        --\n",
       "  ├─Conv2d (conv_separable_depth): 1-10                        [1, 16, 1, 256]           [1, 16, 1, 257]           256                       [1, 16]\n",
       "  ├─Conv2d (conv_separable_point): 1-11                        [1, 16, 1, 257]           [1, 16, 1, 257]           256                       [1, 1]\n",
       "  ├─BatchNorm2d (bnorm_2): 1-12                                [1, 16, 1, 257]           [1, 16, 1, 257]           32                        --\n",
       "  ├─ELU (elu_2): 1-13                                          [1, 16, 1, 257]           [1, 16, 1, 257]           --                        --\n",
       "  ├─AvgPool2d (pool_2): 1-14                                   [1, 16, 1, 257]           [1, 16, 1, 32]            --                        [1, 8]\n",
       "  ├─Dropout (drop_2): 1-15                                     [1, 16, 1, 32]            [1, 16, 1, 32]            --                        --\n",
       "  ├─Sequential (final_layer): 1-16                             [1, 16, 1, 32]            [1, 2]                    --                        --\n",
       "  │    └─Conv2d (conv_classifier): 2-2                         [1, 16, 1, 32]            [1, 2, 1, 1]              1,026                     [1, 32]\n",
       "  │    └─Rearrange (permute_back): 2-3                         [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
       "  │    └─SqueezeFinalOutput (squeeze): 2-4                     [1, 2, 1, 1]              [1, 2]                    --                        --\n",
       "  │    │    └─Rearrange (squeeze): 3-2                         [1, 2, 1, 1]              [1, 2, 1]                 --                        --\n",
       "  ================================================================================================================================================================\n",
       "  Total params: 2,322\n",
       "  Trainable params: 2,322\n",
       "  Non-trainable params: 0\n",
       "  Total mult-adds (Units.MEGABYTES): 6.43\n",
       "  ================================================================================================================================================================\n",
       "  Input size (MB): 0.05\n",
       "  Forward/backward pass size (MB): 1.80\n",
       "  Params size (MB): 0.01\n",
       "  Estimated Total Size (MB): 1.86\n",
       "  ================================================================================================================================================================,\n",
       ")"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def training_function(windows_datasets, n_epochs=25):\n",
    "    print('\\n', '#'*25, 'Cross Subject Training:', '#'*25, '\\n')\n",
    "    dataset = windows_datasets\n",
    "    \n",
    "    # Extract labels from the dataset\n",
    "    # Braindecode datasets store targets in the dataset objects themselves\n",
    "    y = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "    \n",
    "    print(f\"Found {len(np.unique(y))} classes: {np.unique(y)}\")\n",
    "    \n",
    "    clf.fit(dataset, y=y, epochs=n_epochs)\n",
    "    \n",
    "    best_validation_acc = clf.callbacks_[4][1].best_score_  # a hack to get best validation accuracy\n",
    "    best_validation_kappa = (2*best_validation_acc)-1\n",
    "    print(\"Best Cross Validation Kappa Score: {:.2f}\".format(best_validation_kappa))\n",
    "    \n",
    "    return clf\n",
    "\n",
    "# Call the function\n",
    "training_function(windows_datasets, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
