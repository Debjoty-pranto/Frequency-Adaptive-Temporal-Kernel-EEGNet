{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from mne.decoding import CSP\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, LeaveOneGroupOut, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False                    # global variable to suppress output display of MNE functions\n",
    "mne.set_log_level(verbose=verbose) # to suppress large info outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = None  # for multicore parallel processing, set it to 1 if cause memory issues, for full utilization set to -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Conversion to MNE Datatypes\n",
    "[Mike Cohen Tutorials link for EEG Preprocessing](https://www.youtube.com/watch?v=uWB5tjhataY&list=PLn0OLiymPak2gDD-VDA90w9_iGDgOOb2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = globals()['_dh'][0]  # a hack to get path of current folder in which jupyter file is located\n",
    "data_path = os.path.join(current_folder, r'C:\\Users\\User\\Documents\\GitHub\\Frequency-Adaptive-Temporal-Kernel-EEGNet\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_files   = glob.glob(data_path + '/*T.mat')\n",
    "len(training_files)     # if  return zero,then no file is loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Append Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mne_epochs_complete(files_paths, verbose=verbose, t_start=2, fs=512, mode='train'):\n",
    "    '''\n",
    "    similar to get_mne_epochs, just appends data from all relevant files together to give a single\n",
    "    epoch object\n",
    "    '''\n",
    "    eeg_data = []\n",
    "    for filepath in files_paths:\n",
    "        mat_data = loadmat(filepath)\n",
    "        eeg_data.extend(mat_data['RawEEGData'])\n",
    "\n",
    "    idx_start = fs*t_start      # fs*ts\n",
    "    eeg_data = np.array(eeg_data)\n",
    "    eeg_data = eeg_data[:, :, idx_start:]\n",
    "    event_id = {'left-hand': 0, 'right-hand': 1} # pytorch expects labels in [0, n_classes-1]\n",
    "    channel_names = ['F3', 'FC3', 'C3', 'CP3', 'P3', 'FCz', 'CPz', 'F4', 'FC4', 'C4', 'CP4', 'P4']\n",
    "    info = mne.create_info(ch_names=channel_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, verbose=verbose, tmin=t_start-3.0)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None) # required be ICA, (7-30 Hz) later\n",
    "    epochs.apply_baseline(baseline=(-.250, 0)) # linear baseline correction\n",
    "    \n",
    "    if mode == 'train': # this in only applicable for training data\n",
    "        labels = []\n",
    "        for filepath in files_paths:\n",
    "            mat_data = loadmat(filepath)\n",
    "            labels.extend(mat_data['Labels'].ravel() - 1)\n",
    "        epochs.event_id = event_id\n",
    "        epochs.events[:,2] = labels    \n",
    "    return epochs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading with Band Pass Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading relevant files\n",
    "training_epochs_all = get_mne_epochs_complete(training_files).filter(7,32) # for all training subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG Data:  (800, 12, 3072) \t Shape of Labels:  (800,)\n"
     ]
    }
   ],
   "source": [
    "epochs = training_epochs_all.copy()\n",
    "data, labels = epochs.get_data(), epochs.events[:,-1]\n",
    "print('Shape of EEG Data: ', data.shape, '\\t Shape of Labels: ', labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Braindecode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's Training Time with [0.5, 4.5] sec and 2sec window with 1 sec stride (using leave one group out cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = training_epochs_all.copy()\n",
    "epochs = epochs.crop(tmin=0.5, tmax=4.5, include_tmax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil import create_from_mne_epochs\n",
    "\n",
    "# convert epochs to braindecode compatible datastructure \n",
    "# 2sec windows with 0.125 sec stride\n",
    "window_size = 1024 #1024 #1024 #50 # 3072\n",
    "window_stride = 512 #512 #256 # 50\n",
    "\n",
    "windows_datasets = create_from_mne_epochs(\n",
    "            [epochs], # expects list of epochs\n",
    "            window_size_samples = window_size,\n",
    "            window_stride_samples = window_stride,\n",
    "            drop_last_window = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "target_transform must be a callable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 18\u001b[0m\n\u001b[0;32m     12\u001b[0m description_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     13\u001b[0m     data\u001b[38;5;241m=\u001b[39mget_windows_datasets_labels(windows_datasets),\n\u001b[0;32m     14\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Create a new BaseConcatDataset with the updated description\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m windows_datasets \u001b[38;5;241m=\u001b[39m \u001b[43mBaseConcatDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindows_datasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\braindecode\\datasets\\base.py:445\u001b[0m, in \u001b[0;36mBaseConcatDataset.__init__\u001b[1;34m(self, list_of_ds, target_transform)\u001b[0m\n\u001b[0;32m    442\u001b[0m     list_of_ds \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m list_of_ds \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mdatasets]\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(list_of_ds)\n\u001b[1;32m--> 445\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_transform\u001b[49m \u001b[38;5;241m=\u001b[39m target_transform\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\braindecode\\datasets\\base.py:593\u001b[0m, in \u001b[0;36mBaseConcatDataset.target_transform\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;129m@target_transform\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtarget_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mcallable\u001b[39m(fn) \u001b[38;5;129;01mor\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 593\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_transform must be a callable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target_transform \u001b[38;5;241m=\u001b[39m fn\n",
      "\u001b[1;31mTypeError\u001b[0m: target_transform must be a callable."
     ]
    }
   ],
   "source": [
    "from braindecode.datasets import BaseConcatDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_windows_datasets_labels(windows_dataset):\n",
    "    labels = []\n",
    "    for i in range(len(windows_dataset.datasets)):\n",
    "        labels.extend(windows_dataset.datasets[i].y)\n",
    "    return np.array(labels)\n",
    "\n",
    "# Create your new description DataFrame\n",
    "description_df = pd.DataFrame(\n",
    "    data=get_windows_datasets_labels(windows_datasets),\n",
    "    columns=['labels']\n",
    ")\n",
    "\n",
    "# Create a new BaseConcatDataset with the updated description\n",
    "windows_datasets = BaseConcatDataset(windows_datasets.datasets, description_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Windows in a whole Dataset:  1920\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Windows in a whole Dataset: \", len(windows_datasets.description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil.preprocess import exponential_moving_standardize\n",
    "from braindecode.datautil.preprocess import MNEPreproc, NumpyPreproc, preprocess\n",
    "\n",
    "low_cut_hz = 8.  # low cut frequency for filtering\n",
    "high_cut_hz = 32.  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        epochs._data[i] = exponential_moving_standardize(data[i], \n",
    "                        factor_new=factor_new, init_block_size=init_block_size)\n",
    "    return epochs\n",
    "\n",
    "preprocessors = [\n",
    "    # keep only EEG sensors\n",
    "    MNEPreproc(fn='pick_types', eeg=True, meg=False, stim=False),\n",
    "    # bandpass filter\n",
    "    MNEPreproc(fn='filter', l_freq=low_cut_hz, h_freq=high_cut_hz),\n",
    "    # exponential moving standardization\n",
    "    MNEPreproc(fn=custom_exp_moving_std_fn, factor_new=factor_new,\n",
    "        init_block_size=init_block_size)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(windows_datasets, preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #64\n",
    "n_epochs = 25 #25 #25 #25 #25 #20 #25 use few epochs for quick verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, EEGNetv4\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes=2\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_chans = windows_datasets[0][0].shape[0]\n",
    "input_window_samples = windows_datasets[0][0].shape[1]\n",
    "\n",
    "model = EEGNetv4(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    input_window_samples = window_size, #input_window_samples,\n",
    "    final_conv_length='auto',\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = LeaveOneGroupOut()\n",
    "# group parameter for leave one group out cross validation in sklearn, each subject is given unique identifier\n",
    "group_list = []\n",
    "for subject in np.linspace(1,8,8):\n",
    "    group_list.extend([subject for _ in range(len(windows_datasets)//8)]) #since total 8 subjects\n",
    "groups = np.array(group_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "lr = 1 * 0.02 #0.01 \n",
    "weight_decay = 0.5 * 0.001\n",
    "\n",
    "clf =  EEGClassifier(\n",
    "                    model,\n",
    "                    criterion=torch.nn.NLLLoss,\n",
    "                    optimizer=torch.optim.AdamW,\n",
    "                    #iterator_train = StratifiedShuffleSplit(),#cv.split(epochs, y=labels, groups=groups), \n",
    "                    #train_split=predefined_split(train_set),  # using valid_set for validation\n",
    "                    #train_split = cv.split(epochs, y=labels, groups=groups),\n",
    "                    train_split = skorch.dataset.CVSplit(cv=cv.split(windows_datasets, \n",
    "                          y=windows_datasets.description.labels, groups=groups)),\n",
    "                    \n",
    "    \n",
    "                    #= skorch.dataset.CVSplit(cv=LeaveOneGroupOut())),\n",
    "                    optimizer__lr=lr,\n",
    "                    optimizer__weight_decay=weight_decay,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[\n",
    "                        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "                    ],\n",
    "                    device=device,\n",
    "        \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(windows_datasets, n_epochs=25):\n",
    "    print('\\n', '#'*25, 'Cross Subject Training:', '#'*25, '\\n')\n",
    "    dataset = windows_datasets\n",
    "    clf.fit(dataset, y=dataset.description.labels, epochs=n_epochs);\n",
    "    best_validation_acc = clf.callbacks_[4][1].best_score_ # a hack to get best validation accuracy\n",
    "    best_validation_kappa = (2*best_validation_acc)-1\n",
    "    print(\"Best Cross Validation Kappa Score: {:.2f}\".format(best_validation_kappa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######################### Cross Subject Training: ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr      dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  -------\n",
      "      1            \u001b[36m0.7464\u001b[0m        \u001b[32m0.7048\u001b[0m            \u001b[35m0.6792\u001b[0m        \u001b[31m0.7166\u001b[0m  0.0200  13.4470\n",
      "      2            0.7417        \u001b[32m0.5835\u001b[0m            0.6375        1.0621  0.0199  11.6820\n",
      "      3            0.6690        \u001b[32m0.5554\u001b[0m            0.5833        1.4334  0.0197  11.2570\n",
      "      4            \u001b[36m0.7833\u001b[0m        \u001b[32m0.5153\u001b[0m            \u001b[35m0.7083\u001b[0m        \u001b[31m0.5871\u001b[0m  0.0192  13.7350\n",
      "      5            \u001b[36m0.7976\u001b[0m        0.5472            0.6833        0.6751  0.0187  13.5100\n",
      "      6            0.5304        \u001b[32m0.4833\u001b[0m            0.5292        1.1845  0.0179  12.6870\n",
      "      7            0.7173        0.4993            0.6667        0.7118  0.0171  14.0700\n",
      "      8            0.7554        0.4903            \u001b[35m0.7417\u001b[0m        \u001b[31m0.5515\u001b[0m  0.0161  13.0450\n",
      "      9            \u001b[36m0.8321\u001b[0m        \u001b[32m0.4565\u001b[0m            \u001b[35m0.7458\u001b[0m        \u001b[31m0.5326\u001b[0m  0.0150  13.3260\n",
      "     10            0.7173        0.4721            0.6417        0.9983  0.0138  12.2680\n",
      "     11            \u001b[36m0.8375\u001b[0m        0.4767            \u001b[35m0.7708\u001b[0m        \u001b[31m0.4951\u001b[0m  0.0126  11.6770\n",
      "     12            \u001b[36m0.8542\u001b[0m        \u001b[32m0.4221\u001b[0m            0.7667        0.5160  0.0113  12.4400\n",
      "     13            0.7964        \u001b[32m0.3969\u001b[0m            0.7375        0.5653  0.0100  15.0260\n",
      "     14            0.6321        0.4023            0.5667        0.8100  0.0087  15.1436\n",
      "     15            0.8280        \u001b[32m0.3853\u001b[0m            0.7625        0.5356  0.0074  13.0690\n",
      "     16            0.8363        \u001b[32m0.3852\u001b[0m            0.6750        0.7383  0.0062  13.1960\n",
      "     17            \u001b[36m0.8679\u001b[0m        \u001b[32m0.3688\u001b[0m            0.7667        0.5504  0.0050  15.1390\n",
      "     18            0.7500        \u001b[32m0.3602\u001b[0m            0.6792        0.6329  0.0039  14.6470\n",
      "     19            \u001b[36m0.8946\u001b[0m        \u001b[32m0.3339\u001b[0m            0.7583        0.5552  0.0029  14.4310\n",
      "     20            \u001b[36m0.8994\u001b[0m        0.3426            0.7667        0.5394  0.0021  12.0300\n",
      "     21            0.8881        \u001b[32m0.3272\u001b[0m            0.7625        0.5293  0.0013  12.7590\n",
      "     22            \u001b[36m0.9071\u001b[0m        \u001b[32m0.3141\u001b[0m            0.7625        0.5506  0.0008  13.1850\n",
      "     23            \u001b[36m0.9095\u001b[0m        \u001b[32m0.3046\u001b[0m            0.7583        0.5559  0.0003  13.7220\n",
      "     24            \u001b[36m0.9101\u001b[0m        0.3074            0.7583        0.5602  0.0001  13.7420\n",
      "     25            \u001b[36m0.9107\u001b[0m        0.3077            0.7542        0.5636  0.0000  13.6310\n",
      "Best Cross Validation Kappa Score: 0.54\n"
     ]
    }
   ],
   "source": [
    "training_function(windows_datasets, n_epochs=n_epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
