{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from mne.decoding import CSP\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False                    # global variable to suppress output display of MNE functions\n",
    "mne.set_log_level(verbose=verbose) # to suppress large info outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = None  # for multicore parallel processing, set it to 1 if cause memory issues, for full utilization set to -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Conversion to MNE Datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = globals()['_dh'][0]  # a hack to get path of current folder in which jupyter file is located\n",
    "data_path = os.path.join(current_folder, r\"C:\\Users\\MILAKUL\\Documents\\Thesis\\clinicalBCI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_files   = glob.glob(data_path + '/*T.mat')\n",
    "len(training_files)     # if  return zero,then no file is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mne_epochs(filepath, verbose=verbose, t_start=2, fs=512, mode='train'):\n",
    "    '''\n",
    "    This function reads the EEG data from .mat file and convert it to MNE-Python Compatible epochs\n",
    "    data structure. It takes data from [0, 8] sec range and return it by setting t = 0 at cue onset\n",
    "    i.e. 3 seconds and dropping first two seconds so the output data is in [-1.0, 5.0] sec range. The\n",
    "    Details can be found in the preprocessing section of the attached document\n",
    "    '''\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    eeg_data= mat_data['RawEEGData']\n",
    "    idx_start = fs*t_start      \n",
    "    eeg_data = eeg_data[:, :, idx_start:]\n",
    "    event_id = {'left-hand': 0, 'right-hand': 1} # pytorch expects labels in [0, n_classes-1]\n",
    "    channel_names = ['F3', 'FC3', 'C3', 'CP3', 'P3', 'FCz', 'CPz', 'F4', 'FC4', 'C4', 'CP4', 'P4']\n",
    "    info = mne.create_info(ch_names=channel_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, verbose=verbose, tmin=t_start-3.0)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None) \n",
    "    epochs.apply_baseline(baseline=(-.250, 0)) # linear baseline correction\n",
    "    \n",
    "    if mode == 'train': # this in only applicable for training data\n",
    "        epochs.event_id = event_id \n",
    "        epochs.events[:,2] = mat_data['Labels'].ravel() - 1    \n",
    "    return epochs \n",
    "\n",
    "def get_labels(filepath):\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    return mat_data['Labels'].ravel() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG Data:  (80, 12, 3072) \t Shape of Labels:  (80,)\n"
     ]
    }
   ],
   "source": [
    "epochs, labels = get_mne_epochs(training_files[0], verbose=verbose), get_labels(training_files[0])\n",
    "data = epochs.get_data()\n",
    "print('Shape of EEG Data: ', data.shape, '\\t Shape of Labels: ', labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading original data\n",
    "epochs_list_train = []\n",
    "for i in training_files:\n",
    "    epochs_list_train.append(get_mne_epochs(i, verbose=verbose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Braindecode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's Training Time with [0.5, 4.5] sec and 2sec window with 125ms stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets: 8\n",
      "Total windows per subject: 1360\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datautil import create_from_mne_epochs\n",
    "\n",
    "window_size = 1024   # 2 sec windows\n",
    "window_stride = 64   # 125 ms stride\n",
    "\n",
    "windows_datasets_list = []\n",
    "\n",
    "for epoch in epochs_list_train:\n",
    "    # Create windows per subject\n",
    "    windows_dataset = create_from_mne_epochs(\n",
    "        [epoch.crop(tmin=0.5, tmax=4.5, include_tmax=False)],\n",
    "        window_size_samples=window_size,\n",
    "        window_stride_samples=window_stride,\n",
    "        drop_last_window=False\n",
    "    )\n",
    "    # Add labels as a separate attribute\n",
    "    windows_dataset.update_description = pd.DataFrame(\n",
    "        data=np.concatenate([d.y for d in windows_dataset.datasets]),\n",
    "        columns=['labels']\n",
    "    )\n",
    "    windows_datasets_list.append(windows_dataset)\n",
    "\n",
    "print(\"Datasets:\", len(windows_datasets_list))\n",
    "print(\"Total windows per subject:\", len(windows_datasets_list[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.preprocessing import exponential_moving_standardize\n",
    "\n",
    "low_cut_hz = 8.   # low cut frequency for filtering\n",
    "high_cut_hz = 32. # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\n",
    "    \"\"\"Apply exponential moving standardization to MNE epochs inplace.\"\"\"\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        data[i] = exponential_moving_standardize(\n",
    "            data[i], factor_new=factor_new, init_block_size=init_block_size\n",
    "        )\n",
    "    epochs._data = data\n",
    "    return epochs\n",
    "\n",
    "# Apply preprocessing to each dataset\n",
    "for windows_dataset in windows_datasets_list:\n",
    "    # Extract the underlying MNE Epochs object\n",
    "    epochs = windows_dataset.datasets[0].windows\n",
    "    epochs.load_data()  # Ensure data is loaded into memory\n",
    "\n",
    "    # 1) Keep only EEG channels\n",
    "    epochs.pick_types(eeg=True)\n",
    "\n",
    "    # 2) Bandpass filter\n",
    "    epochs.filter(l_freq=low_cut_hz, h_freq=high_cut_hz)\n",
    "\n",
    "    # 3) Exponential moving standardization\n",
    "    custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #64\n",
    "n_epochs = 25 #25 #20 #25 use few epochs for quick verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from Frequency_Adaptive_model import AdaptiveEEGNet  \n",
    "\n",
    "cuda = torch.cuda.is_available()  \n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "# Deterministic training setup \n",
    "torch.backends.cudnn.deterministic = True \n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Model hyperparameters\n",
    "\n",
    "n_classes = 2\n",
    "n_chans = windows_datasets_list[0][0][0].shape[0]      # EEG channels\n",
    "input_window_samples = windows_datasets_list[0][0][0].shape[1]  # time samples\n",
    "\n",
    "# Instantiate AdaptiveEEGNet\n",
    "model = AdaptiveEEGNet(\n",
    "    nb_classes=n_classes,\n",
    "    Chans=n_chans,\n",
    "    Samples=input_window_samples,\n",
    "    kernLength=128,\n",
    "    F1=16,\n",
    "    D=2,\n",
    "    F2=32,\n",
    "    dropoutRate=0.3,\n",
    "    sample_rate=512\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "import numpy as np\n",
    "\n",
    "def training_within_subject_adaptive(windows_datasets_list, model_class, n_epochs=25, batch_size=32, val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Trains AdaptiveEEGNet model separately for each subject (within-subject classification).\n",
    "    Reports best validation accuracy per subject and mean accuracy across all subjects.\n",
    "    \"\"\"\n",
    "    all_subject_acc = []\n",
    "\n",
    "    for subj_idx, subj_data in enumerate(windows_datasets_list):\n",
    "        print(f\"\\n=== Subject {subj_idx+1}/{len(windows_datasets_list)} ===\")\n",
    "\n",
    "        # Gather data\n",
    "        X = np.concatenate([ds.windows for ds in subj_data.datasets], axis=0)\n",
    "        y = np.concatenate([ds.y for ds in subj_data.datasets], axis=0)\n",
    "\n",
    "        # Split train/validation\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=val_ratio, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        # Convert to tensors\n",
    "        train_tensor = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "        val_tensor   = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "\n",
    "        # Create a fresh model for each subject\n",
    "        n_chans = X.shape[1]\n",
    "        input_window_samples = X.shape[2]\n",
    "        n_classes = len(np.unique(y))\n",
    "\n",
    "        model = model_class(\n",
    "            nb_classes=n_classes,\n",
    "            Chans=n_chans,\n",
    "            Samples=input_window_samples,\n",
    "            kernLength=128,\n",
    "            F1=16,\n",
    "            D=2,\n",
    "            F2=32,\n",
    "            dropoutRate=0.3,\n",
    "            sample_rate=512\n",
    "        )\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            model.cuda()\n",
    "            device = 'cuda'\n",
    "        else:\n",
    "            device = 'cpu'\n",
    "\n",
    "        # Create classifier\n",
    "        clf = EEGClassifier(\n",
    "            model,\n",
    "            criterion=torch.nn.CrossEntropyLoss,\n",
    "            optimizer=torch.optim.AdamW,\n",
    "            optimizer__lr=0.02,\n",
    "            optimizer__weight_decay=0.0005,\n",
    "            batch_size=batch_size,\n",
    "            train_split=predefined_split(val_tensor),  # validation data\n",
    "            callbacks=[(\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=n_epochs-1))],\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        clf.fit(train_tensor, y=y_train, epochs=n_epochs)\n",
    "\n",
    "        # Retrieve best validation accuracy\n",
    "        for name, cb in clf.callbacks_:\n",
    "            if name == \"valid_acc\":\n",
    "                best_val_acc = cb.best_score_\n",
    "                break\n",
    "\n",
    "        print(f\"Best Validation Accuracy for Subject {subj_idx+1}: {best_val_acc:.3f}\")\n",
    "        all_subject_acc.append(best_val_acc)\n",
    "\n",
    "    mean_acc = np.mean(all_subject_acc)\n",
    "    print(\"\\n=== Mean Within-Subject Accuracy: {:.3f} ===\".format(mean_acc))\n",
    "    return all_subject_acc, mean_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Subject 1/8 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.8479\u001b[0m       \u001b[32m0.4853\u001b[0m        \u001b[35m2.0142\u001b[0m  0.0200  1.6953\n",
      "      2        \u001b[36m0.6929\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.7804\u001b[0m  0.0199  0.5254\n",
      "      3        \u001b[36m0.6673\u001b[0m       0.5000        1.5472  0.0197  0.5041\n",
      "      4        \u001b[36m0.6326\u001b[0m       0.5000        3.0334  0.0192  0.5143\n",
      "      5        \u001b[36m0.5719\u001b[0m       0.5257        1.0555  0.0187  0.5738\n",
      "      6        \u001b[36m0.5472\u001b[0m       0.5000        4.3548  0.0179  0.5292\n",
      "      7        \u001b[36m0.5142\u001b[0m       \u001b[32m0.7426\u001b[0m        \u001b[35m0.5454\u001b[0m  0.0171  0.5701\n",
      "      8        0.5488       0.7206        \u001b[35m0.5003\u001b[0m  0.0161  0.5375\n",
      "      9        \u001b[36m0.4786\u001b[0m       0.5184        0.9055  0.0150  0.5393\n",
      "     10        \u001b[36m0.3056\u001b[0m       0.5257        3.4548  0.0138  0.5528\n",
      "     11        0.3317       0.5000        9.6357  0.0126  0.5445\n",
      "     12        \u001b[36m0.2888\u001b[0m       0.5699        2.0447  0.0113  0.5368\n",
      "     13        \u001b[36m0.2663\u001b[0m       \u001b[32m0.8529\u001b[0m        \u001b[35m0.3520\u001b[0m  0.0100  0.5701\n",
      "     14        \u001b[36m0.1884\u001b[0m       0.6581        1.0893  0.0087  0.5454\n",
      "     15        0.2252       0.6066        1.7810  0.0074  0.5773\n",
      "     16        0.1948       0.5699        1.8621  0.0062  0.5469\n",
      "     17        0.1981       0.5919        1.5195  0.0050  0.5327\n",
      "     18        \u001b[36m0.1731\u001b[0m       0.7243        0.5927  0.0039  0.5288\n",
      "     19        \u001b[36m0.1587\u001b[0m       \u001b[32m0.9559\u001b[0m        \u001b[35m0.1649\u001b[0m  0.0029  0.5288\n",
      "     20        0.1665       0.9485        \u001b[35m0.1156\u001b[0m  0.0021  0.5558\n",
      "     21        \u001b[36m0.1289\u001b[0m       \u001b[32m0.9706\u001b[0m        \u001b[35m0.0975\u001b[0m  0.0013  0.5384\n",
      "     22        0.1509       0.9228        0.1772  0.0008  0.5306\n",
      "     23        \u001b[36m0.1286\u001b[0m       0.9632        \u001b[35m0.0898\u001b[0m  0.0003  0.5334\n",
      "     24        0.1479       0.9559        0.0951  0.0001  0.5250\n",
      "     25        \u001b[36m0.1265\u001b[0m       0.9485        0.0976  0.0000  0.5208\n",
      "Best Validation Accuracy for Subject 1: 0.971\n",
      "\n",
      "=== Subject 2/8 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.1738\u001b[0m       \u001b[32m0.5147\u001b[0m       \u001b[35m21.3869\u001b[0m  0.0200  0.5314\n",
      "      2        0.1888       \u001b[32m0.6360\u001b[0m        \u001b[35m3.4595\u001b[0m  0.0199  0.5347\n",
      "      3        \u001b[36m0.0689\u001b[0m       0.5147        5.7246  0.0197  0.5305\n",
      "      4        0.0819       \u001b[32m0.9559\u001b[0m        \u001b[35m0.1122\u001b[0m  0.0192  0.5199\n",
      "      5        0.0790       0.8566        0.4419  0.0187  0.5200\n",
      "      6        0.0736       \u001b[32m0.9890\u001b[0m        \u001b[35m0.0237\u001b[0m  0.0179  0.5316\n",
      "      7        \u001b[36m0.0612\u001b[0m       0.9853        0.0243  0.0171  0.5470\n",
      "      8        \u001b[36m0.0353\u001b[0m       \u001b[32m1.0000\u001b[0m        \u001b[35m0.0113\u001b[0m  0.0161  0.5519\n",
      "      9        0.0362       0.9926        0.0314  0.0150  0.5338\n",
      "     10        \u001b[36m0.0309\u001b[0m       0.8824        0.3120  0.0138  0.5491\n",
      "     11        0.0569       0.9706        0.0704  0.0126  0.5312\n",
      "     12        \u001b[36m0.0192\u001b[0m       0.9926        0.0127  0.0113  0.5242\n",
      "     13        \u001b[36m0.0172\u001b[0m       0.6949        1.1231  0.0100  0.5276\n",
      "     14        0.0174       0.9926        0.0166  0.0087  0.5653\n",
      "     15        0.0177       1.0000        \u001b[35m0.0048\u001b[0m  0.0074  0.5284\n",
      "     16        \u001b[36m0.0128\u001b[0m       1.0000        \u001b[35m0.0030\u001b[0m  0.0062  0.5455\n",
      "     17        0.0239       0.9926        0.0084  0.0050  0.5384\n",
      "     18        0.0188       0.9926        0.0124  0.0039  0.5310\n",
      "     19        \u001b[36m0.0069\u001b[0m       0.9926        0.0087  0.0029  0.5454\n",
      "     20        \u001b[36m0.0024\u001b[0m       1.0000        0.0033  0.0021  0.5658\n",
      "     21        0.0154       0.9816        0.0411  0.0013  0.5469\n",
      "     22        0.0089       1.0000        \u001b[35m0.0006\u001b[0m  0.0008  0.5160\n",
      "     23        0.0062       1.0000        0.0039  0.0003  0.5238\n",
      "     24        0.0047       1.0000        0.0007  0.0001  0.5248\n",
      "     25        0.0077       1.0000        0.0040  0.0000  0.5164\n",
      "Best Validation Accuracy for Subject 2: 1.000\n",
      "\n",
      "=== Subject 3/8 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m1.2325\u001b[0m       \u001b[32m0.6728\u001b[0m        \u001b[35m4.3200\u001b[0m  0.0200  0.5278\n",
      "      2        \u001b[36m0.7515\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6387\u001b[0m  0.0199  0.5308\n",
      "      3        \u001b[36m0.5822\u001b[0m       \u001b[32m0.8088\u001b[0m        1.3782  0.0197  0.5179\n",
      "      4        \u001b[36m0.4634\u001b[0m       0.5221        2.6558  0.0192  0.5390\n",
      "      5        \u001b[36m0.3866\u001b[0m       0.5074        3.4127  0.0187  0.5851\n",
      "      6        \u001b[36m0.2998\u001b[0m       \u001b[32m0.8199\u001b[0m        \u001b[35m0.4502\u001b[0m  0.0179  0.5582\n",
      "      7        0.3634       0.5735        1.0033  0.0171  0.5649\n",
      "      8        \u001b[36m0.2780\u001b[0m       0.5000        5.5159  0.0161  0.5632\n",
      "      9        \u001b[36m0.2683\u001b[0m       0.5662        2.6757  0.0150  0.5691\n",
      "     10        \u001b[36m0.2544\u001b[0m       0.7353        0.5783  0.0138  0.5459\n",
      "     11        \u001b[36m0.2197\u001b[0m       0.5074        2.7465  0.0126  0.5489\n",
      "     12        0.2449       0.5037        4.5627  0.0113  0.5390\n",
      "     13        \u001b[36m0.1939\u001b[0m       \u001b[32m0.8309\u001b[0m        0.7045  0.0100  0.5139\n",
      "     14        0.2045       0.6029        1.4103  0.0087  0.5113\n",
      "     15        \u001b[36m0.1790\u001b[0m       0.7316        1.3354  0.0074  0.5202\n",
      "     16        \u001b[36m0.1740\u001b[0m       \u001b[32m0.9154\u001b[0m        \u001b[35m0.2441\u001b[0m  0.0062  0.5283\n",
      "     17        \u001b[36m0.1418\u001b[0m       0.8051        0.5391  0.0050  0.5345\n",
      "     18        0.1558       0.6838        0.7761  0.0039  0.5296\n",
      "     19        0.1614       0.8640        0.3435  0.0029  0.5284\n",
      "     20        0.1512       0.9154        0.2679  0.0021  0.5419\n",
      "     21        \u001b[36m0.1398\u001b[0m       0.9044        0.4420  0.0013  0.5274\n",
      "     22        \u001b[36m0.1345\u001b[0m       0.9154        0.2890  0.0008  0.5109\n",
      "     23        0.1457       0.9007        0.2696  0.0003  0.5137\n",
      "     24        \u001b[36m0.1277\u001b[0m       0.8640        0.3756  0.0001  0.5439\n",
      "     25        \u001b[36m0.1251\u001b[0m       0.8787        0.3937  0.0000  0.5074\n",
      "Best Validation Accuracy for Subject 3: 0.915\n",
      "\n",
      "=== Subject 4/8 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.7591\u001b[0m       \u001b[32m0.5441\u001b[0m        \u001b[35m0.6907\u001b[0m  0.0200  0.5071\n",
      "      2        \u001b[36m0.7226\u001b[0m       0.4890        0.7021  0.0199  0.5207\n",
      "      3        \u001b[36m0.7109\u001b[0m       0.4853        0.7151  0.0197  0.6042\n",
      "      4        \u001b[36m0.7040\u001b[0m       0.5000        0.8175  0.0192  0.5904\n",
      "      5        0.7111       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6776\u001b[0m  0.0187  0.5551\n",
      "      6        0.7047       0.5625        0.7833  0.0179  0.5993\n",
      "      7        0.7128       0.5074        0.7748  0.0171  0.5412\n",
      "      8        \u001b[36m0.6918\u001b[0m       0.5000        0.8466  0.0161  0.5324\n",
      "      9        \u001b[36m0.6871\u001b[0m       \u001b[32m0.5662\u001b[0m        \u001b[35m0.6576\u001b[0m  0.0150  0.5209\n",
      "     10        \u001b[36m0.6599\u001b[0m       0.5147        1.7584  0.0138  0.5283\n",
      "     11        0.6679       0.5441        0.7462  0.0126  0.5307\n",
      "     12        \u001b[36m0.6357\u001b[0m       \u001b[32m0.6691\u001b[0m        \u001b[35m0.5791\u001b[0m  0.0113  0.5193\n",
      "     13        \u001b[36m0.6091\u001b[0m       0.6066        0.6857  0.0100  0.5314\n",
      "     14        \u001b[36m0.5895\u001b[0m       0.5037        0.9752  0.0087  0.5204\n",
      "     15        \u001b[36m0.5326\u001b[0m       0.5956        1.0338  0.0074  0.5236\n",
      "     16        \u001b[36m0.4682\u001b[0m       \u001b[32m0.8272\u001b[0m        \u001b[35m0.3790\u001b[0m  0.0062  0.4999\n",
      "     17        \u001b[36m0.3681\u001b[0m       0.7500        0.4770  0.0050  0.5136\n",
      "     18        \u001b[36m0.3460\u001b[0m       0.7684        0.4216  0.0039  0.5413\n",
      "     19        \u001b[36m0.3317\u001b[0m       0.8125        \u001b[35m0.3600\u001b[0m  0.0029  0.5348\n",
      "     20        \u001b[36m0.2944\u001b[0m       \u001b[32m0.8566\u001b[0m        \u001b[35m0.3256\u001b[0m  0.0021  0.5586\n",
      "     21        0.2947       0.7978        0.3836  0.0013  0.5492\n",
      "     22        \u001b[36m0.2882\u001b[0m       \u001b[32m0.8676\u001b[0m        \u001b[35m0.2986\u001b[0m  0.0008  0.5419\n",
      "     23        \u001b[36m0.2793\u001b[0m       0.8199        0.3259  0.0003  0.5226\n",
      "     24        0.2804       0.8456        0.2999  0.0001  0.5213\n",
      "     25        \u001b[36m0.2779\u001b[0m       0.8382        0.3023  0.0000  0.5417\n",
      "Best Validation Accuracy for Subject 4: 0.868\n",
      "\n",
      "=== Subject 5/8 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.8541\u001b[0m       \u001b[32m0.5257\u001b[0m        \u001b[35m0.7028\u001b[0m  0.0200  0.5277\n",
      "      2        \u001b[36m0.7037\u001b[0m       \u001b[32m0.5294\u001b[0m        0.8662  0.0199  0.5185\n",
      "      3        \u001b[36m0.6978\u001b[0m       0.5147        1.3043  0.0197  0.5248\n",
      "      4        \u001b[36m0.6808\u001b[0m       0.5000        1.2720  0.0192  0.5250\n",
      "      5        \u001b[36m0.6625\u001b[0m       \u001b[32m0.6765\u001b[0m        \u001b[35m0.5807\u001b[0m  0.0187  0.5243\n",
      "      6        \u001b[36m0.5984\u001b[0m       0.5147        4.3714  0.0179  0.5423\n",
      "      7        \u001b[36m0.5672\u001b[0m       0.6618        0.6610  0.0171  0.5484\n",
      "      8        \u001b[36m0.4402\u001b[0m       \u001b[32m0.7721\u001b[0m        \u001b[35m0.4062\u001b[0m  0.0161  0.5401\n",
      "      9        \u001b[36m0.4298\u001b[0m       0.5846        0.9620  0.0150  0.5400\n",
      "     10        \u001b[36m0.3802\u001b[0m       0.6507        0.8142  0.0138  0.5430\n",
      "     11        \u001b[36m0.3584\u001b[0m       0.5735        1.2091  0.0126  0.5733\n",
      "     12        \u001b[36m0.2700\u001b[0m       \u001b[32m0.8787\u001b[0m        \u001b[35m0.3341\u001b[0m  0.0113  0.5486\n",
      "     13        \u001b[36m0.2366\u001b[0m       0.7279        0.6516  0.0100  0.5288\n",
      "     14        0.2608       \u001b[32m0.8824\u001b[0m        \u001b[35m0.2537\u001b[0m  0.0087  0.5218\n",
      "     15        \u001b[36m0.2134\u001b[0m       \u001b[32m0.9154\u001b[0m        \u001b[35m0.1913\u001b[0m  0.0074  0.5275\n",
      "     16        \u001b[36m0.2066\u001b[0m       0.8676        0.3474  0.0062  0.5385\n",
      "     17        \u001b[36m0.1789\u001b[0m       0.8640        0.3408  0.0050  0.5327\n",
      "     18        \u001b[36m0.1710\u001b[0m       \u001b[32m0.9485\u001b[0m        \u001b[35m0.1452\u001b[0m  0.0039  0.5331\n",
      "     19        \u001b[36m0.1502\u001b[0m       \u001b[32m0.9522\u001b[0m        \u001b[35m0.1423\u001b[0m  0.0029  0.5155\n",
      "     20        \u001b[36m0.1374\u001b[0m       0.9301        0.1691  0.0021  0.5434\n",
      "     21        \u001b[36m0.1229\u001b[0m       0.9081        0.2635  0.0013  0.5384\n",
      "     22        0.1234       0.9522        \u001b[35m0.1305\u001b[0m  0.0008  0.5330\n",
      "     23        0.1291       \u001b[32m0.9559\u001b[0m        \u001b[35m0.1304\u001b[0m  0.0003  0.5340\n",
      "     24        \u001b[36m0.1221\u001b[0m       0.9559        \u001b[35m0.1253\u001b[0m  0.0001  0.5295\n",
      "     25        \u001b[36m0.1094\u001b[0m       0.9559        0.1267  0.0000  0.5228\n",
      "Best Validation Accuracy for Subject 5: 0.956\n",
      "\n",
      "=== Subject 6/8 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.7556\u001b[0m       \u001b[32m0.5147\u001b[0m        \u001b[35m3.4181\u001b[0m  0.0200  0.5182\n",
      "      2        \u001b[36m0.5632\u001b[0m       \u001b[32m0.5699\u001b[0m        \u001b[35m1.0636\u001b[0m  0.0199  0.5412\n",
      "      3        \u001b[36m0.5103\u001b[0m       \u001b[32m0.6949\u001b[0m        \u001b[35m0.6204\u001b[0m  0.0197  0.5082\n",
      "      4        \u001b[36m0.4800\u001b[0m       0.5221        1.2735  0.0192  0.5210\n",
      "      5        \u001b[36m0.4522\u001b[0m       \u001b[32m0.7757\u001b[0m        \u001b[35m0.5430\u001b[0m  0.0187  0.5256\n",
      "      6        \u001b[36m0.4358\u001b[0m       0.5000        5.1100  0.0179  0.5261\n",
      "      7        \u001b[36m0.4318\u001b[0m       0.5331        2.2839  0.0171  0.5141\n",
      "      8        \u001b[36m0.3667\u001b[0m       0.5000        3.3538  0.0161  0.5299\n",
      "      9        \u001b[36m0.2418\u001b[0m       \u001b[32m0.9044\u001b[0m        \u001b[35m0.2483\u001b[0m  0.0150  0.5202\n",
      "     10        \u001b[36m0.2024\u001b[0m       0.8676        0.4113  0.0138  0.5169\n",
      "     11        \u001b[36m0.1532\u001b[0m       \u001b[32m0.9522\u001b[0m        \u001b[35m0.1680\u001b[0m  0.0126  0.5193\n",
      "     12        \u001b[36m0.1285\u001b[0m       0.9228        0.1945  0.0113  0.5207\n",
      "     13        0.1517       0.7390        0.8013  0.0100  0.5318\n",
      "     14        0.1435       0.9044        0.2222  0.0087  0.5558\n",
      "     15        \u001b[36m0.1016\u001b[0m       0.9338        \u001b[35m0.1574\u001b[0m  0.0074  0.5843\n",
      "     16        0.1114       0.9412        0.1835  0.0062  0.5367\n",
      "     17        \u001b[36m0.1009\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1393\u001b[0m  0.0050  0.5431\n",
      "     18        \u001b[36m0.0849\u001b[0m       \u001b[32m0.9779\u001b[0m        \u001b[35m0.0879\u001b[0m  0.0039  0.5281\n",
      "     19        \u001b[36m0.0725\u001b[0m       \u001b[32m0.9890\u001b[0m        \u001b[35m0.0737\u001b[0m  0.0029  0.5260\n",
      "     20        \u001b[36m0.0701\u001b[0m       0.9669        0.1132  0.0021  0.5249\n",
      "     21        \u001b[36m0.0491\u001b[0m       0.9779        0.0790  0.0013  0.5240\n",
      "     22        0.0510       0.9853        0.0844  0.0008  0.5363\n",
      "     23        0.0524       0.9890        0.0796  0.0003  0.5203\n",
      "     24        \u001b[36m0.0303\u001b[0m       0.9853        0.0834  0.0001  0.5276\n",
      "     25        0.0411       0.9890        0.0791  0.0000  0.5286\n",
      "Best Validation Accuracy for Subject 6: 0.989\n",
      "\n",
      "=== Subject 7/8 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.5515\u001b[0m       \u001b[32m0.5184\u001b[0m        \u001b[35m4.0360\u001b[0m  0.0200  0.5278\n",
      "      2        \u001b[36m0.4045\u001b[0m       \u001b[32m0.8897\u001b[0m        \u001b[35m0.2647\u001b[0m  0.0199  0.5252\n",
      "      3        \u001b[36m0.2780\u001b[0m       0.5147        9.0574  0.0197  0.5148\n",
      "      4        0.2983       0.5625        3.4459  0.0192  0.5169\n",
      "      5        \u001b[36m0.2583\u001b[0m       0.5882        3.1126  0.0187  0.5178\n",
      "      6        0.2934       0.6176        2.2600  0.0179  0.5099\n",
      "      7        0.2621       \u001b[32m0.9375\u001b[0m        \u001b[35m0.2160\u001b[0m  0.0171  0.5295\n",
      "      8        \u001b[36m0.2244\u001b[0m       0.5404        2.2796  0.0161  0.5896\n",
      "      9        \u001b[36m0.1940\u001b[0m       0.8713        0.4203  0.0150  0.5249\n",
      "     10        0.2234       0.8750        0.3658  0.0138  0.5627\n",
      "     11        0.2294       0.7537        0.6769  0.0126  0.5592\n",
      "     12        \u001b[36m0.1822\u001b[0m       0.7647        0.8761  0.0113  0.5517\n",
      "     13        0.1822       0.7316        0.9464  0.0100  0.5469\n",
      "     14        0.2000       0.6691        1.3014  0.0087  0.5161\n",
      "     15        \u001b[36m0.1159\u001b[0m       0.8787        0.3787  0.0074  0.5169\n",
      "     16        0.1437       \u001b[32m0.9412\u001b[0m        \u001b[35m0.1739\u001b[0m  0.0062  0.5307\n",
      "     17        0.1236       0.7500        0.7120  0.0050  0.5167\n",
      "     18        \u001b[36m0.0970\u001b[0m       0.8787        0.3700  0.0039  0.5165\n",
      "     19        0.0983       \u001b[32m0.9669\u001b[0m        \u001b[35m0.1120\u001b[0m  0.0029  0.5264\n",
      "     20        0.1159       0.9596        \u001b[35m0.1044\u001b[0m  0.0021  0.5158\n",
      "     21        0.1189       0.8346        0.4744  0.0013  0.5231\n",
      "     22        \u001b[36m0.0830\u001b[0m       \u001b[32m0.9706\u001b[0m        0.1076  0.0008  0.5312\n",
      "     23        0.0882       0.9632        0.1074  0.0003  0.5309\n",
      "     24        \u001b[36m0.0812\u001b[0m       0.9669        0.1061  0.0001  0.5454\n",
      "     25        0.0876       0.9596        0.1096  0.0000  0.5486\n",
      "Best Validation Accuracy for Subject 7: 0.971\n",
      "\n",
      "=== Subject 8/8 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.8503\u001b[0m       \u001b[32m0.5110\u001b[0m        \u001b[35m0.8785\u001b[0m  0.0200  0.5477\n",
      "      2        \u001b[36m0.6866\u001b[0m       \u001b[32m0.5772\u001b[0m        \u001b[35m0.6912\u001b[0m  0.0199  0.5358\n",
      "      3        \u001b[36m0.6660\u001b[0m       \u001b[32m0.6544\u001b[0m        \u001b[35m0.6463\u001b[0m  0.0197  0.5241\n",
      "      4        \u001b[36m0.6453\u001b[0m       \u001b[32m0.6728\u001b[0m        0.6510  0.0192  0.5285\n",
      "      5        \u001b[36m0.6334\u001b[0m       0.5000        1.6556  0.0187  0.5209\n",
      "      6        \u001b[36m0.6160\u001b[0m       0.6691        \u001b[35m0.6141\u001b[0m  0.0179  0.5143\n",
      "      7        \u001b[36m0.5871\u001b[0m       \u001b[32m0.7022\u001b[0m        0.6512  0.0171  0.5204\n",
      "      8        \u001b[36m0.5712\u001b[0m       0.6544        0.6477  0.0161  0.5145\n",
      "      9        \u001b[36m0.5346\u001b[0m       0.5221        1.5422  0.0150  0.5209\n",
      "     10        \u001b[36m0.4960\u001b[0m       \u001b[32m0.7794\u001b[0m        \u001b[35m0.4276\u001b[0m  0.0138  0.5201\n",
      "     11        \u001b[36m0.4284\u001b[0m       \u001b[32m0.8088\u001b[0m        \u001b[35m0.4153\u001b[0m  0.0126  0.5256\n",
      "     12        \u001b[36m0.4098\u001b[0m       \u001b[32m0.8162\u001b[0m        \u001b[35m0.3899\u001b[0m  0.0113  0.5235\n",
      "     13        \u001b[36m0.3753\u001b[0m       0.7647        0.5125  0.0100  0.5277\n",
      "     14        \u001b[36m0.3319\u001b[0m       0.7574        0.5752  0.0087  0.5318\n",
      "     15        \u001b[36m0.2898\u001b[0m       \u001b[32m0.8640\u001b[0m        \u001b[35m0.2949\u001b[0m  0.0074  0.5164\n",
      "     16        0.2914       0.7757        0.4874  0.0062  0.5201\n",
      "     17        \u001b[36m0.2890\u001b[0m       0.5588        1.3937  0.0050  0.5190\n",
      "     18        \u001b[36m0.2791\u001b[0m       \u001b[32m0.8860\u001b[0m        \u001b[35m0.2927\u001b[0m  0.0039  0.5191\n",
      "     19        \u001b[36m0.2248\u001b[0m       0.8015        0.4668  0.0029  0.5232\n",
      "     20        \u001b[36m0.1984\u001b[0m       \u001b[32m0.9191\u001b[0m        \u001b[35m0.1834\u001b[0m  0.0021  0.5270\n",
      "     21        \u001b[36m0.1882\u001b[0m       \u001b[32m0.9338\u001b[0m        \u001b[35m0.1644\u001b[0m  0.0013  0.5205\n",
      "     22        0.2040       \u001b[32m0.9375\u001b[0m        \u001b[35m0.1607\u001b[0m  0.0008  0.5404\n",
      "     23        \u001b[36m0.1719\u001b[0m       0.9228        0.1943  0.0003  0.5304\n",
      "     24        0.1751       \u001b[32m0.9412\u001b[0m        0.1641  0.0001  0.5187\n",
      "     25        0.1765       \u001b[32m0.9449\u001b[0m        \u001b[35m0.1581\u001b[0m  0.0000  0.5253\n",
      "Best Validation Accuracy for Subject 8: 0.945\n",
      "\n",
      "=== Mean Within-Subject Accuracy: 0.952 ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.9705882352941176,\n",
       "  1.0,\n",
       "  0.9154411764705882,\n",
       "  0.8676470588235294,\n",
       "  0.9558823529411765,\n",
       "  0.9889705882352942,\n",
       "  0.9705882352941176,\n",
       "  0.9448529411764706],\n",
       " 0.9517463235294118)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_within_subject_adaptive(windows_datasets_list, AdaptiveEEGNet, n_epochs=25, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
