{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from mne.decoding import CSP\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False                    # global variable to suppress output display of MNE functions\n",
    "mne.set_log_level(verbose=verbose) # to suppress large info outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = None  # for multicore parallel processing, set it to 1 if cause memory issues, for full utilization set to -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Conversion to MNE Datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = globals()['_dh'][0]  # a hack to get path of current folder in which jupyter file is located\n",
    "data_path = os.path.join(current_folder, r\"C:\\Users\\User\\Documents\\GitHub\\Frequency-Adaptive-Temporal-Kernel-EEGNet\\Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_files   = glob.glob(data_path + '/*T.mat')\n",
    "len(training_files)     # if  return zero,then no file is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mne_epochs(filepath, verbose=verbose, t_start=2, fs=512, mode='train'):\n",
    "    '''\n",
    "    This function reads the EEG data from .mat file and convert it to MNE-Python Compatible epochs\n",
    "    data structure. It takes data from [0, 8] sec range and return it by setting t = 0 at cue onset\n",
    "    i.e. 3 seconds and dropping first two seconds so the output data is in [-1.0, 5.0] sec range. The\n",
    "    Details can be found in the preprocessing section of the attached document\n",
    "    '''\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    eeg_data= mat_data['RawEEGData']\n",
    "    idx_start = fs*t_start      \n",
    "    eeg_data = eeg_data[:, :, idx_start:]\n",
    "    event_id = {'left-hand': 0, 'right-hand': 1} # pytorch expects labels in [0, n_classes-1]\n",
    "    channel_names = ['F3', 'FC3', 'C3', 'CP3', 'P3', 'FCz', 'CPz', 'F4', 'FC4', 'C4', 'CP4', 'P4']\n",
    "    info = mne.create_info(ch_names=channel_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, verbose=verbose, tmin=t_start-3.0)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None) \n",
    "    epochs.apply_baseline(baseline=(-.250, 0)) # linear baseline correction\n",
    "    \n",
    "    if mode == 'train': # this in only applicable for training data\n",
    "        epochs.event_id = event_id \n",
    "        epochs.events[:,2] = mat_data['Labels'].ravel() - 1    \n",
    "    return epochs \n",
    "\n",
    "def get_labels(filepath):\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    return mat_data['Labels'].ravel() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG Data:  (80, 12, 3072) \t Shape of Labels:  (80,)\n"
     ]
    }
   ],
   "source": [
    "epochs, labels = get_mne_epochs(training_files[0], verbose=verbose), get_labels(training_files[0])\n",
    "data = epochs.get_data()\n",
    "print('Shape of EEG Data: ', data.shape, '\\t Shape of Labels: ', labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading original data\n",
    "epochs_list_train = []\n",
    "for i in training_files:\n",
    "    epochs_list_train.append(get_mne_epochs(i, verbose=verbose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Braindecode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's Training Time with [0.5, 4.5] sec and 2sec window with 125ms stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets: 10\n",
      "Total windows per subject: 1360\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datautil import create_from_mne_epochs\n",
    "\n",
    "window_size = 1024   # 2 sec windows\n",
    "window_stride = 64   # 125 ms stride\n",
    "\n",
    "windows_datasets_list = []\n",
    "\n",
    "for epoch in epochs_list_train:\n",
    "    # Create windows per subject\n",
    "    windows_dataset = create_from_mne_epochs(\n",
    "        [epoch.crop(tmin=0.5, tmax=4.5, include_tmax=False)],\n",
    "        window_size_samples=window_size,\n",
    "        window_stride_samples=window_stride,\n",
    "        drop_last_window=False\n",
    "    )\n",
    "    # Add labels as a separate attribute\n",
    "    windows_dataset.update_description = pd.DataFrame(\n",
    "        data=np.concatenate([d.y for d in windows_dataset.datasets]),\n",
    "        columns=['labels']\n",
    "    )\n",
    "    windows_datasets_list.append(windows_dataset)\n",
    "\n",
    "print(\"Datasets:\", len(windows_datasets_list))\n",
    "print(\"Total windows per subject:\", len(windows_datasets_list[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.preprocessing import exponential_moving_standardize\n",
    "\n",
    "low_cut_hz = 8.   # low cut frequency for filtering\n",
    "high_cut_hz = 32. # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\n",
    "    \"\"\"Apply exponential moving standardization to MNE epochs inplace.\"\"\"\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        data[i] = exponential_moving_standardize(\n",
    "            data[i], factor_new=factor_new, init_block_size=init_block_size\n",
    "        )\n",
    "    epochs._data = data\n",
    "    return epochs\n",
    "\n",
    "# Apply preprocessing to each dataset\n",
    "for windows_dataset in windows_datasets_list:\n",
    "    # Extract the underlying MNE Epochs object\n",
    "    epochs = windows_dataset.datasets[0].windows\n",
    "    epochs.load_data()  # Ensure data is loaded into memory\n",
    "\n",
    "    # 1) Keep only EEG channels\n",
    "    epochs.pick_types(eeg=True)\n",
    "\n",
    "    # 2) Bandpass filter\n",
    "    epochs.filter(l_freq=low_cut_hz, h_freq=high_cut_hz)\n",
    "\n",
    "    # 3) Exponential moving standardization\n",
    "    custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #64\n",
    "n_epochs = 25 #25 #20 #25 use few epochs for quick verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from Frequency_Adaptive_model import AdaptiveEEGNet  \n",
    "\n",
    "cuda = torch.cuda.is_available()  \n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "# Deterministic training setup \n",
    "torch.backends.cudnn.deterministic = True \n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Model hyperparameters\n",
    "\n",
    "n_classes = 2\n",
    "n_chans = windows_datasets_list[0][0][0].shape[0]      # EEG channels\n",
    "input_window_samples = windows_datasets_list[0][0][0].shape[1]  # time samples\n",
    "\n",
    "# Instantiate AdaptiveEEGNet\n",
    "model = AdaptiveEEGNet(\n",
    "    nb_classes=n_classes,\n",
    "    Chans=n_chans,\n",
    "    Samples=input_window_samples,\n",
    "    kernLength=128,\n",
    "    F1=16,\n",
    "    D=2,\n",
    "    F2=32,\n",
    "    dropoutRate=0.3,\n",
    "    sample_rate=512\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "import numpy as np\n",
    "\n",
    "def training_within_subject_adaptive(windows_datasets_list, model_class, n_epochs=25, batch_size=32, val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Trains AdaptiveEEGNet model separately for each subject (within-subject classification).\n",
    "    Reports best validation accuracy per subject and mean accuracy across all subjects.\n",
    "    \"\"\"\n",
    "    all_subject_acc = []\n",
    "\n",
    "    for subj_idx, subj_data in enumerate(windows_datasets_list):\n",
    "        print(f\"\\n=== Subject {subj_idx+1}/{len(windows_datasets_list)} ===\")\n",
    "\n",
    "        # Gather data\n",
    "        X = np.concatenate([ds.windows for ds in subj_data.datasets], axis=0)\n",
    "        y = np.concatenate([ds.y for ds in subj_data.datasets], axis=0)\n",
    "\n",
    "        # Split train/validation\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=val_ratio, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        # Convert to tensors\n",
    "        train_tensor = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "        val_tensor   = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "\n",
    "        # Create a fresh model for each subject\n",
    "        n_chans = X.shape[1]\n",
    "        input_window_samples = X.shape[2]\n",
    "        n_classes = len(np.unique(y))\n",
    "\n",
    "        model = model_class(\n",
    "            nb_classes=n_classes,\n",
    "            Chans=n_chans,\n",
    "            Samples=input_window_samples,\n",
    "            kernLength=128,\n",
    "            F1=16,\n",
    "            D=2,\n",
    "            F2=32,\n",
    "            dropoutRate=0.3,\n",
    "            sample_rate=512\n",
    "        )\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            model.cuda()\n",
    "            device = 'cuda'\n",
    "        else:\n",
    "            device = 'cpu'\n",
    "\n",
    "        # Create classifier\n",
    "        clf = EEGClassifier(\n",
    "            model,\n",
    "            criterion=torch.nn.CrossEntropyLoss,\n",
    "            optimizer=torch.optim.AdamW,\n",
    "            optimizer__lr=0.02,\n",
    "            optimizer__weight_decay=0.0005,\n",
    "            batch_size=batch_size,\n",
    "            train_split=predefined_split(val_tensor),  # validation data\n",
    "            callbacks=[(\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=n_epochs-1))],\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        clf.fit(train_tensor, y=y_train, epochs=n_epochs)\n",
    "\n",
    "        # Retrieve best validation accuracy\n",
    "        for name, cb in clf.callbacks_:\n",
    "            if name == \"valid_acc\":\n",
    "                best_val_acc = cb.best_score_\n",
    "                break\n",
    "\n",
    "        print(f\"Best Validation Accuracy for Subject {subj_idx+1}: {best_val_acc:.3f}\")\n",
    "        all_subject_acc.append(best_val_acc)\n",
    "\n",
    "    mean_acc = np.mean(all_subject_acc)\n",
    "    print(\"\\n=== Mean Within-Subject Accuracy: {:.3f} ===\".format(mean_acc))\n",
    "    return all_subject_acc, mean_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Subject 1/10 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.8624\u001b[0m       \u001b[32m0.4853\u001b[0m        \u001b[35m1.2243\u001b[0m  0.0200  2.1930\n",
      "      2        \u001b[36m0.6579\u001b[0m       \u001b[32m0.6066\u001b[0m        \u001b[35m0.8830\u001b[0m  0.0199  2.2491\n",
      "      3        0.6659       \u001b[32m0.7022\u001b[0m        \u001b[35m0.5522\u001b[0m  0.0197  2.2423\n",
      "      4        \u001b[36m0.5964\u001b[0m       0.5147        4.0993  0.0192  2.2323\n",
      "      5        \u001b[36m0.5749\u001b[0m       0.6544        0.6064  0.0187  2.2847\n",
      "      6        \u001b[36m0.5692\u001b[0m       0.5662        0.7795  0.0179  2.1823\n",
      "      7        0.5845       0.6213        1.0806  0.0171  2.1320\n",
      "      8        \u001b[36m0.4741\u001b[0m       0.5147        2.8854  0.0161  2.1585\n",
      "      9        0.4852       0.6103        1.8598  0.0150  2.1768\n",
      "     10        \u001b[36m0.4419\u001b[0m       0.5147        5.2380  0.0138  2.1378\n",
      "     11        \u001b[36m0.4088\u001b[0m       0.5000        9.4527  0.0126  2.1232\n",
      "     12        0.5036       0.5000       13.9835  0.0113  2.2840\n",
      "     13        0.4527       0.5147        3.2530  0.0100  2.2087\n",
      "     14        \u001b[36m0.3847\u001b[0m       \u001b[32m0.9044\u001b[0m        \u001b[35m0.3205\u001b[0m  0.0087  2.1881\n",
      "     15        0.4193       0.8676        \u001b[35m0.3003\u001b[0m  0.0074  2.1450\n",
      "     16        \u001b[36m0.3531\u001b[0m       0.6434        1.5790  0.0062  2.1608\n",
      "     17        \u001b[36m0.3321\u001b[0m       0.6434        2.0182  0.0050  2.2294\n",
      "     18        \u001b[36m0.3051\u001b[0m       0.5221        1.1885  0.0039  2.1419\n",
      "     19        \u001b[36m0.2984\u001b[0m       0.8162        0.3319  0.0029  2.1382\n",
      "     20        0.3396       0.6985        0.5643  0.0021  2.1177\n",
      "     21        0.3489       \u001b[32m0.9338\u001b[0m        \u001b[35m0.2190\u001b[0m  0.0013  2.1568\n",
      "     22        0.3088       0.6875        0.5975  0.0008  2.1432\n",
      "     23        \u001b[36m0.2796\u001b[0m       0.8824        0.2572  0.0003  2.2194\n",
      "     24        0.3096       0.9338        \u001b[35m0.2139\u001b[0m  0.0001  2.1633\n",
      "     25        \u001b[36m0.2792\u001b[0m       \u001b[32m0.9375\u001b[0m        \u001b[35m0.2029\u001b[0m  0.0000  2.1516\n",
      "Best Validation Accuracy for Subject 1: 0.938\n",
      "\n",
      "=== Subject 2/10 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.1774\u001b[0m       \u001b[32m0.5147\u001b[0m       \u001b[35m34.8189\u001b[0m  0.0200  2.1892\n",
      "      2        \u001b[36m0.1389\u001b[0m       \u001b[32m0.9853\u001b[0m        \u001b[35m0.0531\u001b[0m  0.0199  2.2164\n",
      "      3        \u001b[36m0.0760\u001b[0m       \u001b[32m0.9926\u001b[0m        \u001b[35m0.0181\u001b[0m  0.0197  2.2212\n",
      "      4        \u001b[36m0.0680\u001b[0m       0.9743        0.1086  0.0192  2.1671\n",
      "      5        \u001b[36m0.0270\u001b[0m       0.9375        0.1751  0.0187  2.2229\n",
      "      6        0.0632       0.5147       16.4262  0.0179  2.2386\n",
      "      7        0.0329       \u001b[32m0.9963\u001b[0m        \u001b[35m0.0032\u001b[0m  0.0171  2.2560\n",
      "      8        0.0385       0.9963        0.0138  0.0161  2.1808\n",
      "      9        \u001b[36m0.0269\u001b[0m       0.9926        0.0149  0.0150  2.1541\n",
      "     10        0.0293       0.9632        0.1349  0.0138  2.1143\n",
      "     11        0.0488       0.5147       11.1846  0.0126  2.1208\n",
      "     12        \u001b[36m0.0169\u001b[0m       0.9669        0.1046  0.0113  2.1596\n",
      "     13        0.0620       \u001b[32m1.0000\u001b[0m        0.0046  0.0100  2.1727\n",
      "     14        0.0237       1.0000        0.0053  0.0087  2.2189\n",
      "     15        0.0287       1.0000        \u001b[35m0.0019\u001b[0m  0.0074  2.1426\n",
      "     16        0.0221       0.9485        0.1251  0.0062  2.1246\n",
      "     17        0.0171       1.0000        0.0042  0.0050  2.1732\n",
      "     18        \u001b[36m0.0085\u001b[0m       1.0000        0.0027  0.0039  2.2152\n",
      "     19        \u001b[36m0.0076\u001b[0m       1.0000        \u001b[35m0.0010\u001b[0m  0.0029  2.1569\n",
      "     20        0.0093       1.0000        \u001b[35m0.0005\u001b[0m  0.0021  2.1374\n",
      "     21        \u001b[36m0.0058\u001b[0m       1.0000        \u001b[35m0.0005\u001b[0m  0.0013  2.1180\n",
      "     22        \u001b[36m0.0044\u001b[0m       1.0000        0.0005  0.0008  2.1694\n",
      "     23        0.0107       1.0000        0.0008  0.0003  2.1799\n",
      "     24        \u001b[36m0.0017\u001b[0m       1.0000        0.0005  0.0001  2.1668\n",
      "     25        0.0101       1.0000        0.0007  0.0000  2.0939\n",
      "Best Validation Accuracy for Subject 2: 1.000\n",
      "\n",
      "=== Subject 3/10 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.9835\u001b[0m       \u001b[32m0.5588\u001b[0m        \u001b[35m3.0529\u001b[0m  0.0200  2.1799\n",
      "      2        \u001b[36m0.5114\u001b[0m       \u001b[32m0.7647\u001b[0m        \u001b[35m0.4336\u001b[0m  0.0199  2.1360\n",
      "      3        \u001b[36m0.4189\u001b[0m       0.5074        4.5029  0.0197  2.1373\n",
      "      4        0.4677       0.5184        4.8981  0.0192  2.1241\n",
      "      5        0.4312       0.5147        5.7779  0.0187  2.1083\n",
      "      6        \u001b[36m0.3462\u001b[0m       0.5074        4.9752  0.0179  2.1108\n",
      "      7        \u001b[36m0.3211\u001b[0m       0.7574        0.5344  0.0171  2.1525\n",
      "      8        \u001b[36m0.2528\u001b[0m       \u001b[32m0.8235\u001b[0m        0.8332  0.0161  2.1950\n",
      "      9        0.2539       0.7353        1.2660  0.0150  2.1531\n",
      "     10        \u001b[36m0.2075\u001b[0m       \u001b[32m0.8419\u001b[0m        0.9228  0.0138  2.2123\n",
      "     11        0.2483       \u001b[32m0.8971\u001b[0m        \u001b[35m0.2750\u001b[0m  0.0126  2.2423\n",
      "     12        \u001b[36m0.1869\u001b[0m       0.7059        1.3040  0.0113  2.1418\n",
      "     13        0.1879       0.8382        0.3092  0.0100  2.1770\n",
      "     14        0.2205       0.7721        0.6232  0.0087  2.2007\n",
      "     15        \u001b[36m0.1748\u001b[0m       \u001b[32m0.9301\u001b[0m        0.2900  0.0074  2.1090\n",
      "     16        \u001b[36m0.1612\u001b[0m       0.9118        \u001b[35m0.2098\u001b[0m  0.0062  2.1134\n",
      "     17        0.1668       0.8419        0.3521  0.0050  2.0612\n",
      "     18        \u001b[36m0.1438\u001b[0m       0.7463        0.9148  0.0039  2.0845\n",
      "     19        \u001b[36m0.1435\u001b[0m       0.9265        0.3712  0.0029  2.1078\n",
      "     20        \u001b[36m0.1235\u001b[0m       0.9007        0.4092  0.0021  2.0756\n",
      "     21        0.1373       \u001b[32m0.9375\u001b[0m        0.3156  0.0013  2.1047\n",
      "     22        0.1305       0.9301        0.5201  0.0008  2.0653\n",
      "     23        0.1440       0.9081        0.3281  0.0003  2.1101\n",
      "     24        0.1421       0.9301        0.3589  0.0001  2.1372\n",
      "     25        0.1347       \u001b[32m0.9412\u001b[0m        0.3463  0.0000  2.1866\n",
      "Best Validation Accuracy for Subject 3: 0.941\n",
      "\n",
      "=== Subject 4/10 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.7814\u001b[0m       \u001b[32m0.5184\u001b[0m        \u001b[35m0.6970\u001b[0m  0.0200  2.1445\n",
      "      2        \u001b[36m0.7487\u001b[0m       \u001b[32m0.5368\u001b[0m        0.7030  0.0199  2.2734\n",
      "      3        \u001b[36m0.6970\u001b[0m       0.5000        0.9905  0.0197  2.2064\n",
      "      4        \u001b[36m0.6893\u001b[0m       \u001b[32m0.5735\u001b[0m        0.7181  0.0192  2.1992\n",
      "      5        \u001b[36m0.6723\u001b[0m       0.5000        1.1607  0.0187  2.2580\n",
      "      6        0.6860       0.4853        1.1249  0.0179  2.1909\n",
      "      7        \u001b[36m0.6610\u001b[0m       0.4890        1.0240  0.0171  2.2284\n",
      "      8        \u001b[36m0.6469\u001b[0m       0.5221        0.9085  0.0161  2.2138\n",
      "      9        0.6602       \u001b[32m0.6397\u001b[0m        \u001b[35m0.6025\u001b[0m  0.0150  2.1638\n",
      "     10        \u001b[36m0.5958\u001b[0m       0.6360        0.7814  0.0138  2.1759\n",
      "     11        0.6086       0.5000        2.2423  0.0126  2.2508\n",
      "     12        0.6038       0.5331        1.0164  0.0113  2.1767\n",
      "     13        \u001b[36m0.5518\u001b[0m       0.5000        1.5765  0.0100  2.1598\n",
      "     14        \u001b[36m0.5507\u001b[0m       \u001b[32m0.7390\u001b[0m        \u001b[35m0.5238\u001b[0m  0.0087  2.1646\n",
      "     15        \u001b[36m0.5233\u001b[0m       \u001b[32m0.7610\u001b[0m        \u001b[35m0.5057\u001b[0m  0.0074  2.1481\n",
      "     16        0.5448       0.6434        0.6343  0.0062  2.1972\n",
      "     17        \u001b[36m0.4797\u001b[0m       0.5037        1.3953  0.0050  2.1684\n",
      "     18        0.5054       0.7390        \u001b[35m0.5047\u001b[0m  0.0039  2.1846\n",
      "     19        \u001b[36m0.4704\u001b[0m       0.5331        1.1011  0.0029  2.1810\n",
      "     20        0.4720       0.6912        0.5143  0.0021  2.1870\n",
      "     21        \u001b[36m0.4213\u001b[0m       \u001b[32m0.8051\u001b[0m        \u001b[35m0.4427\u001b[0m  0.0013  2.1911\n",
      "     22        0.4563       0.7353        0.4727  0.0008  2.1775\n",
      "     23        0.4475       \u001b[32m0.8199\u001b[0m        \u001b[35m0.4110\u001b[0m  0.0003  2.1988\n",
      "     24        0.4237       \u001b[32m0.8235\u001b[0m        0.4133  0.0001  2.2469\n",
      "     25        0.4308       0.8125        0.4193  0.0000  2.1868\n",
      "Best Validation Accuracy for Subject 4: 0.824\n",
      "\n",
      "=== Subject 5/10 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.9207\u001b[0m       \u001b[32m0.5184\u001b[0m        \u001b[35m0.7286\u001b[0m  0.0200  2.2445\n",
      "      2        \u001b[36m0.7359\u001b[0m       0.5037        \u001b[35m0.7081\u001b[0m  0.0199  2.2062\n",
      "      3        \u001b[36m0.6945\u001b[0m       \u001b[32m0.5735\u001b[0m        \u001b[35m0.7046\u001b[0m  0.0197  2.2622\n",
      "      4        \u001b[36m0.6586\u001b[0m       \u001b[32m0.5919\u001b[0m        0.8316  0.0192  2.2193\n",
      "      5        \u001b[36m0.6536\u001b[0m       0.5000        3.2314  0.0187  2.2064\n",
      "      6        \u001b[36m0.6126\u001b[0m       0.5551        0.9035  0.0179  2.1658\n",
      "      7        \u001b[36m0.5539\u001b[0m       0.5625        0.8750  0.0171  2.2496\n",
      "      8        0.5573       0.5037        1.2845  0.0161  2.2445\n",
      "      9        \u001b[36m0.4722\u001b[0m       \u001b[32m0.5956\u001b[0m        0.9421  0.0150  2.2100\n",
      "     10        \u001b[36m0.4388\u001b[0m       \u001b[32m0.7831\u001b[0m        \u001b[35m0.4438\u001b[0m  0.0138  2.1691\n",
      "     11        \u001b[36m0.3742\u001b[0m       0.5184        1.5192  0.0126  2.1192\n",
      "     12        \u001b[36m0.3177\u001b[0m       0.6324        0.9367  0.0113  2.1818\n",
      "     13        \u001b[36m0.2466\u001b[0m       0.6544        0.9675  0.0100  2.2870\n",
      "     14        \u001b[36m0.2330\u001b[0m       0.5037        3.6976  0.0087  2.4558\n",
      "     15        \u001b[36m0.2296\u001b[0m       \u001b[32m0.8971\u001b[0m        \u001b[35m0.2462\u001b[0m  0.0074  2.2222\n",
      "     16        \u001b[36m0.2067\u001b[0m       0.8603        0.3120  0.0062  2.2166\n",
      "     17        \u001b[36m0.1790\u001b[0m       0.7757        0.5475  0.0050  2.2737\n",
      "     18        \u001b[36m0.1653\u001b[0m       0.8971        0.2472  0.0039  2.2547\n",
      "     19        \u001b[36m0.1275\u001b[0m       \u001b[32m0.9191\u001b[0m        \u001b[35m0.2037\u001b[0m  0.0029  2.2290\n",
      "     20        0.1658       0.9154        \u001b[35m0.1903\u001b[0m  0.0021  2.1939\n",
      "     21        0.1420       0.8713        0.3145  0.0013  2.5293\n",
      "     22        \u001b[36m0.1100\u001b[0m       \u001b[32m0.9522\u001b[0m        \u001b[35m0.1253\u001b[0m  0.0008  4.6241\n",
      "     23        0.1110       0.9449        \u001b[35m0.1097\u001b[0m  0.0003  4.8402\n",
      "     24        \u001b[36m0.1088\u001b[0m       0.9449        \u001b[35m0.1083\u001b[0m  0.0001  5.0476\n",
      "     25        0.1136       0.9449        0.1084  0.0000  4.9159\n",
      "Best Validation Accuracy for Subject 5: 0.952\n",
      "\n",
      "=== Subject 6/10 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.7228\u001b[0m       \u001b[32m0.5257\u001b[0m        \u001b[35m1.1696\u001b[0m  0.0200  4.8271\n",
      "      2        \u001b[36m0.5450\u001b[0m       \u001b[32m0.7316\u001b[0m        \u001b[35m0.5895\u001b[0m  0.0199  4.6508\n",
      "      3        \u001b[36m0.5046\u001b[0m       0.5294        1.2265  0.0197  4.8109\n",
      "      4        0.5116       \u001b[32m0.7426\u001b[0m        0.6376  0.0192  4.8477\n",
      "      5        \u001b[36m0.4862\u001b[0m       \u001b[32m0.7684\u001b[0m        \u001b[35m0.5225\u001b[0m  0.0187  4.9096\n",
      "      6        \u001b[36m0.4516\u001b[0m       0.5000        3.6027  0.0179  4.7819\n",
      "      7        \u001b[36m0.3657\u001b[0m       \u001b[32m0.8529\u001b[0m        \u001b[35m0.4406\u001b[0m  0.0171  5.0638\n",
      "      8        \u001b[36m0.2786\u001b[0m       0.8199        0.4450  0.0161  4.8238\n",
      "      9        0.2836       \u001b[32m0.8824\u001b[0m        \u001b[35m0.3019\u001b[0m  0.0150  4.9197\n",
      "     10        \u001b[36m0.2287\u001b[0m       \u001b[32m0.9007\u001b[0m        \u001b[35m0.2364\u001b[0m  0.0138  4.7108\n",
      "     11        \u001b[36m0.2092\u001b[0m       0.8787        0.3906  0.0126  4.9575\n",
      "     12        \u001b[36m0.1282\u001b[0m       0.7684        0.9295  0.0113  4.9930\n",
      "     13        \u001b[36m0.0995\u001b[0m       0.9007        0.2665  0.0100  4.9482\n",
      "     14        0.1588       \u001b[32m0.9081\u001b[0m        0.2694  0.0087  4.7739\n",
      "     15        0.1113       \u001b[32m0.9118\u001b[0m        0.3007  0.0074  4.6545\n",
      "     16        0.1093       \u001b[32m0.9522\u001b[0m        \u001b[35m0.1309\u001b[0m  0.0062  4.9960\n",
      "     17        \u001b[36m0.0687\u001b[0m       0.9118        0.2593  0.0050  4.9690\n",
      "     18        0.0705       0.8824        0.4720  0.0039  5.0370\n",
      "     19        \u001b[36m0.0635\u001b[0m       \u001b[32m0.9559\u001b[0m        0.1536  0.0029  4.7425\n",
      "     20        0.0642       0.9412        0.1474  0.0021  4.9036\n",
      "     21        \u001b[36m0.0526\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1147\u001b[0m  0.0013  5.0722\n",
      "     22        0.0534       0.9632        0.1253  0.0008  5.0512\n",
      "     23        0.0529       \u001b[32m0.9669\u001b[0m        \u001b[35m0.1050\u001b[0m  0.0003  2.3565\n",
      "     24        \u001b[36m0.0394\u001b[0m       0.9632        \u001b[35m0.1002\u001b[0m  0.0001  2.1771\n",
      "     25        0.0483       0.9596        \u001b[35m0.0994\u001b[0m  0.0000  2.1919\n",
      "Best Validation Accuracy for Subject 6: 0.967\n",
      "\n",
      "=== Subject 7/10 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.5461\u001b[0m       \u001b[32m0.5147\u001b[0m        \u001b[35m7.3855\u001b[0m  0.0200  2.2302\n",
      "      2        \u001b[36m0.3826\u001b[0m       \u001b[32m0.9118\u001b[0m        \u001b[35m0.2452\u001b[0m  0.0199  2.1514\n",
      "      3        \u001b[36m0.3804\u001b[0m       0.5772        3.1837  0.0197  2.2264\n",
      "      4        \u001b[36m0.3380\u001b[0m       0.5074        2.7005  0.0192  2.2567\n",
      "      5        \u001b[36m0.2619\u001b[0m       0.5772        2.6984  0.0187  2.1180\n",
      "      6        \u001b[36m0.2431\u001b[0m       \u001b[32m0.9375\u001b[0m        \u001b[35m0.2211\u001b[0m  0.0179  2.1469\n",
      "      7        0.2718       \u001b[32m0.9522\u001b[0m        \u001b[35m0.2063\u001b[0m  0.0171  2.1793\n",
      "      8        \u001b[36m0.2138\u001b[0m       0.6765        1.4426  0.0161  2.1519\n",
      "      9        0.2211       0.7463        0.9400  0.0150  2.2120\n",
      "     10        \u001b[36m0.1820\u001b[0m       0.9118        0.2449  0.0138  2.1302\n",
      "     11        0.2190       0.9081        0.2624  0.0126  2.2110\n",
      "     12        0.2379       0.8787        0.2682  0.0113  2.1202\n",
      "     13        0.1945       0.5551        2.2319  0.0100  2.1185\n",
      "     14        \u001b[36m0.1807\u001b[0m       0.9301        0.2177  0.0087  2.1641\n",
      "     15        \u001b[36m0.1448\u001b[0m       0.8934        0.2908  0.0074  2.1826\n",
      "     16        \u001b[36m0.1130\u001b[0m       0.8382        0.4696  0.0062  2.1316\n",
      "     17        \u001b[36m0.1056\u001b[0m       \u001b[32m0.9706\u001b[0m        \u001b[35m0.1064\u001b[0m  0.0050  2.2129\n",
      "     18        0.1294       0.9228        0.1569  0.0039  2.1821\n",
      "     19        \u001b[36m0.0764\u001b[0m       0.8934        0.2580  0.0029  2.2668\n",
      "     20        \u001b[36m0.0624\u001b[0m       \u001b[32m0.9779\u001b[0m        \u001b[35m0.0767\u001b[0m  0.0021  2.1894\n",
      "     21        \u001b[36m0.0531\u001b[0m       0.9632        0.0788  0.0013  2.3018\n",
      "     22        0.0634       0.9779        \u001b[35m0.0712\u001b[0m  0.0008  2.1898\n",
      "     23        0.0751       0.9743        \u001b[35m0.0639\u001b[0m  0.0003  2.2201\n",
      "     24        0.0750       \u001b[32m0.9816\u001b[0m        \u001b[35m0.0624\u001b[0m  0.0001  2.1482\n",
      "     25        0.0628       0.9816        0.0639  0.0000  2.1511\n",
      "Best Validation Accuracy for Subject 7: 0.982\n",
      "\n",
      "=== Subject 8/10 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.9305\u001b[0m       \u001b[32m0.5147\u001b[0m        \u001b[35m1.1018\u001b[0m  0.0200  2.1614\n",
      "      2        \u001b[36m0.7080\u001b[0m       \u001b[32m0.5404\u001b[0m        \u001b[35m0.7080\u001b[0m  0.0199  2.1403\n",
      "      3        \u001b[36m0.6581\u001b[0m       \u001b[32m0.5809\u001b[0m        \u001b[35m0.7027\u001b[0m  0.0197  2.1633\n",
      "      4        \u001b[36m0.6220\u001b[0m       \u001b[32m0.6213\u001b[0m        \u001b[35m0.6886\u001b[0m  0.0192  2.2025\n",
      "      5        0.6441       0.5662        0.8033  0.0187  2.2456\n",
      "      6        \u001b[36m0.6177\u001b[0m       0.5993        0.7787  0.0179  2.1792\n",
      "      7        \u001b[36m0.6043\u001b[0m       0.6029        \u001b[35m0.6703\u001b[0m  0.0171  2.1871\n",
      "      8        \u001b[36m0.5866\u001b[0m       0.6176        \u001b[35m0.6653\u001b[0m  0.0161  2.1898\n",
      "      9        \u001b[36m0.5770\u001b[0m       \u001b[32m0.6691\u001b[0m        0.6779  0.0150  2.1842\n",
      "     10        \u001b[36m0.5551\u001b[0m       \u001b[32m0.7169\u001b[0m        \u001b[35m0.5769\u001b[0m  0.0138  2.1655\n",
      "     11        \u001b[36m0.4909\u001b[0m       0.6360        0.8169  0.0126  2.1666\n",
      "     12        \u001b[36m0.4289\u001b[0m       \u001b[32m0.8051\u001b[0m        \u001b[35m0.4184\u001b[0m  0.0113  2.2497\n",
      "     13        \u001b[36m0.3957\u001b[0m       0.5551        1.5039  0.0100  2.1568\n",
      "     14        \u001b[36m0.3697\u001b[0m       0.5147        2.1397  0.0087  2.1962\n",
      "     15        \u001b[36m0.3072\u001b[0m       0.7096        0.8064  0.0074  2.1649\n",
      "     16        \u001b[36m0.2492\u001b[0m       0.7904        0.4962  0.0062  2.1598\n",
      "     17        \u001b[36m0.2265\u001b[0m       0.7941        0.5422  0.0050  2.2101\n",
      "     18        \u001b[36m0.2023\u001b[0m       0.7316        0.8283  0.0039  2.1574\n",
      "     19        \u001b[36m0.1860\u001b[0m       \u001b[32m0.9118\u001b[0m        \u001b[35m0.2117\u001b[0m  0.0029  2.1579\n",
      "     20        \u001b[36m0.1584\u001b[0m       \u001b[32m0.9265\u001b[0m        \u001b[35m0.2020\u001b[0m  0.0021  2.1496\n",
      "     21        0.1868       0.8713        0.2997  0.0013  2.1710\n",
      "     22        \u001b[36m0.1519\u001b[0m       \u001b[32m0.9375\u001b[0m        \u001b[35m0.1680\u001b[0m  0.0008  2.1768\n",
      "     23        \u001b[36m0.1438\u001b[0m       0.9228        0.1907  0.0003  2.1587\n",
      "     24        \u001b[36m0.1200\u001b[0m       0.9301        0.1754  0.0001  2.1705\n",
      "     25        0.1319       0.9375        0.1703  0.0000  2.2015\n",
      "Best Validation Accuracy for Subject 8: 0.938\n",
      "\n",
      "=== Subject 9/10 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m0.8066\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m3.0756\u001b[0m  0.0200  2.1917\n",
      "      2        \u001b[36m0.5407\u001b[0m       \u001b[32m0.7316\u001b[0m        \u001b[35m0.4593\u001b[0m  0.0199  2.1449\n",
      "      3        \u001b[36m0.4842\u001b[0m       \u001b[32m0.7904\u001b[0m        \u001b[35m0.4267\u001b[0m  0.0197  2.1373\n",
      "      4        \u001b[36m0.4607\u001b[0m       0.5110        1.6337  0.0192  2.1861\n",
      "      5        0.4685       0.5000        2.4917  0.0187  2.1438\n",
      "      6        \u001b[36m0.3967\u001b[0m       0.6250        0.8284  0.0179  2.1642\n",
      "      7        0.4229       \u001b[32m0.7941\u001b[0m        \u001b[35m0.4241\u001b[0m  0.0171  2.1822\n",
      "      8        \u001b[36m0.3614\u001b[0m       \u001b[32m0.8015\u001b[0m        \u001b[35m0.4201\u001b[0m  0.0161  2.1539\n",
      "      9        \u001b[36m0.3503\u001b[0m       \u001b[32m0.8456\u001b[0m        \u001b[35m0.3437\u001b[0m  0.0150  2.1404\n",
      "     10        \u001b[36m0.3328\u001b[0m       0.8162        0.4388  0.0138  2.1668\n",
      "     11        \u001b[36m0.3176\u001b[0m       \u001b[32m0.8787\u001b[0m        \u001b[35m0.2929\u001b[0m  0.0126  2.1543\n",
      "     12        0.3220       0.8713        0.3270  0.0113  2.1633\n",
      "     13        \u001b[36m0.2898\u001b[0m       0.6213        1.1431  0.0100  2.1872\n",
      "     14        \u001b[36m0.2772\u001b[0m       \u001b[32m0.8824\u001b[0m        \u001b[35m0.2260\u001b[0m  0.0087  2.1378\n",
      "     15        \u001b[36m0.2487\u001b[0m       0.8235        0.4310  0.0074  2.1714\n",
      "     16        0.2544       \u001b[32m0.9265\u001b[0m        \u001b[35m0.1869\u001b[0m  0.0062  2.1500\n",
      "     17        \u001b[36m0.2174\u001b[0m       0.8493        0.4007  0.0050  2.1457\n",
      "     18        \u001b[36m0.1889\u001b[0m       \u001b[32m0.9301\u001b[0m        \u001b[35m0.1642\u001b[0m  0.0039  2.1814\n",
      "     19        \u001b[36m0.1642\u001b[0m       0.8162        0.4145  0.0029  2.1456\n",
      "     20        \u001b[36m0.1440\u001b[0m       0.8971        0.2280  0.0021  2.1679\n",
      "     21        0.1441       \u001b[32m0.9632\u001b[0m        \u001b[35m0.0941\u001b[0m  0.0013  2.1821\n",
      "     22        \u001b[36m0.1127\u001b[0m       0.9485        0.1320  0.0008  2.1679\n",
      "     23        \u001b[36m0.0958\u001b[0m       0.9412        0.1429  0.0003  2.1343\n",
      "     24        0.1104       0.9154        0.2250  0.0001  2.1722\n",
      "     25        0.0985       0.9375        0.1531  0.0000  2.1502\n",
      "Best Validation Accuracy for Subject 9: 0.963\n",
      "\n",
      "=== Subject 10/10 ===\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr     dur\n",
      "-------  ------------  -----------  ------------  ------  ------\n",
      "      1        \u001b[36m1.4888\u001b[0m       \u001b[32m0.6618\u001b[0m        \u001b[35m1.0767\u001b[0m  0.0200  2.1482\n",
      "      2        \u001b[36m0.6665\u001b[0m       0.6029        \u001b[35m0.9399\u001b[0m  0.0199  2.1559\n",
      "      3        \u001b[36m0.5316\u001b[0m       \u001b[32m0.7279\u001b[0m        0.9714  0.0197  2.1338\n",
      "      4        \u001b[36m0.4629\u001b[0m       0.6029        1.1361  0.0192  2.1427\n",
      "      5        0.4745       \u001b[32m0.8272\u001b[0m        \u001b[35m0.3393\u001b[0m  0.0187  2.1879\n",
      "      6        \u001b[36m0.3896\u001b[0m       0.6801        0.9279  0.0179  2.1515\n",
      "      7        0.4599       0.7574        0.4802  0.0171  2.1668\n",
      "      8        0.4018       0.8199        0.3654  0.0161  2.1348\n",
      "      9        \u001b[36m0.3821\u001b[0m       0.5919        0.9809  0.0150  2.1746\n",
      "     10        \u001b[36m0.3221\u001b[0m       \u001b[32m0.8309\u001b[0m        0.4261  0.0138  2.1491\n",
      "     11        0.3519       0.7831        0.4436  0.0126  2.1599\n",
      "     12        \u001b[36m0.2729\u001b[0m       0.7463        0.6896  0.0113  2.1534\n",
      "     13        \u001b[36m0.2569\u001b[0m       0.6654        1.2541  0.0100  2.1531\n",
      "     14        \u001b[36m0.2218\u001b[0m       0.5147        2.6124  0.0087  2.1513\n",
      "     15        0.2514       \u001b[32m0.9191\u001b[0m        \u001b[35m0.2076\u001b[0m  0.0074  2.1351\n",
      "     16        \u001b[36m0.2117\u001b[0m       0.9191        \u001b[35m0.1758\u001b[0m  0.0062  2.1841\n",
      "     17        \u001b[36m0.1720\u001b[0m       0.8860        0.2772  0.0050  2.1714\n",
      "     18        0.1778       0.8493        0.3269  0.0039  2.1709\n",
      "     19        \u001b[36m0.1660\u001b[0m       \u001b[32m0.9265\u001b[0m        \u001b[35m0.1598\u001b[0m  0.0029  2.3145\n",
      "     20        0.1736       0.9265        0.1727  0.0021  2.3471\n",
      "     21        0.1799       \u001b[32m0.9301\u001b[0m        0.1649  0.0013  2.1346\n",
      "     22        0.1714       0.9191        \u001b[35m0.1532\u001b[0m  0.0008  2.1397\n",
      "     23        \u001b[36m0.1519\u001b[0m       0.9301        \u001b[35m0.1440\u001b[0m  0.0003  2.1560\n",
      "     24        \u001b[36m0.1395\u001b[0m       0.9301        \u001b[35m0.1432\u001b[0m  0.0001  2.1355\n",
      "     25        \u001b[36m0.1291\u001b[0m       \u001b[32m0.9338\u001b[0m        \u001b[35m0.1426\u001b[0m  0.0000  2.1639\n",
      "Best Validation Accuracy for Subject 10: 0.934\n",
      "\n",
      "=== Mean Within-Subject Accuracy: 0.944 ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.9375,\n",
       "  1.0,\n",
       "  0.9411764705882353,\n",
       "  0.8235294117647058,\n",
       "  0.9522058823529411,\n",
       "  0.9669117647058824,\n",
       "  0.9816176470588235,\n",
       "  0.9375,\n",
       "  0.9632352941176471,\n",
       "  0.9338235294117647],\n",
       " np.float64(0.94375))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_within_subject_adaptive(windows_datasets_list, AdaptiveEEGNet, n_epochs=25, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
