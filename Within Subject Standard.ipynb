{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from mne.decoding import CSP\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False                    # global variable to suppress output display of MNE functions\n",
    "mne.set_log_level(verbose=verbose) # to suppress large info outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = None  # for multicore parallel processing, set it to 1 if cause memory issues, for full utilization set to -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Conversion to MNE Datatypes\n",
    "[Mike Cohen Tutorials link for EEG Preprocessing](https://www.youtube.com/watch?v=uWB5tjhataY&list=PLn0OLiymPak2gDD-VDA90w9_iGDgOOb2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = globals()['_dh'][0]  # a hack to get path of current folder in which jupyter file is located\n",
    "data_path = os.path.join(current_folder, r\"C:\\Users\\User\\Documents\\GitHub\\Frequency-Adaptive-Temporal-Kernel-EEGNet\\Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_files   = glob.glob(data_path + '/*T.mat')\n",
    "len(training_files)     # if  return zero,then no file is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have modified the labels values from [1, 2] to [0, 1] as pytorch \n",
    "# expects labels/classes to be in [0, n_classes-1] format\n",
    "def get_mne_epochs(filepath, verbose=verbose, t_start=2, fs=512, mode='train'):\n",
    "    '''\n",
    "    This function reads the EEG data from .mat file and convert it to MNE-Python Compatible epochs\n",
    "    data structure. It takes data from [0, 8] sec range and return it by setting t = 0 at cue onset\n",
    "    i.e. 3 seconds and dropping first two seconds so the output data is in [-1.0, 5.0] sec range. The\n",
    "    Details can be found in the preprocessing section of the attached document\n",
    "    '''\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    eeg_data= mat_data['RawEEGData']\n",
    "    idx_start = fs*t_start      \n",
    "    eeg_data = eeg_data[:, :, idx_start:]\n",
    "    event_id = {'left-hand': 0, 'right-hand': 1} # pytorch expects labels in [0, n_classes-1]\n",
    "    channel_names = ['F3', 'FC3', 'C3', 'CP3', 'P3', 'FCz', 'CPz', 'F4', 'FC4', 'C4', 'CP4', 'P4']\n",
    "    info = mne.create_info(ch_names=channel_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, verbose=verbose, tmin=t_start-3.0)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None) \n",
    "    epochs.apply_baseline(baseline=(-.250, 0)) # linear baseline correction\n",
    "    \n",
    "    if mode == 'train': # this in only applicable for training data\n",
    "        epochs.event_id = event_id \n",
    "        epochs.events[:,2] = mat_data['Labels'].ravel() - 1    \n",
    "    return epochs \n",
    "\n",
    "def get_labels(filepath):\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    return mat_data['Labels'].ravel() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG Data:  (80, 12, 3072) \t Shape of Labels:  (80,)\n"
     ]
    }
   ],
   "source": [
    "epochs, labels = get_mne_epochs(training_files[0], verbose=verbose), get_labels(training_files[0])\n",
    "data = epochs.get_data()\n",
    "print('Shape of EEG Data: ', data.shape, '\\t Shape of Labels: ', labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading original data\n",
    "epochs_list_train = []\n",
    "for i in training_files:\n",
    "    epochs_list_train.append(get_mne_epochs(i, verbose=verbose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Braindecode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's Training Time with [0.5, 4.5] sec and 2sec window with 125ms stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets per subject: 10\n",
      "Total windows for first subject: 1360\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datautil import create_from_mne_epochs\n",
    "\n",
    "window_size = 1024   # 2 sec windows\n",
    "window_stride = 64   # 125 ms stride\n",
    "\n",
    "windows_datasets_list = []\n",
    "\n",
    "for epoch in epochs_list_train:\n",
    "    # Create windows per subject\n",
    "    windows_dataset = create_from_mne_epochs(\n",
    "        [epoch.crop(tmin=0.5, tmax=4.5, include_tmax=False)],\n",
    "        window_size_samples=window_size,\n",
    "        window_stride_samples=window_stride,\n",
    "        drop_last_window=False\n",
    "    )\n",
    "    # Add labels as a separate attribute\n",
    "    windows_dataset.update_description = pd.DataFrame(\n",
    "        data=np.concatenate([d.y for d in windows_dataset.datasets]),\n",
    "        columns=['labels']\n",
    "    )\n",
    "    windows_datasets_list.append(windows_dataset)\n",
    "\n",
    "print(\"Datasets per subject:\", len(windows_datasets_list))\n",
    "print(\"Total windows for first subject:\", len(windows_datasets_list[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.preprocessing import exponential_moving_standardize\n",
    "\n",
    "low_cut_hz = 8.   # low cut frequency for filtering\n",
    "high_cut_hz = 32. # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\n",
    "    \"\"\"Apply exponential moving standardization to MNE epochs inplace.\"\"\"\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        data[i] = exponential_moving_standardize(\n",
    "            data[i], factor_new=factor_new, init_block_size=init_block_size\n",
    "        )\n",
    "    epochs._data = data\n",
    "    return epochs\n",
    "\n",
    "# Apply preprocessing to each dataset\n",
    "for windows_dataset in windows_datasets_list:\n",
    "    # Extract the underlying MNE Epochs object\n",
    "    epochs = windows_dataset.datasets[0].windows\n",
    "    epochs.load_data()  # Ensure data is loaded into memory\n",
    "\n",
    "    # 1) Keep only EEG channels\n",
    "    epochs.pick_types(eeg=True)\n",
    "\n",
    "    # 2) Bandpass filter\n",
    "    epochs.filter(l_freq=low_cut_hz, h_freq=high_cut_hz)\n",
    "\n",
    "    # 3) Exponential moving standardization\n",
    "    custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from braindecode.preprocessing import exponential_moving_standardize\\nfrom braindecode.preprocessing import MNEPreproc, NumpyPreproc, preprocess\\n\\nlow_cut_hz = 8.  # low cut frequency for filtering\\nhigh_cut_hz = 32.  # high cut frequency for filtering\\n# Parameters for exponential moving standardization\\nfactor_new = 1e-3\\ninit_block_size = 1000\\n\\ndef custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\\n    data = epochs.get_data()\\n    for i in range(len(data)):\\n        epochs._data[i] = exponential_moving_standardize(data[i], \\n                        factor_new=factor_new, init_block_size=init_block_size)\\n    return epochs\\n\\npreprocessors = [\\n    # keep only EEG sensors\\n    MNEPreproc(fn='pick_types', eeg=True, meg=False, stim=False),\\n    # bandpass filter\\n    MNEPreproc(fn='filter', l_freq=low_cut_hz, h_freq=high_cut_hz),\\n    # exponential moving standardization\\n    MNEPreproc(fn=custom_exp_moving_std_fn, factor_new=factor_new,\\n        init_block_size=init_block_size)\\n]\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from braindecode.preprocessing import exponential_moving_standardize\n",
    "from braindecode.preprocessing import MNEPreproc, NumpyPreproc, preprocess\n",
    "\n",
    "low_cut_hz = 8.  # low cut frequency for filtering\n",
    "high_cut_hz = 32.  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        epochs._data[i] = exponential_moving_standardize(data[i], \n",
    "                        factor_new=factor_new, init_block_size=init_block_size)\n",
    "    return epochs\n",
    "\n",
    "preprocessors = [\n",
    "    # keep only EEG sensors\n",
    "    MNEPreproc(fn='pick_types', eeg=True, meg=False, stim=False),\n",
    "    # bandpass filter\n",
    "    MNEPreproc(fn='filter', l_freq=low_cut_hz, h_freq=high_cut_hz),\n",
    "    # exponential moving standardization\n",
    "    MNEPreproc(fn=custom_exp_moving_std_fn, factor_new=factor_new,\n",
    "        init_block_size=init_block_size)\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for windows_dataset in windows_datasets_list: \\n    preprocess(windows_dataset, preprocessors)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for windows_dataset in windows_datasets_list: \n",
    "    preprocess(windows_dataset, preprocessors)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #64\n",
    "n_epochs = 25 #25 #20 #25 use few epochs for quick verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, EEGNetv4\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes=2\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_chans = windows_datasets_list[0][0][0].shape[0]\n",
    "input_window_samples = windows_datasets_list[0][0][0].shape[1]\n",
    "\n",
    "model = EEGNetv4(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    n_times = window_size, #input_window_samples,\n",
    "    final_conv_length='auto',\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "lr = 1 * 0.02 #0.01 \n",
    "weight_decay = 0.5 * 0.001\n",
    "\n",
    "clfs_list = []\n",
    "for i in range(len(epochs_list_train)):\n",
    "    clfs_list.append(\n",
    "        EEGClassifier(\n",
    "                    model,\n",
    "                    criterion = torch.nn.CrossEntropyLoss(),\n",
    "                    optimizer=torch.optim.AdamW,\n",
    "                    #train_split=predefined_split(train_set),  # using valid_set for validation\n",
    "                    optimizer__lr=lr,\n",
    "                    optimizer__weight_decay=weight_decay,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[\n",
    "                        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "                    ],\n",
    "                    device=device,\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def training_function(subject_index=0):\\n    print(\\'\\n\\', \\'#\\'*25, \\'Training for Subject:\\', subject_index+1, \\'#\\'*25, \\'\\n\\')\\n    dataset = windows_datasets_list[subject_index]\\n    clfs_list[subject_index].fit(dataset, y=dataset.description.labels, epochs=n_epochs);\\n    best_validation_acc = clfs_list[subject_index].callbacks_[4][1].best_score_ # a hack to get best validation accuracy\\n    best_validation_kappa = (2*best_validation_acc)-1\\n    print(\"Best Cross Validation Kappa Score: {:.2f}\".format(best_validation_kappa))'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def training_function(subject_index=0):\n",
    "    print('\\n', '#'*25, 'Training for Subject:', subject_index+1, '#'*25, '\\n')\n",
    "    dataset = windows_datasets_list[subject_index]\n",
    "    clfs_list[subject_index].fit(dataset, y=dataset.description.labels, epochs=n_epochs);\n",
    "    best_validation_acc = clfs_list[subject_index].callbacks_[4][1].best_score_ # a hack to get best validation accuracy\n",
    "    best_validation_kappa = (2*best_validation_acc)-1\n",
    "    print(\"Best Cross Validation Kappa Score: {:.2f}\".format(best_validation_kappa))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(subject_index=0):\n",
    "    print('\\n', '#'*25, 'Training for Subject:', subject_index+1, '#'*25, '\\n')\n",
    "    \n",
    "    dataset = windows_datasets_list[subject_index]\n",
    "    \n",
    "    # Get labels directly from the dataset\n",
    "    y = np.concatenate([d.y for d in dataset.datasets])\n",
    "    \n",
    "    # Train the model\n",
    "    clfs_list[subject_index].fit(dataset, y=y, epochs=n_epochs)\n",
    "    \n",
    "    # Get validation accuracy from history\n",
    "    history = clfs_list[subject_index].history\n",
    "    # Convert to a list of dicts\n",
    "    valid_accs = [entry['valid_accuracy'] for entry in history if 'valid_accuracy' in entry]\n",
    "    \n",
    "    if valid_accs:\n",
    "        best_val_acc = max(valid_accs)\n",
    "        best_val_kappa = (2 * best_val_acc) - 1\n",
    "        print(f\"Best Cross Validation Kappa Score: {best_val_kappa:.2f}\")\n",
    "    else:\n",
    "        print(\"Validation accuracy not available in history.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGNetv4 (EEGNetv4)                                          [1, 12, 1024]             [1, 2]                    --                        --\n",
      "├─Ensure4d (ensuredims): 1-1                                 [1, 12, 1024]             [1, 12, 1024, 1]          --                        --\n",
      "├─Rearrange (dimshuffle): 1-2                                [1, 12, 1024, 1]          [1, 1, 12, 1024]          --                        --\n",
      "├─Conv2d (conv_temporal): 1-3                                [1, 1, 12, 1024]          [1, 8, 12, 1025]          512                       [1, 64]\n",
      "├─BatchNorm2d (bnorm_temporal): 1-4                          [1, 8, 12, 1025]          [1, 8, 12, 1025]          16                        --\n",
      "├─ParametrizedConv2dWithConstraint (conv_spatial): 1-5       [1, 8, 12, 1025]          [1, 16, 1, 1025]          --                        [12, 1]\n",
      "│    └─ModuleDict (parametrizations): 2-1                    --                        --                        --                        --\n",
      "│    │    └─ParametrizationList (weight): 3-1                --                        [16, 1, 12, 1]            192                       --\n",
      "├─BatchNorm2d (bnorm_1): 1-6                                 [1, 16, 1, 1025]          [1, 16, 1, 1025]          32                        --\n",
      "├─ELU (elu_1): 1-7                                           [1, 16, 1, 1025]          [1, 16, 1, 1025]          --                        --\n",
      "├─AvgPool2d (pool_1): 1-8                                    [1, 16, 1, 1025]          [1, 16, 1, 256]           --                        [1, 4]\n",
      "├─Dropout (drop_1): 1-9                                      [1, 16, 1, 256]           [1, 16, 1, 256]           --                        --\n",
      "├─Conv2d (conv_separable_depth): 1-10                        [1, 16, 1, 256]           [1, 16, 1, 257]           256                       [1, 16]\n",
      "├─Conv2d (conv_separable_point): 1-11                        [1, 16, 1, 257]           [1, 16, 1, 257]           256                       [1, 1]\n",
      "├─BatchNorm2d (bnorm_2): 1-12                                [1, 16, 1, 257]           [1, 16, 1, 257]           32                        --\n",
      "├─ELU (elu_2): 1-13                                          [1, 16, 1, 257]           [1, 16, 1, 257]           --                        --\n",
      "├─AvgPool2d (pool_2): 1-14                                   [1, 16, 1, 257]           [1, 16, 1, 32]            --                        [1, 8]\n",
      "├─Dropout (drop_2): 1-15                                     [1, 16, 1, 32]            [1, 16, 1, 32]            --                        --\n",
      "├─Sequential (final_layer): 1-16                             [1, 16, 1, 32]            [1, 2]                    --                        --\n",
      "│    └─Conv2d (conv_classifier): 2-2                         [1, 16, 1, 32]            [1, 2, 1, 1]              1,026                     [1, 32]\n",
      "│    └─Rearrange (permute_back): 2-3                         [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
      "│    └─SqueezeFinalOutput (squeeze): 2-4                     [1, 2, 1, 1]              [1, 2]                    --                        --\n",
      "│    │    └─Rearrange (squeeze): 3-2                         [1, 2, 1, 1]              [1, 2, 1]                 --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 2,322\n",
      "Trainable params: 2,322\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 6.43\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 1.80\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 1.86\n",
      "================================================================================================================================================================\n",
      "CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "print(clfs_list[0].module)        # show model architecture\n",
    "print(clfs_list[0].criterion)     # show loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######################### Training for Subject: 1 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m0.7370\u001b[0m       \u001b[35m0.4375\u001b[0m            \u001b[31m0.4375\u001b[0m       \u001b[94m15.7079\u001b[0m  0.0200  1.3855\n",
      "      2            0.5000        \u001b[32m0.5471\u001b[0m       0.4375            0.4375       44.3179  0.0199  1.4112\n",
      "      3            0.5000        \u001b[32m0.4531\u001b[0m       0.4375            0.4375       35.3165  0.0197  1.3290\n",
      "      4            0.5000        \u001b[32m0.4174\u001b[0m       0.4375            0.4375       51.6970  0.0192  1.3217\n",
      "      5            0.5000        0.4339       0.4375            0.4375       29.9006  0.0187  1.2852\n",
      "      6            0.5000        0.5354       0.4375            0.4375       \u001b[94m14.9388\u001b[0m  0.0179  1.2438\n",
      "      7            0.5000        \u001b[32m0.4061\u001b[0m       \u001b[35m0.5000\u001b[0m            \u001b[31m0.5000\u001b[0m       18.4518  0.0171  1.2850\n",
      "      8            0.5000        \u001b[32m0.3835\u001b[0m       0.5000            0.5000       20.4626  0.0161  7.0708\n",
      "      9            0.5000        0.4150       0.5000            0.5000       17.2680  0.0150  5.4462\n",
      "     10            0.5000        \u001b[32m0.3615\u001b[0m       0.5000            0.5000        \u001b[94m7.1220\u001b[0m  0.0138  1.3010\n",
      "     11            0.5000        \u001b[32m0.3462\u001b[0m       0.5000            0.5000       11.3283  0.0126  1.2931\n",
      "     12            0.5000        \u001b[32m0.2865\u001b[0m       0.5000            0.5000       18.5893  0.0113  1.3552\n",
      "     13            0.5000        0.3029       0.5000            0.5000        9.0750  0.0100  1.3642\n",
      "     14            0.5000        0.3674       0.5000            0.5000        \u001b[94m5.6405\u001b[0m  0.0087  1.2680\n",
      "     15            0.5000        0.2914       0.5000            0.5000        6.8855  0.0074  1.2765\n",
      "     16            0.5000        \u001b[32m0.2596\u001b[0m       0.5000            0.5000        9.8136  0.0062  1.3726\n",
      "     17            0.5000        0.2810       0.5000            0.5000        8.2956  0.0050  1.2890\n",
      "     18            0.5000        0.2696       0.5000            0.5000       10.4355  0.0039  1.2618\n",
      "     19            0.5000        \u001b[32m0.2533\u001b[0m       0.5000            0.5000        6.8021  0.0029  1.3202\n",
      "     20            \u001b[36m0.5193\u001b[0m        \u001b[32m0.2492\u001b[0m       \u001b[35m0.9044\u001b[0m            \u001b[31m0.9044\u001b[0m        \u001b[94m4.4110\u001b[0m  0.0021  5.0793\n",
      "     21            0.5193        0.2555       0.9044            0.9044        4.4582  0.0013  6.4810\n",
      "     22            \u001b[36m0.5221\u001b[0m        \u001b[32m0.2453\u001b[0m       \u001b[35m0.9081\u001b[0m            \u001b[31m0.9081\u001b[0m        4.4374  0.0008  6.6777\n",
      "     23            \u001b[36m0.5386\u001b[0m        \u001b[32m0.2233\u001b[0m       \u001b[35m0.9154\u001b[0m            \u001b[31m0.9154\u001b[0m        \u001b[94m4.3627\u001b[0m  0.0003  7.0313\n",
      "     24            \u001b[36m0.5542\u001b[0m        0.2244       0.9118            0.9118        \u001b[94m4.3286\u001b[0m  0.0001  7.0123\n",
      "     25            \u001b[36m0.5643\u001b[0m        \u001b[32m0.2194\u001b[0m       0.9044            0.9044        \u001b[94m4.3234\u001b[0m  0.0000  7.1284\n",
      "Best Cross Validation Kappa Score: 0.83\n",
      "\n",
      " ######################### Training for Subject: 2 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m1.1399\u001b[0m       \u001b[35m0.5625\u001b[0m            \u001b[31m0.5625\u001b[0m       \u001b[94m11.6738\u001b[0m  0.0200  5.6678\n",
      "      2            \u001b[36m0.9577\u001b[0m        \u001b[32m0.0401\u001b[0m       \u001b[35m0.8199\u001b[0m            \u001b[31m0.8199\u001b[0m        \u001b[94m0.7578\u001b[0m  0.0199  1.3246\n",
      "      3            0.5000        0.0629       0.5000            0.5000       24.1932  0.0197  1.3121\n",
      "      4            0.5000        \u001b[32m0.0321\u001b[0m       0.5000            0.5000       13.0859  0.0192  1.3087\n",
      "      5            0.5018        \u001b[32m0.0178\u001b[0m       0.5000            0.5000       10.7193  0.0187  1.3490\n",
      "      6            0.7261        0.0233       0.5441            0.5441        2.1941  0.0179  1.3698\n",
      "      7            0.5478        0.0352       0.5000            0.5000        4.8545  0.0171  1.2923\n",
      "      8            0.5018        0.0241       0.5000            0.5000       10.7655  0.0161  1.3192\n",
      "      9            0.5000        \u001b[32m0.0141\u001b[0m       0.5000            0.5000       18.1880  0.0150  1.3588\n",
      "     10            0.5000        \u001b[32m0.0057\u001b[0m       0.5000            0.5000       17.2633  0.0138  1.3243\n",
      "     11            0.5000        \u001b[32m0.0045\u001b[0m       0.5000            0.5000       14.9161  0.0126  1.3154\n",
      "     12            0.5055        \u001b[32m0.0020\u001b[0m       0.5000            0.5000       10.4861  0.0113  1.3473\n",
      "     13            0.5009        0.0038       0.5000            0.5000       12.7879  0.0100  1.2692\n",
      "     14            0.5000        0.0178       0.5000            0.5000       26.0554  0.0087  1.3031\n",
      "     15            0.5386        0.0210       0.5000            0.5000        6.5255  0.0074  1.3335\n",
      "     16            0.5211        0.0239       0.5000            0.5000        7.5211  0.0062  1.2929\n",
      "     17            0.5101        0.0043       0.5000            0.5000       10.5456  0.0050  1.2961\n",
      "     18            0.5248        0.0028       0.5000            0.5000        7.4531  0.0039  1.3123\n",
      "     19            0.5156        0.0040       0.5000            0.5000        8.7191  0.0029  1.2894\n",
      "     20            \u001b[36m0.9991\u001b[0m        0.0031       \u001b[35m0.9412\u001b[0m            \u001b[31m0.9412\u001b[0m        \u001b[94m0.2026\u001b[0m  0.0021  1.3450\n",
      "     21            \u001b[36m1.0000\u001b[0m        0.0021       \u001b[35m0.9559\u001b[0m            \u001b[31m0.9559\u001b[0m        \u001b[94m0.1223\u001b[0m  0.0013  6.7965\n",
      "     22            0.9936        \u001b[32m0.0019\u001b[0m       0.9081            0.9081        0.3190  0.0008  6.5766\n",
      "     23            0.9991        0.0125       0.9449            0.9449        0.2029  0.0003  6.2990\n",
      "     24            1.0000        0.0026       \u001b[35m0.9669\u001b[0m            \u001b[31m0.9669\u001b[0m        \u001b[94m0.0863\u001b[0m  0.0001  6.6627\n",
      "     25            1.0000        \u001b[32m0.0004\u001b[0m       \u001b[35m0.9779\u001b[0m            \u001b[31m0.9779\u001b[0m        \u001b[94m0.0478\u001b[0m  0.0000  6.8006\n",
      "Best Cross Validation Kappa Score: 0.96\n",
      "\n",
      " ######################### Training for Subject: 3 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m3.3626\u001b[0m       \u001b[35m0.4375\u001b[0m            \u001b[31m0.4375\u001b[0m        \u001b[94m7.6574\u001b[0m  0.0200  6.3934\n",
      "      2            0.5000        \u001b[32m0.6926\u001b[0m       0.4375            0.4375        \u001b[94m7.6277\u001b[0m  0.0199  6.8935\n",
      "      3            0.5000        \u001b[32m0.5814\u001b[0m       0.4375            0.4375        \u001b[94m6.3685\u001b[0m  0.0197  6.7018\n",
      "      4            \u001b[36m0.9458\u001b[0m        \u001b[32m0.3139\u001b[0m       0.4375            0.4375        8.6415  0.0192  6.7830\n",
      "      5            0.5156        \u001b[32m0.1822\u001b[0m       \u001b[35m0.8162\u001b[0m            \u001b[31m0.8162\u001b[0m        \u001b[94m4.2774\u001b[0m  0.0187  6.8314\n",
      "      6            0.9329        \u001b[32m0.1518\u001b[0m       0.4375            0.4375       18.1487  0.0179  7.1484\n",
      "      7            0.6737        0.1527       0.6875            0.6875       11.6820  0.0171  6.7590\n",
      "      8            0.5009        0.1846       0.4375            0.4375       25.3852  0.0161  6.3648\n",
      "      9            0.5423        \u001b[32m0.1118\u001b[0m       0.4375            0.4375       25.7831  0.0150  7.2459\n",
      "     10            0.5653        \u001b[32m0.0985\u001b[0m       0.4375            0.4375       20.9393  0.0138  6.5253\n",
      "     11            0.8033        0.1822       0.5478            0.5478       19.4583  0.0126  6.2284\n",
      "     12            0.7528        0.1163       0.6029            0.6029       16.9899  0.0113  6.4719\n",
      "     13            \u001b[36m0.9835\u001b[0m        \u001b[32m0.0826\u001b[0m       0.8088            0.8088       13.9932  0.0100  6.1045\n",
      "     14            0.9559        \u001b[32m0.0798\u001b[0m       0.8015            0.8015       11.2632  0.0087  1.3025\n",
      "     15            0.8566        \u001b[32m0.0774\u001b[0m       0.8015            0.8015       11.8252  0.0074  1.2962\n",
      "     16            0.6884        0.0887       0.4375            0.4375       21.0517  0.0062  1.3593\n",
      "     17            0.9513        \u001b[32m0.0708\u001b[0m       0.8051            0.8051       13.1532  0.0050  1.3071\n",
      "     18            0.9219        0.1027       0.6838            0.6838       14.5128  0.0039  1.3204\n",
      "     19            0.8309        0.0854       0.7684            0.7684       13.1783  0.0029  1.3027\n",
      "     20            0.9669        \u001b[32m0.0547\u001b[0m       0.8051            0.8051       14.2032  0.0021  1.2857\n",
      "     21            0.9835        0.0567       0.7831            0.7831       14.8536  0.0013  1.3010\n",
      "     22            0.9605        \u001b[32m0.0469\u001b[0m       0.8051            0.8051       14.4306  0.0008  1.8011\n",
      "     23            0.9835        0.0550       0.7868            0.7868       14.9491  0.0003  6.7839\n",
      "     24            \u001b[36m0.9844\u001b[0m        0.0629       0.7537            0.7537       15.1856  0.0001  6.1146\n",
      "     25            0.9844        0.0595       0.7463            0.7463       15.3474  0.0000  1.3015\n",
      "Best Cross Validation Kappa Score: 0.63\n",
      "\n",
      " ######################### Training for Subject: 4 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5147\u001b[0m        \u001b[32m0.7548\u001b[0m       \u001b[35m0.5000\u001b[0m            \u001b[31m0.5000\u001b[0m        \u001b[94m1.6949\u001b[0m  0.0200  1.2824\n",
      "      2            0.5000        \u001b[32m0.5889\u001b[0m       0.4375            0.4375        4.0104  0.0199  1.3132\n",
      "      3            \u001b[36m0.5165\u001b[0m        \u001b[32m0.5431\u001b[0m       0.5000            0.5000        2.2963  0.0197  1.3186\n",
      "      4            0.5000        \u001b[32m0.4112\u001b[0m       0.5000            0.5000        6.7737  0.0192  1.2929\n",
      "      5            0.5000        \u001b[32m0.3652\u001b[0m       0.5000            0.5000       13.4249  0.0187  1.2863\n",
      "      6            0.5000        \u001b[32m0.2932\u001b[0m       0.5000            0.5000       16.6395  0.0179  1.3550\n",
      "      7            0.5165        \u001b[32m0.2908\u001b[0m       0.5000            0.5000        7.3475  0.0171  1.3293\n",
      "      8            0.5000        0.3954       0.4375            0.4375        8.1317  0.0161  1.2807\n",
      "      9            \u001b[36m0.5368\u001b[0m        \u001b[32m0.2309\u001b[0m       0.4375            0.4375        5.5010  0.0150  1.2706\n",
      "     10            0.5009        \u001b[32m0.1844\u001b[0m       0.4375            0.4375        6.9806  0.0138  1.3399\n",
      "     11            \u001b[36m0.7528\u001b[0m        0.2018       0.3750            0.3750        2.4963  0.0126  1.3345\n",
      "     12            0.5423        \u001b[32m0.1369\u001b[0m       0.4779            0.4779        5.3065  0.0113  1.3014\n",
      "     13            0.5340        \u001b[32m0.1093\u001b[0m       0.5000            0.5000        6.2881  0.0100  1.2956\n",
      "     14            0.5386        \u001b[32m0.1032\u001b[0m       0.4779            0.4779        4.7703  0.0087  1.3374\n",
      "     15            0.5469        \u001b[32m0.0918\u001b[0m       \u001b[35m0.5147\u001b[0m            \u001b[31m0.5147\u001b[0m        4.2608  0.0074  1.2653\n",
      "     16            0.5386        \u001b[32m0.0914\u001b[0m       0.4265            0.4265        6.2297  0.0062  1.3637\n",
      "     17            0.5441        \u001b[32m0.0726\u001b[0m       0.4559            0.4559        5.8370  0.0050  1.3601\n",
      "     18            \u001b[36m0.9890\u001b[0m        \u001b[32m0.0694\u001b[0m       0.5110            0.5110        5.4062  0.0039  1.3554\n",
      "     19            0.6544        0.0900       \u001b[35m0.5809\u001b[0m            \u001b[31m0.5809\u001b[0m        3.6275  0.0029  1.3118\n",
      "     20            0.9789        0.0728       0.4779            0.4779        6.8918  0.0021  1.2918\n",
      "     21            0.9375        \u001b[32m0.0536\u001b[0m       0.4375            0.4375        8.1774  0.0013  1.2902\n",
      "     22            0.9715        0.0774       0.4706            0.4706        7.4132  0.0008  1.3630\n",
      "     23            0.9476        0.0642       0.4375            0.4375        8.0888  0.0003  1.3330\n",
      "     24            0.9301        0.0591       0.4375            0.4375        8.3911  0.0001  1.3031\n",
      "     25            0.9347        0.0658       0.4375            0.4375        8.3050  0.0000  1.3018\n",
      "Best Cross Validation Kappa Score: 0.16\n",
      "\n",
      " ######################### Training for Subject: 5 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m0.8268\u001b[0m       \u001b[35m0.5625\u001b[0m            \u001b[31m0.5625\u001b[0m        \u001b[94m3.8354\u001b[0m  0.0200  1.3063\n",
      "      2            0.5000        \u001b[32m0.6248\u001b[0m       0.5625            0.5625        4.0619  0.0199  1.3134\n",
      "      3            0.5000        \u001b[32m0.5207\u001b[0m       0.5000            0.5000        \u001b[94m2.0973\u001b[0m  0.0197  1.3482\n",
      "      4            0.5000        \u001b[32m0.3792\u001b[0m       0.4669            0.4669        3.8959  0.0192  1.3304\n",
      "      5            \u001b[36m0.5175\u001b[0m        \u001b[32m0.3671\u001b[0m       0.4301            0.4301        \u001b[94m2.0327\u001b[0m  0.0187  1.3164\n",
      "      6            \u001b[36m0.5726\u001b[0m        \u001b[32m0.2643\u001b[0m       0.2757            0.2757        2.7165  0.0179  1.2980\n",
      "      7            0.5000        0.2679       0.5000            0.5000        5.9814  0.0171  1.3186\n",
      "      8            0.5000        \u001b[32m0.2423\u001b[0m       0.5000            0.5000       12.4681  0.0161  1.2695\n",
      "      9            0.5000        \u001b[32m0.2102\u001b[0m       0.5000            0.5000       14.7434  0.0150  1.3242\n",
      "     10            0.5165        0.2204       0.4890            0.4890        3.1816  0.0138  1.2922\n",
      "     11            0.5000        \u001b[32m0.1792\u001b[0m       0.5000            0.5000        8.6577  0.0126  1.3045\n",
      "     12            0.5000        \u001b[32m0.1729\u001b[0m       0.5000            0.5000        6.1758  0.0113  1.3217\n",
      "     13            0.5000        \u001b[32m0.1594\u001b[0m       0.5000            0.5000        7.2905  0.0100  1.3281\n",
      "     14            0.5138        \u001b[32m0.1558\u001b[0m       0.5074            0.5074        4.0969  0.0087  1.3259\n",
      "     15            0.5092        0.1701       0.5147            0.5147        5.1486  0.0074  1.2910\n",
      "     16            0.5064        \u001b[32m0.1168\u001b[0m       0.5000            0.5000        6.1892  0.0062  1.3122\n",
      "     17            0.5000        \u001b[32m0.0873\u001b[0m       0.5000            0.5000        7.3046  0.0050  1.3153\n",
      "     18            0.5046        \u001b[32m0.0744\u001b[0m       0.5000            0.5000        7.7117  0.0039  1.2943\n",
      "     19            0.5046        0.0875       0.5000            0.5000        7.8935  0.0029  1.3016\n",
      "     20            0.5119        0.0873       0.5000            0.5000        7.2071  0.0021  1.3262\n",
      "     21            \u001b[36m0.6792\u001b[0m        \u001b[32m0.0659\u001b[0m       \u001b[35m0.5699\u001b[0m            \u001b[31m0.5699\u001b[0m        2.9964  0.0013  1.3329\n",
      "     22            \u001b[36m0.6884\u001b[0m        0.0860       0.5478            0.5478        3.0998  0.0008  1.2971\n",
      "     23            \u001b[36m0.7132\u001b[0m        0.0659       0.5368            0.5368        3.0379  0.0003  1.2928\n",
      "     24            \u001b[36m0.8199\u001b[0m        0.0822       0.5147            0.5147        2.7537  0.0001  1.3270\n",
      "     25            \u001b[36m0.9062\u001b[0m        \u001b[32m0.0648\u001b[0m       0.4963            0.4963        2.5940  0.0000  1.3124\n",
      "Best Cross Validation Kappa Score: 0.14\n",
      "\n",
      " ######################### Training for Subject: 6 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5993\u001b[0m        \u001b[32m0.7845\u001b[0m       \u001b[35m0.5037\u001b[0m            \u001b[31m0.5037\u001b[0m        \u001b[94m2.9187\u001b[0m  0.0200  1.2629\n",
      "      2            0.5634        \u001b[32m0.2519\u001b[0m       \u001b[35m0.5074\u001b[0m            \u001b[31m0.5074\u001b[0m        4.0889  0.0199  1.3362\n",
      "      3            \u001b[36m0.9329\u001b[0m        \u001b[32m0.1703\u001b[0m       \u001b[35m0.7426\u001b[0m            \u001b[31m0.7426\u001b[0m        \u001b[94m0.8240\u001b[0m  0.0197  1.3010\n",
      "      4            0.6121        \u001b[32m0.1400\u001b[0m       0.5074            0.5074        4.8473  0.0192  1.3102\n",
      "      5            0.5919        \u001b[32m0.0811\u001b[0m       0.5074            0.5074        5.2576  0.0187  1.3005\n",
      "      6            0.5717        0.0835       0.5037            0.5037        6.1555  0.0179  1.3466\n",
      "      7            0.8263        \u001b[32m0.0709\u001b[0m       0.4963            0.4963        3.7813  0.0171  1.2877\n",
      "      8            \u001b[36m0.9862\u001b[0m        0.1041       0.5551            0.5551        3.0464  0.0161  1.3200\n",
      "      9            0.8006        0.0864       \u001b[35m0.9228\u001b[0m            \u001b[31m0.9228\u001b[0m        \u001b[94m0.3997\u001b[0m  0.0150  1.2685\n",
      "     10            0.9798        \u001b[32m0.0375\u001b[0m       0.6103            0.6103        3.0068  0.0138  1.3139\n",
      "     11            0.9743        0.0710       0.5662            0.5662        3.7944  0.0126  1.3119\n",
      "     12            \u001b[36m0.9963\u001b[0m        0.0472       0.6140            0.6140        2.5464  0.0113  1.3766\n",
      "     13            0.9678        \u001b[32m0.0288\u001b[0m       0.5404            0.5404        4.0861  0.0100  1.3305\n",
      "     14            0.5524        0.0472       0.4853            0.4853        9.2862  0.0087  1.3481\n",
      "     15            \u001b[36m1.0000\u001b[0m        \u001b[32m0.0204\u001b[0m       0.5993            0.5993        3.0547  0.0074  1.3509\n",
      "     16            0.9963        \u001b[32m0.0109\u001b[0m       0.5662            0.5662        4.1813  0.0062  1.3134\n",
      "     17            0.9283        0.0182       0.8272            0.8272        1.2029  0.0050  1.3155\n",
      "     18            0.9991        0.0339       0.5809            0.5809        4.0095  0.0039  1.2894\n",
      "     19            1.0000        0.0338       0.6287            0.6287        2.3952  0.0029  1.2799\n",
      "     20            1.0000        \u001b[32m0.0097\u001b[0m       0.6360            0.6360        2.0481  0.0021  1.2896\n",
      "     21            1.0000        0.0097       0.6618            0.6618        1.8283  0.0013  1.3127\n",
      "     22            1.0000        0.0160       0.6360            0.6360        2.2235  0.0008  1.3166\n",
      "     23            1.0000        0.0299       0.6140            0.6140        2.6866  0.0003  1.2726\n",
      "     24            1.0000        0.0178       0.6103            0.6103        2.7150  0.0001  1.3178\n",
      "     25            1.0000        0.0149       0.6140            0.6140        2.6947  0.0000  1.2998\n",
      "Best Cross Validation Kappa Score: 0.85\n",
      "\n",
      " ######################### Training for Subject: 7 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m0.6516\u001b[0m       \u001b[35m0.5625\u001b[0m            \u001b[31m0.5625\u001b[0m       \u001b[94m37.2882\u001b[0m  0.0200  1.3571\n",
      "      2            0.5000        \u001b[32m0.2078\u001b[0m       0.5625            0.5625       \u001b[94m29.4048\u001b[0m  0.0199  1.3428\n",
      "      3            0.5000        \u001b[32m0.1656\u001b[0m       0.5625            0.5625       \u001b[94m16.7344\u001b[0m  0.0197  1.3116\n",
      "      4            0.5000        \u001b[32m0.1445\u001b[0m       0.5625            0.5625       \u001b[94m13.3086\u001b[0m  0.0192  1.2982\n",
      "      5            0.5000        0.1849       0.5625            0.5625       \u001b[94m10.8243\u001b[0m  0.0187  1.3352\n",
      "      6            \u001b[36m0.7114\u001b[0m        \u001b[32m0.1423\u001b[0m       \u001b[35m0.6728\u001b[0m            \u001b[31m0.6728\u001b[0m        \u001b[94m2.2194\u001b[0m  0.0179  1.2997\n",
      "      7            \u001b[36m0.7142\u001b[0m        \u001b[32m0.0910\u001b[0m       \u001b[35m0.6949\u001b[0m            \u001b[31m0.6949\u001b[0m        2.5899  0.0171  1.3479\n",
      "      8            0.6930        0.1262       0.6544            0.6544        2.8805  0.0161  1.3679\n",
      "      9            \u001b[36m0.9715\u001b[0m        \u001b[32m0.0816\u001b[0m       \u001b[35m0.8162\u001b[0m            \u001b[31m0.8162\u001b[0m        \u001b[94m1.7551\u001b[0m  0.0150  1.3392\n",
      "     10            0.7914        0.0818       \u001b[35m0.8566\u001b[0m            \u001b[31m0.8566\u001b[0m        \u001b[94m1.3054\u001b[0m  0.0138  1.3600\n",
      "     11            0.5469        \u001b[32m0.0778\u001b[0m       0.7206            0.7206        2.8931  0.0126  1.2739\n",
      "     12            0.5634        \u001b[32m0.0734\u001b[0m       0.7610            0.7610        2.6807  0.0113  1.2960\n",
      "     13            0.5184        \u001b[32m0.0667\u001b[0m       0.6801            0.6801        4.0499  0.0100  1.3601\n",
      "     14            0.5699        \u001b[32m0.0658\u001b[0m       0.7904            0.7904        2.4877  0.0087  1.3301\n",
      "     15            0.5910        \u001b[32m0.0469\u001b[0m       0.7941            0.7941        2.4077  0.0074  1.3908\n",
      "     16            0.5156        0.0558       0.6801            0.6801        4.2186  0.0062  1.3442\n",
      "     17            0.5322        0.0714       0.7059            0.7059        3.3937  0.0050  1.3722\n",
      "     18            0.5763        0.0497       0.7904            0.7904        2.3040  0.0039  1.3354\n",
      "     19            0.5257        \u001b[32m0.0444\u001b[0m       0.6875            0.6875        3.8205  0.0029  1.3439\n",
      "     20            0.7399        \u001b[32m0.0357\u001b[0m       0.8493            0.8493        1.6285  0.0021  1.3094\n",
      "     21            0.6737        0.0590       0.8382            0.8382        1.7647  0.0013  1.3072\n",
      "     22            0.8401        0.0423       0.8529            0.8529        1.5578  0.0008  1.3151\n",
      "     23            0.9283        \u001b[32m0.0353\u001b[0m       \u001b[35m0.8640\u001b[0m            \u001b[31m0.8640\u001b[0m        1.5148  0.0003  1.3877\n",
      "     24            \u001b[36m0.9761\u001b[0m        0.0477       \u001b[35m0.8787\u001b[0m            \u001b[31m0.8787\u001b[0m        1.5123  0.0001  1.4097\n",
      "     25            \u001b[36m0.9936\u001b[0m        0.0390       0.8787            0.8787        1.5393  0.0000  1.3557\n",
      "Best Cross Validation Kappa Score: 0.76\n",
      "\n",
      " ######################### Training for Subject: 8 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m0.8579\u001b[0m       \u001b[35m0.4375\u001b[0m            \u001b[31m0.4375\u001b[0m       \u001b[94m11.4880\u001b[0m  0.0200  1.4253\n",
      "      2            0.5000        \u001b[32m0.4927\u001b[0m       0.4375            0.4375       13.5684  0.0199  1.7416\n",
      "      3            \u001b[36m0.5441\u001b[0m        \u001b[32m0.4491\u001b[0m       0.4375            0.4375        \u001b[94m5.8874\u001b[0m  0.0197  1.3363\n",
      "      4            0.5303        \u001b[32m0.3965\u001b[0m       \u001b[35m0.9154\u001b[0m            \u001b[31m0.9154\u001b[0m        \u001b[94m1.7026\u001b[0m  0.0192  1.3090\n",
      "      5            0.5000        \u001b[32m0.3225\u001b[0m       0.8640            0.8640        2.1477  0.0187  1.4302\n",
      "      6            0.5000        \u001b[32m0.2933\u001b[0m       0.5625            0.5625        2.7720  0.0179  5.5386\n",
      "      7            0.5000        0.3028       0.5000            0.5000        4.4811  0.0171  1.3167\n",
      "      8            0.5000        \u001b[32m0.2531\u001b[0m       0.5000            0.5000        7.6477  0.0161  1.3449\n",
      "      9            0.5000        0.2670       0.5404            0.5404        2.7180  0.0150  1.3675\n",
      "     10            0.5000        \u001b[32m0.2363\u001b[0m       0.5000            0.5000        5.0046  0.0138  1.2768\n",
      "     11            0.5000        \u001b[32m0.2102\u001b[0m       0.5000            0.5000        5.2791  0.0126  1.2971\n",
      "     12            0.5000        \u001b[32m0.1854\u001b[0m       0.5000            0.5000        4.4491  0.0113  1.3361\n",
      "     13            \u001b[36m0.8952\u001b[0m        0.1999       0.4890            0.4890        3.0851  0.0100  1.2983\n",
      "     14            0.5000        0.1973       0.5000            0.5000        7.9261  0.0087  1.3082\n",
      "     15            0.5000        \u001b[32m0.1364\u001b[0m       0.6213            0.6213        3.3664  0.0074  1.5290\n",
      "     16            0.5119        0.1410       0.7537            0.7537        2.8637  0.0062  1.4708\n",
      "     17            0.5542        \u001b[32m0.1045\u001b[0m       0.8860            0.8860        2.8410  0.0050  1.5474\n",
      "     18            0.5046        0.1294       0.7574            0.7574        3.5210  0.0039  1.5626\n",
      "     19            0.7564        0.1359       0.8824            0.8824        2.8797  0.0029  1.5529\n",
      "     20            0.7840        0.1090       0.8860            0.8860        3.0465  0.0021  1.5111\n",
      "     21            \u001b[36m0.9917\u001b[0m        0.1114       0.6875            0.6875        3.9028  0.0013  1.2514\n",
      "     22            0.8860        \u001b[32m0.0771\u001b[0m       0.7941            0.7941        3.3300  0.0008  1.2737\n",
      "     23            0.9237        0.0954       0.7794            0.7794        3.4849  0.0003  1.5244\n",
      "     24            0.9320        0.1039       0.7794            0.7794        3.5310  0.0001  1.5765\n",
      "     25            0.9605        0.1055       0.7721            0.7721        3.6186  0.0000  1.5586\n",
      "Best Cross Validation Kappa Score: 0.83\n",
      "\n",
      " ######################### Training for Subject: 9 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5312\u001b[0m        \u001b[32m1.1769\u001b[0m       \u001b[35m0.5000\u001b[0m            \u001b[31m0.5000\u001b[0m        \u001b[94m4.4998\u001b[0m  0.0200  1.3343\n",
      "      2            \u001b[36m0.6893\u001b[0m        \u001b[32m0.4896\u001b[0m       \u001b[35m0.5147\u001b[0m            \u001b[31m0.5147\u001b[0m        \u001b[94m1.2771\u001b[0m  0.0199  1.2838\n",
      "      3            \u001b[36m0.7031\u001b[0m        \u001b[32m0.3601\u001b[0m       \u001b[35m0.9301\u001b[0m            \u001b[31m0.9301\u001b[0m        \u001b[94m0.2136\u001b[0m  0.0197  1.3221\n",
      "      4            0.5533        \u001b[32m0.3260\u001b[0m       0.5000            0.5000        3.1276  0.0192  1.3282\n",
      "      5            0.5561        \u001b[32m0.2700\u001b[0m       \u001b[35m0.9706\u001b[0m            \u001b[31m0.9706\u001b[0m        \u001b[94m0.1275\u001b[0m  0.0187  1.2900\n",
      "      6            0.5000        \u001b[32m0.2216\u001b[0m       0.5662            0.5662        1.0240  0.0179  1.3137\n",
      "      7            0.6553        0.2241       0.5000            0.5000        3.1905  0.0171  1.3015\n",
      "      8            0.5000        \u001b[32m0.1683\u001b[0m       0.5000            0.5000       19.7698  0.0161  1.3132\n",
      "      9            0.6195        \u001b[32m0.1554\u001b[0m       0.5074            0.5074        3.8068  0.0150  1.3295\n",
      "     10            0.5119        0.1764       0.5000            0.5000       15.9892  0.0138  3.8180\n",
      "     11            \u001b[36m0.8309\u001b[0m        0.1842       0.5809            0.5809        2.4136  0.0126  6.9236\n",
      "     12            0.7868        \u001b[32m0.1443\u001b[0m       0.5478            0.5478        3.3174  0.0113  7.0544\n",
      "     13            0.5257        \u001b[32m0.1170\u001b[0m       0.5000            0.5000        9.7561  0.0100  7.0237\n",
      "     14            0.5524        \u001b[32m0.1114\u001b[0m       0.5000            0.5000        7.0169  0.0087  7.3273\n",
      "     15            0.5009        0.1456       0.5000            0.5000       16.0260  0.0074  7.0225\n",
      "     16            0.5147        \u001b[32m0.1065\u001b[0m       0.5000            0.5000       15.5225  0.0062  7.0038\n",
      "     17            0.5349        \u001b[32m0.1046\u001b[0m       0.5000            0.5000        8.4481  0.0050  3.3876\n",
      "     18            0.5267        \u001b[32m0.0821\u001b[0m       0.5000            0.5000        9.8711  0.0039  1.3082\n",
      "     19            0.5616        0.0841       0.5000            0.5000        7.4126  0.0029  1.3212\n",
      "     20            0.5882        \u001b[32m0.0755\u001b[0m       0.5000            0.5000        6.3127  0.0021  1.2976\n",
      "     21            0.5460        \u001b[32m0.0754\u001b[0m       0.5000            0.5000        7.9427  0.0013  1.2733\n",
      "     22            0.7491        \u001b[32m0.0722\u001b[0m       0.5662            0.5662        4.0976  0.0008  1.2716\n",
      "     23            \u001b[36m0.8805\u001b[0m        \u001b[32m0.0570\u001b[0m       0.5919            0.5919        3.2689  0.0003  1.3178\n",
      "     24            \u001b[36m0.9301\u001b[0m        0.0727       0.6324            0.6324        2.8063  0.0001  1.2988\n",
      "     25            \u001b[36m0.9522\u001b[0m        0.0689       0.6618            0.6618        2.4861  0.0000  1.3198\n",
      "Best Cross Validation Kappa Score: 0.94\n",
      "\n",
      " ######################### Training for Subject: 10 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5790\u001b[0m        \u001b[32m0.8749\u001b[0m       \u001b[35m0.5000\u001b[0m            \u001b[31m0.5000\u001b[0m        \u001b[94m8.9472\u001b[0m  0.0200  1.3047\n",
      "      2            \u001b[36m0.6075\u001b[0m        \u001b[32m0.4055\u001b[0m       \u001b[35m0.5882\u001b[0m            \u001b[31m0.5882\u001b[0m        \u001b[94m1.6256\u001b[0m  0.0199  1.2634\n",
      "      3            \u001b[36m0.8300\u001b[0m        \u001b[32m0.3834\u001b[0m       \u001b[35m0.6029\u001b[0m            \u001b[31m0.6029\u001b[0m        \u001b[94m0.9603\u001b[0m  0.0197  1.2921\n",
      "      4            0.6866        \u001b[32m0.3465\u001b[0m       0.5809            0.5809        1.0503  0.0192  1.2847\n",
      "      5            0.5441        \u001b[32m0.3082\u001b[0m       0.5000            0.5000        3.2812  0.0187  1.3379\n",
      "      6            0.5349        \u001b[32m0.3057\u001b[0m       0.5000            0.5000        3.2540  0.0179  1.2751\n",
      "      7            0.5239        \u001b[32m0.2863\u001b[0m       0.4669            0.4669        1.6130  0.0171  1.2592\n",
      "      8            0.5533        \u001b[32m0.2767\u001b[0m       0.4926            0.4926        3.0126  0.0161  1.2855\n",
      "      9            0.5064        \u001b[32m0.2471\u001b[0m       0.5000            0.5000        7.9407  0.0150  1.3321\n",
      "     10            0.5441        \u001b[32m0.1979\u001b[0m       0.5404            0.5404        1.1783  0.0138  1.2731\n",
      "     11            0.5037        0.2650       0.5000            0.5000        6.6103  0.0126  1.3545\n",
      "     12            0.7748        \u001b[32m0.1382\u001b[0m       0.5221            0.5221        2.2292  0.0113  1.3245\n",
      "     13            \u001b[36m0.9403\u001b[0m        \u001b[32m0.1139\u001b[0m       \u001b[35m0.7316\u001b[0m            \u001b[31m0.7316\u001b[0m        \u001b[94m0.6691\u001b[0m  0.0100  1.3192\n",
      "     14            0.5708        0.1210       0.5000            0.5000       11.4039  0.0087  1.2869\n",
      "     15            0.5000        \u001b[32m0.1007\u001b[0m       0.5000            0.5000        6.7431  0.0074  1.2846\n",
      "     16            0.5000        0.1607       0.5000            0.5000       10.2226  0.0062  1.2856\n",
      "     17            0.8649        0.1021       0.7169            0.7169        1.2722  0.0050  1.3067\n",
      "     18            0.8934        \u001b[32m0.0924\u001b[0m       0.6838            0.6838        1.2890  0.0039  1.2784\n",
      "     19            0.6893        0.1061       0.5110            0.5110        3.5326  0.0029  1.3263\n",
      "     20            \u001b[36m0.9890\u001b[0m        \u001b[32m0.0854\u001b[0m       \u001b[35m0.7904\u001b[0m            \u001b[31m0.7904\u001b[0m        1.1120  0.0021  1.3223\n",
      "     21            0.8879        \u001b[32m0.0685\u001b[0m       0.6066            0.6066        2.0849  0.0013  1.2666\n",
      "     22            0.9798        0.0964       0.7794            0.7794        1.2157  0.0008  1.2804\n",
      "     23            0.9651        0.0857       0.7610            0.7610        1.2716  0.0003  1.3518\n",
      "     24            0.9761        0.0774       0.7610            0.7610        1.2991  0.0001  1.2875\n",
      "     25            0.9789        \u001b[32m0.0612\u001b[0m       0.7610            0.7610        1.3275  0.0000  1.2833\n",
      "Best Cross Validation Kappa Score: 0.58\n"
     ]
    }
   ],
   "source": [
    "for subject_index in range(len(training_files)):\n",
    "    training_function(subject_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
