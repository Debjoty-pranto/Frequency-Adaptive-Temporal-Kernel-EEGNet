{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinical BCI Challenge-WCCI2020\n",
    "- [website link](https://sites.google.com/view/bci-comp-wcci/?fbclid=IwAR37WLQ_xNd5qsZvktZCT8XJerHhmVb_bU5HDu69CnO85DE3iF0fs57vQ6M)\n",
    "\n",
    "\n",
    " - [Dataset Link](https://github.com/5anirban9/Clinical-Brain-Computer-Interfaces-Challenge-WCCI-2020-Glasgow)\n",
    " \n",
    " \n",
    " - [Braindecode Tutorial](https://braindecode.org/auto_examples/plot_bcic_iv_2a_moabb_trial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from mne.decoding import CSP\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False                    # global variable to suppress output display of MNE functions\n",
    "mne.set_log_level(verbose=verbose) # to suppress large info outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = None  # for multicore parallel processing, set it to 1 if cause memory issues, for full utilization set to -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Conversion to MNE Datatypes\n",
    "[Mike Cohen Tutorials link for EEG Preprocessing](https://www.youtube.com/watch?v=uWB5tjhataY&list=PLn0OLiymPak2gDD-VDA90w9_iGDgOOb2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = globals()['_dh'][0]  # a hack to get path of current folder in which jupyter file is located\n",
    "data_path = os.path.join(current_folder, r\"C:\\Users\\MILAKUL\\Documents\\Thesis\\clinicalBCI\\matlab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_files   = glob.glob(data_path + '/*T.mat')\n",
    "len(training_files)     # if  return zero,then no file is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have modified the labels values from [1, 2] to [0, 1] as pytorch \n",
    "# expects labels/classes to be in [0, n_classes-1] format\n",
    "def get_mne_epochs(filepath, verbose=verbose, t_start=2, fs=512, mode='train'):\n",
    "    '''\n",
    "    This function reads the EEG data from .mat file and convert it to MNE-Python Compatible epochs\n",
    "    data structure. It takes data from [0, 8] sec range and return it by setting t = 0 at cue onset\n",
    "    i.e. 3 seconds and dropping first two seconds so the output data is in [-1.0, 5.0] sec range. The\n",
    "    Details can be found in the preprocessing section of the attached document\n",
    "    '''\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    eeg_data= mat_data['RawEEGData']\n",
    "    idx_start = fs*t_start      \n",
    "    eeg_data = eeg_data[:, :, idx_start:]\n",
    "    event_id = {'left-hand': 0, 'right-hand': 1} # pytorch expects labels in [0, n_classes-1]\n",
    "    channel_names = ['F3', 'FC3', 'C3', 'CP3', 'P3', 'FCz', 'CPz', 'F4', 'FC4', 'C4', 'CP4', 'P4']\n",
    "    info = mne.create_info(ch_names=channel_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, verbose=verbose, tmin=t_start-3.0)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None) \n",
    "    epochs.apply_baseline(baseline=(-.250, 0)) # linear baseline correction\n",
    "    \n",
    "    if mode == 'train': # this in only applicable for training data\n",
    "        epochs.event_id = event_id \n",
    "        epochs.events[:,2] = mat_data['Labels'].ravel() - 1    \n",
    "    return epochs \n",
    "\n",
    "def get_labels(filepath):\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    return mat_data['Labels'].ravel() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG Data:  (80, 12, 3072) \t Shape of Labels:  (80,)\n"
     ]
    }
   ],
   "source": [
    "epochs, labels = get_mne_epochs(training_files[0], verbose=verbose), get_labels(training_files[0])\n",
    "data = epochs.get_data()\n",
    "print('Shape of EEG Data: ', data.shape, '\\t Shape of Labels: ', labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading original data\n",
    "epochs_list_train = []\n",
    "for i in training_files:\n",
    "    epochs_list_train.append(get_mne_epochs(i, verbose=verbose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Braindecode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's Training Time with [0.5, 4.5] sec and 2sec window with 125ms stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets per subject: 10\n",
      "Total windows for first subject: 1360\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datautil import create_from_mne_epochs\n",
    "\n",
    "window_size = 1024   # 2 sec windows\n",
    "window_stride = 64   # 125 ms stride\n",
    "\n",
    "windows_datasets_list = []\n",
    "\n",
    "for epoch in epochs_list_train:\n",
    "    # Create windows per subject\n",
    "    windows_dataset = create_from_mne_epochs(\n",
    "        [epoch.crop(tmin=0.5, tmax=4.5, include_tmax=False)],\n",
    "        window_size_samples=window_size,\n",
    "        window_stride_samples=window_stride,\n",
    "        drop_last_window=False\n",
    "    )\n",
    "    # Add labels as a separate attribute\n",
    "    windows_dataset.update_description = pd.DataFrame(\n",
    "        data=np.concatenate([d.y for d in windows_dataset.datasets]),\n",
    "        columns=['labels']\n",
    "    )\n",
    "    windows_datasets_list.append(windows_dataset)\n",
    "\n",
    "print(\"Datasets per subject:\", len(windows_datasets_list))\n",
    "print(\"Total windows for first subject:\", len(windows_datasets_list[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.preprocessing import exponential_moving_standardize\n",
    "\n",
    "low_cut_hz = 8.   # low cut frequency for filtering\n",
    "high_cut_hz = 32. # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\n",
    "    \"\"\"Apply exponential moving standardization to MNE epochs inplace.\"\"\"\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        data[i] = exponential_moving_standardize(\n",
    "            data[i], factor_new=factor_new, init_block_size=init_block_size\n",
    "        )\n",
    "    epochs._data = data\n",
    "    return epochs\n",
    "\n",
    "# Apply preprocessing to each dataset\n",
    "for windows_dataset in windows_datasets_list:\n",
    "    # Extract the underlying MNE Epochs object\n",
    "    epochs = windows_dataset.datasets[0].windows\n",
    "    epochs.load_data()  # Ensure data is loaded into memory\n",
    "\n",
    "    # 1) Keep only EEG channels\n",
    "    epochs.pick_types(eeg=True)\n",
    "\n",
    "    # 2) Bandpass filter\n",
    "    epochs.filter(l_freq=low_cut_hz, h_freq=high_cut_hz)\n",
    "\n",
    "    # 3) Exponential moving standardization\n",
    "    custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #64\n",
    "n_epochs = 25 #25 #20 #25 use few epochs for quick verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, EEGNetv4\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes=2\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_chans = windows_datasets_list[0][0][0].shape[0]\n",
    "input_window_samples = windows_datasets_list[0][0][0].shape[1]\n",
    "\n",
    "model = EEGNetv4(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    n_times = window_size, #input_window_samples,\n",
    "    final_conv_length='auto',\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "lr = 1 * 0.02 #0.01 \n",
    "weight_decay = 0.5 * 0.001\n",
    "\n",
    "clfs_list = []\n",
    "for i in range(len(epochs_list_train)):\n",
    "    clfs_list.append(\n",
    "        EEGClassifier(\n",
    "                    model,\n",
    "                    criterion = torch.nn.CrossEntropyLoss(),\n",
    "                    optimizer=torch.optim.AdamW,\n",
    "                    #train_split=predefined_split(train_set),  # using valid_set for validation\n",
    "                    optimizer__lr=lr,\n",
    "                    optimizer__weight_decay=weight_decay,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[\n",
    "                        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "                    ],\n",
    "                    device=device,\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######################### Training for Subject: 1 ######################### \n",
      "\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5064\u001b[0m        \u001b[32m0.6766\u001b[0m       \u001b[35m0.4375\u001b[0m            \u001b[31m0.4375\u001b[0m        \u001b[94m6.6486\u001b[0m  0.0200  1.9657\n",
      "      2            0.5055        \u001b[32m0.2789\u001b[0m       0.4375            0.4375        7.3016  0.0199  1.6942\n",
      "      3            0.5000        0.2826       0.4375            0.4375       11.3223  0.0197  1.7398\n",
      "      4            \u001b[36m0.7077\u001b[0m        \u001b[32m0.2146\u001b[0m       \u001b[35m0.5404\u001b[0m            \u001b[31m0.5404\u001b[0m        \u001b[94m2.6112\u001b[0m  0.0192  1.7120\n",
      "      5            \u001b[36m0.9642\u001b[0m        \u001b[32m0.1990\u001b[0m       \u001b[35m0.6691\u001b[0m            \u001b[31m0.6691\u001b[0m        3.6753  0.0187  1.6859\n",
      "      6            0.5506        \u001b[32m0.1096\u001b[0m       0.4375            0.4375        7.9458  0.0179  1.6684\n",
      "      7            0.6342        \u001b[32m0.0870\u001b[0m       0.4375            0.4375        9.1564  0.0171  1.7468\n",
      "      8            0.7555        0.0982       0.5588            0.5588        4.6841  0.0161  1.6907\n",
      "      9            0.5285        0.1374       0.4375            0.4375       11.4659  0.0150  1.7408\n",
      "     10            0.8079        0.1112       0.5551            0.5551        4.8360  0.0138  1.6986\n",
      "     11            0.5028        0.1131       0.4375            0.4375       15.9425  0.0126  1.7250\n",
      "     12            0.8125        0.0998       0.4816            0.4816        9.6297  0.0113  1.7430\n",
      "     13            0.5515        \u001b[32m0.0711\u001b[0m       0.5000            0.5000       13.1032  0.0100  1.6928\n",
      "     14            0.5294        \u001b[32m0.0427\u001b[0m       0.5000            0.5000       18.3539  0.0087  1.6865\n",
      "     15            0.6186        \u001b[32m0.0350\u001b[0m       0.5294            0.5294        7.1391  0.0074  1.7709\n",
      "     16            0.5607        0.0433       0.5368            0.5368        7.4585  0.0062  1.7427\n",
      "     17            0.7960        \u001b[32m0.0306\u001b[0m       \u001b[35m0.7500\u001b[0m            \u001b[31m0.7500\u001b[0m        6.2186  0.0050  1.6943\n",
      "     18            0.5910        \u001b[32m0.0292\u001b[0m       0.6287            0.6287        7.1855  0.0039  1.7663\n",
      "     19            0.7583        \u001b[32m0.0212\u001b[0m       \u001b[35m0.7537\u001b[0m            \u001b[31m0.7537\u001b[0m        6.6486  0.0029  1.8439\n",
      "     20            0.7849        \u001b[32m0.0210\u001b[0m       0.7390            0.7390        6.8901  0.0021  1.7668\n",
      "     21            0.8603        0.0217       0.7243            0.7243        7.1039  0.0013  1.7908\n",
      "     22            0.8768        \u001b[32m0.0179\u001b[0m       0.7022            0.7022        7.1891  0.0008  1.7398\n",
      "     23            \u001b[36m0.9660\u001b[0m        \u001b[32m0.0172\u001b[0m       0.6801            0.6801        7.7112  0.0003  1.7426\n",
      "     24            \u001b[36m0.9954\u001b[0m        0.0247       0.6618            0.6618        8.1794  0.0001  1.7942\n",
      "     25            \u001b[36m0.9982\u001b[0m        0.0274       0.6654            0.6654        8.4790  0.0000  1.8042\n",
      "Best Cross Validation Accuracy: 0.754\n",
      "Best Cross Validation Kappa Score: 0.507\n",
      "\n",
      " ######################### Training for Subject: 2 ######################### \n",
      "\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m1.1782\u001b[0m       \u001b[35m0.5625\u001b[0m            \u001b[31m0.5625\u001b[0m        \u001b[94m8.4600\u001b[0m  0.0200  1.8291\n",
      "      2            0.5000        \u001b[32m0.0325\u001b[0m       0.5625            0.5625        \u001b[94m7.3773\u001b[0m  0.0199  1.8753\n",
      "      3            \u001b[36m0.9871\u001b[0m        0.0561       \u001b[35m0.9963\u001b[0m            \u001b[31m0.9963\u001b[0m        \u001b[94m0.0355\u001b[0m  0.0197  1.8296\n",
      "      4            0.9485        \u001b[32m0.0241\u001b[0m       0.8676            0.8676        0.3801  0.0192  1.8045\n",
      "      5            \u001b[36m1.0000\u001b[0m        \u001b[32m0.0091\u001b[0m       0.9669            0.9669        0.0583  0.0187  1.6991\n",
      "      6            0.7960        \u001b[32m0.0027\u001b[0m       0.6581            0.6581        1.1901  0.0179  1.6972\n",
      "      7            0.6949        \u001b[32m0.0010\u001b[0m       0.5478            0.5478        2.2109  0.0171  2.3251\n",
      "      8            0.7472        0.0062       0.5919            0.5919        1.8547  0.0161  4.6369\n",
      "      9            0.9936        0.0025       0.9485            0.9485        0.2518  0.0150  4.4485\n",
      "     10            1.0000        0.0063       0.9743            0.9743        0.0404  0.0138  4.3868\n",
      "     11            1.0000        \u001b[32m0.0008\u001b[0m       0.9596            0.9596        0.1196  0.0126  4.3037\n",
      "     12            0.9972        0.0011       0.9485            0.9485        0.2775  0.0113  1.8202\n",
      "     13            0.9963        0.0018       0.9485            0.9485        0.2963  0.0100  1.6768\n",
      "     14            1.0000        0.0040       0.9779            0.9779        \u001b[94m0.0313\u001b[0m  0.0087  1.6111\n",
      "     15            0.9917        0.0033       0.8860            0.8860        0.4338  0.0074  1.6394\n",
      "     16            1.0000        \u001b[32m0.0005\u001b[0m       0.9375            0.9375        0.1096  0.0062  1.6528\n",
      "     17            1.0000        0.0014       \u001b[35m1.0000\u001b[0m            \u001b[31m1.0000\u001b[0m        \u001b[94m0.0081\u001b[0m  0.0050  1.7153\n",
      "     18            1.0000        0.0010       0.9963            0.9963        0.0147  0.0039  1.7019\n",
      "     19            1.0000        0.0045       0.9632            0.9632        0.0914  0.0029  1.6748\n",
      "     20            1.0000        0.0010       0.9632            0.9632        0.0894  0.0021  1.6488\n",
      "     21            1.0000        0.0018       0.9632            0.9632        0.0954  0.0013  1.6473\n",
      "     22            1.0000        0.0005       0.9632            0.9632        0.0733  0.0008  1.6513\n",
      "     23            1.0000        0.0016       0.9706            0.9706        0.0584  0.0003  1.6074\n",
      "     24            1.0000        0.0009       0.9706            0.9706        0.0469  0.0001  1.6160\n",
      "     25            1.0000        0.0013       0.9743            0.9743        0.0379  0.0000  1.7053\n",
      "Best Cross Validation Accuracy: 1.000\n",
      "Best Cross Validation Kappa Score: 1.000\n",
      "\n",
      " ######################### Training for Subject: 3 ######################### \n",
      "\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m2.5131\u001b[0m       \u001b[35m0.4375\u001b[0m            \u001b[31m0.4375\u001b[0m       \u001b[94m78.1995\u001b[0m  0.0200  1.6647\n",
      "      2            0.5000        \u001b[32m0.1392\u001b[0m       0.4375            0.4375       \u001b[94m54.7848\u001b[0m  0.0199  1.6523\n",
      "      3            0.5000        0.1704       0.4375            0.4375       59.0767  0.0197  1.7884\n",
      "      4            0.5000        \u001b[32m0.1158\u001b[0m       0.4375            0.4375       \u001b[94m29.3553\u001b[0m  0.0192  1.7619\n",
      "      5            \u001b[36m0.6985\u001b[0m        \u001b[32m0.0924\u001b[0m       \u001b[35m0.5441\u001b[0m            \u001b[31m0.5441\u001b[0m       \u001b[94m17.7323\u001b[0m  0.0187  1.7756\n",
      "      6            \u001b[36m0.9761\u001b[0m        \u001b[32m0.0797\u001b[0m       \u001b[35m0.5515\u001b[0m            \u001b[31m0.5515\u001b[0m       18.3018  0.0179  1.7728\n",
      "      7            0.7335        \u001b[32m0.0645\u001b[0m       \u001b[35m0.5588\u001b[0m            \u001b[31m0.5588\u001b[0m       19.6777  0.0171  1.6694\n",
      "      8            0.5000        \u001b[32m0.0536\u001b[0m       0.4375            0.4375       39.7392  0.0161  1.6171\n",
      "      9            0.7555        0.0720       \u001b[35m0.6434\u001b[0m            \u001b[31m0.6434\u001b[0m       21.4872  0.0150  1.6338\n",
      "     10            0.8520        \u001b[32m0.0479\u001b[0m       0.5368            0.5368       33.5297  0.0138  1.6412\n",
      "     11            0.8704        0.0741       0.5368            0.5368       35.6679  0.0126  1.6828\n",
      "     12            0.9733        0.0603       \u001b[35m0.6618\u001b[0m            \u001b[31m0.6618\u001b[0m       19.2028  0.0113  1.6295\n",
      "     13            0.9688        \u001b[32m0.0279\u001b[0m       0.5478            0.5478       \u001b[94m16.8017\u001b[0m  0.0100  1.6396\n",
      "     14            \u001b[36m0.9982\u001b[0m        0.0508       \u001b[35m0.7206\u001b[0m            \u001b[31m0.7206\u001b[0m       \u001b[94m11.9133\u001b[0m  0.0087  1.6099\n",
      "     15            0.9881        0.0384       0.7132            0.7132       16.6926  0.0074  1.6075\n",
      "     16            0.9936        0.0319       0.5478            0.5478       18.9199  0.0062  1.6245\n",
      "     17            0.9219        0.0384       0.6985            0.6985       14.5281  0.0050  1.6086\n",
      "     18            0.9550        0.0440       0.5735            0.5735       18.7664  0.0039  1.6082\n",
      "     19            0.9972        \u001b[32m0.0243\u001b[0m       0.6985            0.6985       15.6458  0.0029  1.5957\n",
      "     20            \u001b[36m1.0000\u001b[0m        0.0385       0.6103            0.6103       17.9832  0.0021  1.6179\n",
      "     21            0.9991        \u001b[32m0.0113\u001b[0m       0.5772            0.5772       18.5524  0.0013  1.5509\n",
      "     22            1.0000        0.0217       0.6397            0.6397       17.4006  0.0008  1.5691\n",
      "     23            1.0000        0.0330       0.6654            0.6654       16.5967  0.0003  1.5601\n",
      "     24            1.0000        0.0241       0.6875            0.6875       16.1584  0.0001  1.5700\n",
      "     25            1.0000        0.0288       0.6912            0.6912       15.9458  0.0000  1.5924\n",
      "Best Cross Validation Accuracy: 0.721\n",
      "Best Cross Validation Kappa Score: 0.441\n",
      "\n",
      " ######################### Training for Subject: 4 ######################### \n",
      "\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6811\u001b[0m        \u001b[32m0.5334\u001b[0m       \u001b[35m0.4375\u001b[0m            \u001b[31m0.4375\u001b[0m        \u001b[94m4.3133\u001b[0m  0.0200  1.5767\n",
      "      2            \u001b[36m0.6976\u001b[0m        \u001b[32m0.2438\u001b[0m       0.2647            0.2647        \u001b[94m2.5534\u001b[0m  0.0199  1.5509\n",
      "      3            \u001b[36m0.6985\u001b[0m        0.2912       \u001b[35m0.9191\u001b[0m            \u001b[31m0.9191\u001b[0m        \u001b[94m0.7826\u001b[0m  0.0197  1.5571\n",
      "      4            \u001b[36m0.7307\u001b[0m        \u001b[32m0.2160\u001b[0m       0.3162            0.3162        2.9445  0.0192  1.6485\n",
      "      5            0.6213        \u001b[32m0.1720\u001b[0m       0.7904            0.7904        1.5136  0.0187  1.6026\n",
      "      6            0.6406        \u001b[32m0.1468\u001b[0m       0.6507            0.6507        1.8448  0.0179  1.6772\n",
      "      7            0.6544        \u001b[32m0.1330\u001b[0m       0.7353            0.7353        1.8599  0.0171  1.6668\n",
      "      8            0.5671        \u001b[32m0.1116\u001b[0m       0.6397            0.6397        2.5980  0.0161  1.7302\n",
      "      9            \u001b[36m0.9246\u001b[0m        \u001b[32m0.0933\u001b[0m       0.6507            0.6507        2.6322  0.0150  1.6854\n",
      "     10            0.8199        \u001b[32m0.0818\u001b[0m       0.4669            0.4669        5.6048  0.0138  1.7503\n",
      "     11            0.8649        \u001b[32m0.0652\u001b[0m       0.4963            0.4963        5.3923  0.0126  1.6580\n",
      "     12            0.8447        \u001b[32m0.0484\u001b[0m       0.4669            0.4669        7.6751  0.0113  1.6690\n",
      "     13            \u001b[36m1.0000\u001b[0m        0.0511       0.5294            0.5294        5.3613  0.0100  1.6107\n",
      "     14            0.9972        \u001b[32m0.0397\u001b[0m       0.5515            0.5515        5.4373  0.0087  1.6458\n",
      "     15            0.9853        0.0534       0.5809            0.5809        5.3058  0.0074  1.6756\n",
      "     16            0.9917        0.0519       0.5846            0.5846        5.1549  0.0062  1.7048\n",
      "     17            0.9835        0.0398       0.5993            0.5993        4.6851  0.0050  1.6614\n",
      "     18            0.9623        \u001b[32m0.0394\u001b[0m       0.6029            0.6029        4.5343  0.0039  1.5870\n",
      "     19            0.9954        \u001b[32m0.0321\u001b[0m       0.5735            0.5735        4.8390  0.0029  1.6101\n",
      "     20            1.0000        0.0327       0.5662            0.5662        5.2264  0.0021  1.5989\n",
      "     21            0.9963        0.0334       0.5846            0.5846        4.8860  0.0013  1.6228\n",
      "     22            0.9982        \u001b[32m0.0288\u001b[0m       0.5735            0.5735        5.1546  0.0008  1.5809\n",
      "     23            0.9982        0.0353       0.5735            0.5735        5.1784  0.0003  1.5722\n",
      "     24            1.0000        0.0326       0.5662            0.5662        5.2872  0.0001  1.5930\n",
      "     25            1.0000        0.0395       0.5662            0.5662        5.3512  0.0000  1.6198\n",
      "Best Cross Validation Accuracy: 0.919\n",
      "Best Cross Validation Kappa Score: 0.838\n",
      "\n",
      " ######################### Training for Subject: 5 ######################### \n",
      "\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5607\u001b[0m        \u001b[32m0.7869\u001b[0m       \u001b[35m0.5000\u001b[0m            \u001b[31m0.5000\u001b[0m        \u001b[94m1.1396\u001b[0m  0.0200  1.5729\n",
      "      2            \u001b[36m0.8134\u001b[0m        \u001b[32m0.3735\u001b[0m       \u001b[35m0.5110\u001b[0m            \u001b[31m0.5110\u001b[0m        \u001b[94m0.8949\u001b[0m  0.0199  1.5702\n",
      "      3            \u001b[36m0.8741\u001b[0m        \u001b[32m0.3146\u001b[0m       0.4890            0.4890        \u001b[94m0.8649\u001b[0m  0.0197  1.6059\n",
      "      4            \u001b[36m0.9329\u001b[0m        \u001b[32m0.2391\u001b[0m       0.4559            0.4559        1.1395  0.0192  1.5861\n",
      "      5            0.5496        \u001b[32m0.2364\u001b[0m       0.5000            0.5000        3.3622  0.0187  1.6252\n",
      "      6            0.5000        \u001b[32m0.1961\u001b[0m       0.5000            0.5000        5.8140  0.0179  1.6848\n",
      "      7            0.5836        \u001b[32m0.1508\u001b[0m       0.5074            0.5074        3.3893  0.0171  1.6730\n",
      "      8            0.6333        \u001b[32m0.1317\u001b[0m       \u001b[35m0.5221\u001b[0m            \u001b[31m0.5221\u001b[0m        2.7546  0.0161  1.7086\n",
      "      9            0.5257        \u001b[32m0.1193\u001b[0m       0.5000            0.5000        6.0009  0.0150  1.6357\n",
      "     10            0.5947        \u001b[32m0.1155\u001b[0m       0.5147            0.5147        3.7257  0.0138  1.6039\n",
      "     11            0.5322        \u001b[32m0.0828\u001b[0m       0.5000            0.5000        5.7522  0.0126  1.6820\n",
      "     12            0.5754        \u001b[32m0.0765\u001b[0m       0.5221            0.5221        4.4643  0.0113  1.6512\n",
      "     13            \u001b[36m0.9568\u001b[0m        0.0770       0.4375            0.4375        2.8491  0.0100  1.7455\n",
      "     14            0.6719        \u001b[32m0.0690\u001b[0m       0.5221            0.5221        4.9266  0.0087  1.6163\n",
      "     15            \u001b[36m0.9881\u001b[0m        0.1065       0.4118            0.4118        2.9037  0.0074  1.5977\n",
      "     16            \u001b[36m0.9972\u001b[0m        0.1014       0.4265            0.4265        2.6604  0.0062  1.7121\n",
      "     17            0.8520        \u001b[32m0.0574\u001b[0m       \u001b[35m0.5478\u001b[0m            \u001b[31m0.5478\u001b[0m        3.3310  0.0050  1.8365\n",
      "     18            0.6664        0.0577       0.5404            0.5404        4.4145  0.0039  1.6838\n",
      "     19            0.9835        \u001b[32m0.0427\u001b[0m       0.4743            0.4743        2.4788  0.0029  1.8960\n",
      "     20            0.9954        0.0606       0.3860            0.3860        3.0920  0.0021  1.6714\n",
      "     21            \u001b[36m0.9991\u001b[0m        0.0533       0.4044            0.4044        2.8624  0.0013  1.7137\n",
      "     22            0.9991        0.0584       0.3971            0.3971        2.7885  0.0008  1.6833\n",
      "     23            0.9991        \u001b[32m0.0390\u001b[0m       0.3971            0.3971        2.7700  0.0003  1.6930\n",
      "     24            0.9991        0.0600       0.3971            0.3971        2.8128  0.0001  1.7501\n",
      "     25            0.9991        \u001b[32m0.0353\u001b[0m       0.3971            0.3971        2.8374  0.0000  1.6850\n",
      "Best Cross Validation Accuracy: 0.548\n",
      "Best Cross Validation Kappa Score: 0.096\n",
      "\n",
      " ######################### Training for Subject: 6 ######################### \n",
      "\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5248\u001b[0m        \u001b[32m0.4951\u001b[0m       \u001b[35m0.6140\u001b[0m            \u001b[31m0.6140\u001b[0m        \u001b[94m2.0019\u001b[0m  0.0200  1.7367\n",
      "      2            \u001b[36m0.5827\u001b[0m        \u001b[32m0.1813\u001b[0m       \u001b[35m0.7243\u001b[0m            \u001b[31m0.7243\u001b[0m        \u001b[94m1.4740\u001b[0m  0.0199  1.7916\n",
      "      3            \u001b[36m0.9724\u001b[0m        \u001b[32m0.1471\u001b[0m       0.4816            0.4816        1.9466  0.0197  1.6267\n",
      "      4            0.8410        \u001b[32m0.1344\u001b[0m       0.4890            0.4890        4.3406  0.0192  1.6094\n",
      "      5            \u001b[36m0.9853\u001b[0m        \u001b[32m0.0905\u001b[0m       0.5000            0.5000        2.4323  0.0187  1.6793\n",
      "      6            0.9393        \u001b[32m0.0604\u001b[0m       0.4706            0.4706        4.2759  0.0179  1.6571\n",
      "      7            0.5138        0.1264       0.4963            0.4963       10.3546  0.0171  1.5962\n",
      "      8            \u001b[36m0.9936\u001b[0m        0.0778       0.5037            0.5037        2.9599  0.0161  1.7367\n",
      "      9            0.8667        0.0791       \u001b[35m0.8309\u001b[0m            \u001b[31m0.8309\u001b[0m        \u001b[94m0.9581\u001b[0m  0.0150  1.6472\n",
      "     10            \u001b[36m1.0000\u001b[0m        0.0789       0.4890            0.4890        2.9412  0.0138  1.6003\n",
      "     11            0.9991        \u001b[32m0.0508\u001b[0m       0.4632            0.4632        3.8338  0.0126  1.5626\n",
      "     12            0.9982        0.0519       0.4596            0.4596        4.1495  0.0113  1.5495\n",
      "     13            0.8015        0.0598       \u001b[35m0.8713\u001b[0m            \u001b[31m0.8713\u001b[0m        \u001b[94m0.7812\u001b[0m  0.0100  1.5645\n",
      "     14            0.9605        0.0791       0.5037            0.5037        4.5007  0.0087  1.6036\n",
      "     15            1.0000        \u001b[32m0.0403\u001b[0m       0.5110            0.5110        3.0655  0.0074  1.5976\n",
      "     16            1.0000        0.0434       0.5551            0.5551        2.3532  0.0062  1.6313\n",
      "     17            1.0000        \u001b[32m0.0276\u001b[0m       0.5441            0.5441        2.5797  0.0050  1.6213\n",
      "     18            1.0000        0.0343       0.5478            0.5478        2.4931  0.0039  1.5834\n",
      "     19            1.0000        \u001b[32m0.0237\u001b[0m       0.5735            0.5735        2.2717  0.0029  1.5277\n",
      "     20            1.0000        \u001b[32m0.0125\u001b[0m       0.5699            0.5699        2.2799  0.0021  1.6144\n",
      "     21            1.0000        0.0260       0.5257            0.5257        2.6264  0.0013  1.5730\n",
      "     22            1.0000        0.0302       0.5184            0.5184        2.8807  0.0008  1.5629\n",
      "     23            1.0000        0.0231       0.5184            0.5184        2.8082  0.0003  1.5325\n",
      "     24            1.0000        0.0285       0.5184            0.5184        2.7303  0.0001  1.5766\n",
      "     25            1.0000        0.0296       0.5184            0.5184        2.7001  0.0000  1.5950\n",
      "Best Cross Validation Accuracy: 0.871\n",
      "Best Cross Validation Kappa Score: 0.743\n",
      "\n",
      " ######################### Training for Subject: 7 ######################### \n",
      "\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m0.7099\u001b[0m       \u001b[35m0.5625\u001b[0m            \u001b[31m0.5625\u001b[0m       \u001b[94m33.1384\u001b[0m  0.0200  1.6047\n",
      "      2            0.5000        \u001b[32m0.1528\u001b[0m       0.5625            0.5625       \u001b[94m27.5854\u001b[0m  0.0199  1.6320\n",
      "      3            0.5000        \u001b[32m0.1216\u001b[0m       0.5625            0.5625       \u001b[94m21.2737\u001b[0m  0.0197  1.5946\n",
      "      4            0.5000        0.1504       0.5625            0.5625       \u001b[94m10.7944\u001b[0m  0.0192  1.5566\n",
      "      5            \u001b[36m0.5276\u001b[0m        0.1273       0.5515            0.5515        \u001b[94m7.4733\u001b[0m  0.0187  1.6012\n",
      "      6            \u001b[36m0.9118\u001b[0m        0.1822       \u001b[35m0.8235\u001b[0m            \u001b[31m0.8235\u001b[0m        \u001b[94m1.5013\u001b[0m  0.0179  1.5418\n",
      "      7            0.6866        \u001b[32m0.0858\u001b[0m       \u001b[35m0.8456\u001b[0m            \u001b[31m0.8456\u001b[0m        \u001b[94m1.2156\u001b[0m  0.0171  1.5575\n",
      "      8            0.5083        0.0969       0.5919            0.5919        3.7629  0.0161  1.5511\n",
      "      9            0.6700        0.0894       \u001b[35m0.8493\u001b[0m            \u001b[31m0.8493\u001b[0m        1.3156  0.0150  1.5656\n",
      "     10            0.5083        0.0923       0.6287            0.6287        3.6196  0.0138  1.5334\n",
      "     11            0.5368        0.1095       0.7390            0.7390        2.5793  0.0126  1.5460\n",
      "     12            0.6204        0.0864       0.8272            0.8272        1.5436  0.0113  1.5420\n",
      "     13            0.5083        \u001b[32m0.0582\u001b[0m       0.5699            0.5699        5.0232  0.0100  1.5077\n",
      "     14            0.5000        0.0749       0.5000            0.5000        8.3405  0.0087  1.5399\n",
      "     15            0.5000        0.0701       0.5000            0.5000       15.8437  0.0074  1.5668\n",
      "     16            0.5000        0.0683       0.5000            0.5000       13.4133  0.0062  1.5545\n",
      "     17            0.5083        0.0764       0.5184            0.5184        5.2131  0.0050  1.5804\n",
      "     18            0.5083        \u001b[32m0.0444\u001b[0m       0.5588            0.5588        5.2333  0.0039  1.5372\n",
      "     19            0.5092        \u001b[32m0.0430\u001b[0m       0.6654            0.6654        4.2332  0.0029  1.5324\n",
      "     20            0.5083        0.0921       0.5588            0.5588        5.3685  0.0021  1.5725\n",
      "     21            0.5083        0.0587       0.6581            0.6581        4.2084  0.0013  1.6403\n",
      "     22            0.5368        0.0485       0.7390            0.7390        2.7277  0.0008  1.6183\n",
      "     23            0.5818        \u001b[32m0.0360\u001b[0m       0.8272            0.8272        2.1159  0.0003  1.6241\n",
      "     24            0.6268        0.0362       0.8382            0.8382        1.6708  0.0001  1.6529\n",
      "     25            0.7224        0.0441       \u001b[35m0.8529\u001b[0m            \u001b[31m0.8529\u001b[0m        1.4667  0.0000  1.5513\n",
      "Best Cross Validation Accuracy: 0.853\n",
      "Best Cross Validation Kappa Score: 0.706\n",
      "\n",
      " ######################### Training for Subject: 8 ######################### \n",
      "\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5028\u001b[0m        \u001b[32m0.7876\u001b[0m       \u001b[35m0.7059\u001b[0m            \u001b[31m0.7059\u001b[0m        \u001b[94m1.3334\u001b[0m  0.0200  1.5931\n",
      "      2            0.5000        \u001b[32m0.4253\u001b[0m       0.5000            0.5000        7.5691  0.0199  1.5837\n",
      "      3            0.5000        \u001b[32m0.3398\u001b[0m       0.5000            0.5000        4.9734  0.0197  1.5410\n",
      "      4            \u001b[36m0.5230\u001b[0m        \u001b[32m0.2996\u001b[0m       \u001b[35m0.8676\u001b[0m            \u001b[31m0.8676\u001b[0m        1.3751  0.0192  1.6001\n",
      "      5            0.5000        \u001b[32m0.2449\u001b[0m       0.5000            0.5000        5.0935  0.0187  1.5472\n",
      "      6            0.5000        \u001b[32m0.2172\u001b[0m       0.5000            0.5000        8.6849  0.0179  1.5793\n",
      "      7            0.5000        \u001b[32m0.1835\u001b[0m       0.5000            0.5000       11.8479  0.0171  1.6303\n",
      "      8            0.5000        \u001b[32m0.1600\u001b[0m       0.5000            0.5000        4.9138  0.0161  1.5690\n",
      "      9            0.5083        0.1730       0.4375            0.4375       12.0999  0.0150  1.5754\n",
      "     10            0.5092        \u001b[32m0.1122\u001b[0m       0.5000            0.5000       14.7890  0.0138  1.6104\n",
      "     11            \u001b[36m0.7206\u001b[0m        0.1259       0.4375            0.4375        3.6490  0.0126  1.5228\n",
      "     12            0.5000        0.1276       0.5000            0.5000        9.8474  0.0113  1.5780\n",
      "     13            \u001b[36m0.8722\u001b[0m        \u001b[32m0.0807\u001b[0m       0.5037            0.5037        3.0080  0.0100  1.5201\n",
      "     14            0.5395        \u001b[32m0.0561\u001b[0m       0.4375            0.4375        8.8811  0.0087  1.5335\n",
      "     15            0.5000        0.0871       0.5000            0.5000       14.9186  0.0074  1.5388\n",
      "     16            0.7325        0.0721       0.4375            0.4375        6.2624  0.0062  1.5681\n",
      "     17            0.5064        0.0719       0.4375            0.4375       16.1001  0.0050  1.5571\n",
      "     18            0.5000        0.0616       0.5000            0.5000        8.2883  0.0039  1.5541\n",
      "     19            0.5836        0.0642       0.7868            0.7868        3.7589  0.0029  1.5534\n",
      "     20            0.6471        \u001b[32m0.0555\u001b[0m       \u001b[35m0.8824\u001b[0m            \u001b[31m0.8824\u001b[0m        3.7302  0.0021  1.5794\n",
      "     21            0.6434        \u001b[32m0.0519\u001b[0m       0.8566            0.8566        3.7557  0.0013  1.6435\n",
      "     22            0.8070        \u001b[32m0.0362\u001b[0m       \u001b[35m0.9081\u001b[0m            \u001b[31m0.9081\u001b[0m        3.5784  0.0008  1.5998\n",
      "     23            0.8070        0.0440       \u001b[35m0.9154\u001b[0m            \u001b[31m0.9154\u001b[0m        3.8019  0.0003  1.5746\n",
      "     24            0.7472        \u001b[32m0.0328\u001b[0m       0.9154            0.9154        4.0928  0.0001  1.5936\n",
      "     25            0.8033        0.0361       0.9081            0.9081        4.2005  0.0000  1.5723\n",
      "Best Cross Validation Accuracy: 0.915\n",
      "Best Cross Validation Kappa Score: 0.831\n",
      "\n",
      " ######################### Training for Subject: 9 ######################### \n",
      "\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5579\u001b[0m        \u001b[32m1.1589\u001b[0m       \u001b[35m0.9265\u001b[0m            \u001b[31m0.9265\u001b[0m        \u001b[94m0.2054\u001b[0m  0.0200  1.6185\n",
      "      2            0.5248        \u001b[32m0.4184\u001b[0m       0.5000            0.5000        6.6176  0.0199  1.6209\n",
      "      3            0.5083        \u001b[32m0.3713\u001b[0m       0.5000            0.5000        7.2715  0.0197  1.5812\n",
      "      4            0.5000        \u001b[32m0.2785\u001b[0m       0.5000            0.5000       18.5622  0.0192  1.6030\n",
      "      5            0.5092        0.3117       0.5000            0.5000       10.3661  0.0187  1.6013\n",
      "      6            \u001b[36m0.7040\u001b[0m        \u001b[32m0.2619\u001b[0m       0.8603            0.8603        0.4347  0.0179  1.6025\n",
      "      7            \u001b[36m0.9320\u001b[0m        \u001b[32m0.2211\u001b[0m       0.5809            0.5809        2.1689  0.0171  1.5511\n",
      "      8            0.5092        \u001b[32m0.2108\u001b[0m       0.5000            0.5000       11.8663  0.0161  1.5824\n",
      "      9            0.5000        \u001b[32m0.1877\u001b[0m       0.5000            0.5000       12.7295  0.0150  1.5861\n",
      "     10            0.5285        \u001b[32m0.1388\u001b[0m       0.5000            0.5000        8.8447  0.0138  1.5800\n",
      "     11            0.7316        0.1472       0.8199            0.8199        0.5349  0.0126  1.5080\n",
      "     12            0.5331        \u001b[32m0.1145\u001b[0m       0.5000            0.5000        7.9477  0.0113  1.7133\n",
      "     13            0.5340        0.1223       0.5000            0.5000        8.7962  0.0100  1.6952\n",
      "     14            0.5450        \u001b[32m0.0850\u001b[0m       0.5000            0.5000        8.0375  0.0087  1.5593\n",
      "     15            0.5018        0.1155       0.5000            0.5000       13.4209  0.0074  1.5909\n",
      "     16            0.7564        0.0859       0.8603            0.8603        0.6061  0.0062  1.5779\n",
      "     17            0.5276        \u001b[32m0.0630\u001b[0m       0.5000            0.5000       12.1698  0.0050  1.5404\n",
      "     18            0.5018        0.0814       0.5000            0.5000       14.4944  0.0039  1.5203\n",
      "     19            0.8842        \u001b[32m0.0622\u001b[0m       0.5699            0.5699        3.8640  0.0029  1.5657\n",
      "     20            \u001b[36m0.9945\u001b[0m        0.0695       0.7132            0.7132        2.0302  0.0021  1.7260\n",
      "     21            0.9329        0.0875       0.5735            0.5735        3.4325  0.0013  1.8341\n",
      "     22            0.9853        \u001b[32m0.0575\u001b[0m       0.6691            0.6691        2.5694  0.0008  1.7486\n",
      "     23            0.9936        0.0581       0.7096            0.7096        1.9573  0.0003  1.5846\n",
      "     24            0.9945        0.0731       0.7059            0.7059        1.9894  0.0001  1.5177\n",
      "     25            \u001b[36m0.9954\u001b[0m        0.0607       0.7022            0.7022        2.0232  0.0000  1.4889\n",
      "Best Cross Validation Accuracy: 0.926\n",
      "Best Cross Validation Kappa Score: 0.853\n",
      "\n",
      " ######################### Training for Subject: 10 ######################### \n",
      "\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m0.8069\u001b[0m       \u001b[35m0.5000\u001b[0m            \u001b[31m0.5000\u001b[0m        \u001b[94m2.5804\u001b[0m  0.0200  1.4635\n",
      "      2            \u001b[36m0.6985\u001b[0m        \u001b[32m0.4127\u001b[0m       0.4375            0.4375        \u001b[94m1.5552\u001b[0m  0.0199  1.4789\n",
      "      3            \u001b[36m0.7068\u001b[0m        \u001b[32m0.3105\u001b[0m       0.4375            0.4375        1.7172  0.0197  1.4896\n",
      "      4            0.6912        0.3237       \u001b[35m0.5257\u001b[0m            \u001b[31m0.5257\u001b[0m        1.7095  0.0192  1.6592\n",
      "      5            0.5717        \u001b[32m0.2732\u001b[0m       0.5110            0.5110        \u001b[94m1.4003\u001b[0m  0.0187  1.5571\n",
      "      6            \u001b[36m0.9494\u001b[0m        \u001b[32m0.2638\u001b[0m       \u001b[35m0.7978\u001b[0m            \u001b[31m0.7978\u001b[0m        \u001b[94m0.5380\u001b[0m  0.0179  1.6114\n",
      "      7            0.8125        \u001b[32m0.2432\u001b[0m       0.5772            0.5772        0.9901  0.0171  1.6537\n",
      "      8            \u001b[36m0.9642\u001b[0m        \u001b[32m0.2254\u001b[0m       0.7574            0.7574        0.7334  0.0161  1.5796\n",
      "      9            0.7702        \u001b[32m0.2230\u001b[0m       0.7537            0.7537        0.6605  0.0150  1.5434\n",
      "     10            \u001b[36m0.9706\u001b[0m        \u001b[32m0.1659\u001b[0m       0.7610            0.7610        0.7970  0.0138  1.5185\n",
      "     11            0.7381        0.2124       0.6728            0.6728        0.8924  0.0126  1.5234\n",
      "     12            0.9164        0.1715       0.7831            0.7831        0.8405  0.0113  1.5151\n",
      "     13            0.8015        \u001b[32m0.1453\u001b[0m       0.7059            0.7059        0.9535  0.0100  1.4999\n",
      "     14            \u001b[36m0.9807\u001b[0m        0.1620       0.7941            0.7941        0.7638  0.0087  1.5525\n",
      "     15            0.8061        0.1622       0.7868            0.7868        0.8206  0.0074  1.5760\n",
      "     16            0.7279        0.1522       0.6838            0.6838        1.0560  0.0062  1.5280\n",
      "     17            0.8640        \u001b[32m0.1221\u001b[0m       0.7390            0.7390        0.8651  0.0050  1.5271\n",
      "     18            0.8805        0.1369       \u001b[35m0.8051\u001b[0m            \u001b[31m0.8051\u001b[0m        0.7482  0.0039  1.5328\n",
      "     19            0.9550        0.1233       \u001b[35m0.8199\u001b[0m            \u001b[31m0.8199\u001b[0m        0.7230  0.0029  1.4955\n",
      "     20            \u001b[36m0.9816\u001b[0m        0.1295       0.8162            0.8162        0.7263  0.0021  1.5272\n",
      "     21            0.9706        0.1284       0.7978            0.7978        0.7642  0.0013  1.5785\n",
      "     22            0.9642        \u001b[32m0.1088\u001b[0m       0.7941            0.7941        0.7605  0.0008  1.5503\n",
      "     23            0.9816        0.1102       0.7978            0.7978        0.7447  0.0003  1.5401\n",
      "     24            0.9816        0.1254       0.8125            0.8125        0.7376  0.0001  1.5405\n",
      "     25            \u001b[36m0.9853\u001b[0m        0.1219       0.8088            0.8088        0.7338  0.0000  1.5487\n",
      "Best Cross Validation Accuracy: 0.820\n",
      "Best Cross Validation Kappa Score: 0.640\n",
      "\n",
      "==================================================\n",
      "Mean Cross-Subject Accuracy: 0.833\n",
      "Mean Cross-Subject Kappa:    0.665\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "all_subject_acc = []\n",
    "all_subject_kappa = []\n",
    "\n",
    "def training_function(subject_index=0):\n",
    "    print('\\n', '#' * 25, 'Training for Subject:', subject_index + 1, '#' * 25, '\\n')\n",
    "    \n",
    "    dataset = windows_datasets_list[subject_index]\n",
    "    \n",
    "    y = np.concatenate([d.y for d in dataset.datasets])\n",
    "    \n",
    "    clfs_list[subject_index].fit(dataset, y=y, epochs=n_epochs)\n",
    "    \n",
    "    history = clfs_list[subject_index].history\n",
    "    valid_accs = [entry['valid_accuracy'] for entry in history if 'valid_accuracy' in entry]\n",
    "    \n",
    "    if valid_accs:\n",
    "        best_val_acc = max(valid_accs)\n",
    "        best_val_kappa = (2 * best_val_acc) - 1\n",
    "        print(f\"Best Cross Validation Accuracy: {best_val_acc:.3f}\")\n",
    "        print(f\"Best Cross Validation Kappa Score: {best_val_kappa:.3f}\")\n",
    "        \n",
    "      \n",
    "        all_subject_acc.append(best_val_acc)\n",
    "        all_subject_kappa.append(best_val_kappa)\n",
    "    else:\n",
    "        print(\"Validation accuracy not available in history.\")\n",
    "\n",
    "\n",
    "for sub_idx in range(len(windows_datasets_list)):\n",
    "    training_function(sub_idx)\n",
    "\n",
    "mean_acc = np.mean(all_subject_acc)\n",
    "mean_kappa = np.mean(all_subject_kappa)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Mean Within-Subject Accuracy: {mean_acc:.3f}\")\n",
    "print(f\"Mean Within-Subject Kappa:    {mean_kappa:.3f}\")\n",
    "print(\"=\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
