{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinical BCI Challenge-WCCI2020\n",
    "- [website link](https://sites.google.com/view/bci-comp-wcci/?fbclid=IwAR37WLQ_xNd5qsZvktZCT8XJerHhmVb_bU5HDu69CnO85DE3iF0fs57vQ6M)\n",
    "\n",
    "\n",
    " - [Dataset Link](https://github.com/5anirban9/Clinical-Brain-Computer-Interfaces-Challenge-WCCI-2020-Glasgow)\n",
    " \n",
    " \n",
    " - [Braindecode Tutorial](https://braindecode.org/auto_examples/plot_bcic_iv_2a_moabb_trial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from mne.decoding import CSP\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False                    # global variable to suppress output display of MNE functions\n",
    "mne.set_log_level(verbose=verbose) # to suppress large info outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = None  # for multicore parallel processing, set it to 1 if cause memory issues, for full utilization set to -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Conversion to MNE Datatypes\n",
    "[Mike Cohen Tutorials link for EEG Preprocessing](https://www.youtube.com/watch?v=uWB5tjhataY&list=PLn0OLiymPak2gDD-VDA90w9_iGDgOOb2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = globals()['_dh'][0]  # a hack to get path of current folder in which jupyter file is located\n",
    "data_path = os.path.join(current_folder, r\"C:\\Users\\MILAKUL\\Documents\\Thesis\\clinicalBCI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_files   = glob.glob(data_path + '/*T.mat')\n",
    "len(training_files)     # if  return zero,then no file is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have modified the labels values from [1, 2] to [0, 1] as pytorch \n",
    "# expects labels/classes to be in [0, n_classes-1] format\n",
    "def get_mne_epochs(filepath, verbose=verbose, t_start=2, fs=512, mode='train'):\n",
    "    '''\n",
    "    This function reads the EEG data from .mat file and convert it to MNE-Python Compatible epochs\n",
    "    data structure. It takes data from [0, 8] sec range and return it by setting t = 0 at cue onset\n",
    "    i.e. 3 seconds and dropping first two seconds so the output data is in [-1.0, 5.0] sec range. The\n",
    "    Details can be found in the preprocessing section of the attached document\n",
    "    '''\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    eeg_data= mat_data['RawEEGData']\n",
    "    idx_start = fs*t_start      \n",
    "    eeg_data = eeg_data[:, :, idx_start:]\n",
    "    event_id = {'left-hand': 0, 'right-hand': 1} # pytorch expects labels in [0, n_classes-1]\n",
    "    channel_names = ['F3', 'FC3', 'C3', 'CP3', 'P3', 'FCz', 'CPz', 'F4', 'FC4', 'C4', 'CP4', 'P4']\n",
    "    info = mne.create_info(ch_names=channel_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, verbose=verbose, tmin=t_start-3.0)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None) \n",
    "    epochs.apply_baseline(baseline=(-.250, 0)) # linear baseline correction\n",
    "    \n",
    "    if mode == 'train': # this in only applicable for training data\n",
    "        epochs.event_id = event_id \n",
    "        epochs.events[:,2] = mat_data['Labels'].ravel() - 1    \n",
    "    return epochs \n",
    "\n",
    "def get_labels(filepath):\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    return mat_data['Labels'].ravel() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG Data:  (80, 12, 3072) \t Shape of Labels:  (80,)\n"
     ]
    }
   ],
   "source": [
    "epochs, labels = get_mne_epochs(training_files[0], verbose=verbose), get_labels(training_files[0])\n",
    "data = epochs.get_data()\n",
    "print('Shape of EEG Data: ', data.shape, '\\t Shape of Labels: ', labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading original data\n",
    "epochs_list_train = []\n",
    "for i in training_files:\n",
    "    epochs_list_train.append(get_mne_epochs(i, verbose=verbose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Braindecode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's Training Time with [0.5, 4.5] sec and 2sec window with 125ms stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets per subject: 8\n",
      "Total windows for first subject: 1360\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datautil import create_from_mne_epochs\n",
    "\n",
    "window_size = 1024   # 2 sec windows\n",
    "window_stride = 64   # 125 ms stride\n",
    "\n",
    "windows_datasets_list = []\n",
    "\n",
    "for epoch in epochs_list_train:\n",
    "    # Create windows per subject\n",
    "    windows_dataset = create_from_mne_epochs(\n",
    "        [epoch.crop(tmin=0.5, tmax=4.5, include_tmax=False)],\n",
    "        window_size_samples=window_size,\n",
    "        window_stride_samples=window_stride,\n",
    "        drop_last_window=False\n",
    "    )\n",
    "    # Add labels as a separate attribute\n",
    "    windows_dataset.update_description = pd.DataFrame(\n",
    "        data=np.concatenate([d.y for d in windows_dataset.datasets]),\n",
    "        columns=['labels']\n",
    "    )\n",
    "    windows_datasets_list.append(windows_dataset)\n",
    "\n",
    "print(\"Datasets per subject:\", len(windows_datasets_list))\n",
    "print(\"Total windows for first subject:\", len(windows_datasets_list[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.preprocessing import exponential_moving_standardize\n",
    "\n",
    "low_cut_hz = 8.   # low cut frequency for filtering\n",
    "high_cut_hz = 32. # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\n",
    "    \"\"\"Apply exponential moving standardization to MNE epochs inplace.\"\"\"\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        data[i] = exponential_moving_standardize(\n",
    "            data[i], factor_new=factor_new, init_block_size=init_block_size\n",
    "        )\n",
    "    epochs._data = data\n",
    "    return epochs\n",
    "\n",
    "# Apply preprocessing to each dataset\n",
    "for windows_dataset in windows_datasets_list:\n",
    "    # Extract the underlying MNE Epochs object\n",
    "    epochs = windows_dataset.datasets[0].windows\n",
    "    epochs.load_data()  # Ensure data is loaded into memory\n",
    "\n",
    "    # 1) Keep only EEG channels\n",
    "    epochs.pick_types(eeg=True)\n",
    "\n",
    "    # 2) Bandpass filter\n",
    "    epochs.filter(l_freq=low_cut_hz, h_freq=high_cut_hz)\n",
    "\n",
    "    # 3) Exponential moving standardization\n",
    "    custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from braindecode.preprocessing import exponential_moving_standardize\\nfrom braindecode.preprocessing import MNEPreproc, NumpyPreproc, preprocess\\n\\nlow_cut_hz = 8.  # low cut frequency for filtering\\nhigh_cut_hz = 32.  # high cut frequency for filtering\\n# Parameters for exponential moving standardization\\nfactor_new = 1e-3\\ninit_block_size = 1000\\n\\ndef custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\\n    data = epochs.get_data()\\n    for i in range(len(data)):\\n        epochs._data[i] = exponential_moving_standardize(data[i], \\n                        factor_new=factor_new, init_block_size=init_block_size)\\n    return epochs\\n\\npreprocessors = [\\n    # keep only EEG sensors\\n    MNEPreproc(fn='pick_types', eeg=True, meg=False, stim=False),\\n    # bandpass filter\\n    MNEPreproc(fn='filter', l_freq=low_cut_hz, h_freq=high_cut_hz),\\n    # exponential moving standardization\\n    MNEPreproc(fn=custom_exp_moving_std_fn, factor_new=factor_new,\\n        init_block_size=init_block_size)\\n]\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from braindecode.preprocessing import exponential_moving_standardize\n",
    "from braindecode.preprocessing import MNEPreproc, NumpyPreproc, preprocess\n",
    "\n",
    "low_cut_hz = 8.  # low cut frequency for filtering\n",
    "high_cut_hz = 32.  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        epochs._data[i] = exponential_moving_standardize(data[i], \n",
    "                        factor_new=factor_new, init_block_size=init_block_size)\n",
    "    return epochs\n",
    "\n",
    "preprocessors = [\n",
    "    # keep only EEG sensors\n",
    "    MNEPreproc(fn='pick_types', eeg=True, meg=False, stim=False),\n",
    "    # bandpass filter\n",
    "    MNEPreproc(fn='filter', l_freq=low_cut_hz, h_freq=high_cut_hz),\n",
    "    # exponential moving standardization\n",
    "    MNEPreproc(fn=custom_exp_moving_std_fn, factor_new=factor_new,\n",
    "        init_block_size=init_block_size)\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for windows_dataset in windows_datasets_list: \\n    preprocess(windows_dataset, preprocessors)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for windows_dataset in windows_datasets_list: \n",
    "    preprocess(windows_dataset, preprocessors)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #64\n",
    "n_epochs = 25 #25 #20 #25 use few epochs for quick verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, EEGNetv4\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes=2\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_chans = windows_datasets_list[0][0][0].shape[0]\n",
    "input_window_samples = windows_datasets_list[0][0][0].shape[1]\n",
    "\n",
    "model = EEGNetv4(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    n_times = window_size, #input_window_samples,\n",
    "    final_conv_length='auto',\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "lr = 1 * 0.02 #0.01 \n",
    "weight_decay = 0.5 * 0.001\n",
    "\n",
    "clfs_list = []\n",
    "for i in range(len(epochs_list_train)):\n",
    "    clfs_list.append(\n",
    "        EEGClassifier(\n",
    "                    model,\n",
    "                    criterion = torch.nn.CrossEntropyLoss(),\n",
    "                    optimizer=torch.optim.AdamW,\n",
    "                    #train_split=predefined_split(train_set),  # using valid_set for validation\n",
    "                    optimizer__lr=lr,\n",
    "                    optimizer__weight_decay=weight_decay,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[\n",
    "                        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "                    ],\n",
    "                    device=device,\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def training_function(subject_index=0):\\n    print(\\'\\n\\', \\'#\\'*25, \\'Training for Subject:\\', subject_index+1, \\'#\\'*25, \\'\\n\\')\\n    dataset = windows_datasets_list[subject_index]\\n    clfs_list[subject_index].fit(dataset, y=dataset.description.labels, epochs=n_epochs);\\n    best_validation_acc = clfs_list[subject_index].callbacks_[4][1].best_score_ # a hack to get best validation accuracy\\n    best_validation_kappa = (2*best_validation_acc)-1\\n    print(\"Best Cross Validation Kappa Score: {:.2f}\".format(best_validation_kappa))'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def training_function(subject_index=0):\n",
    "    print('\\n', '#'*25, 'Training for Subject:', subject_index+1, '#'*25, '\\n')\n",
    "    dataset = windows_datasets_list[subject_index]\n",
    "    clfs_list[subject_index].fit(dataset, y=dataset.description.labels, epochs=n_epochs);\n",
    "    best_validation_acc = clfs_list[subject_index].callbacks_[4][1].best_score_ # a hack to get best validation accuracy\n",
    "    best_validation_kappa = (2*best_validation_acc)-1\n",
    "    print(\"Best Cross Validation Kappa Score: {:.2f}\".format(best_validation_kappa))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(subject_index=0):\n",
    "    print('\\n', '#'*25, 'Training for Subject:', subject_index+1, '#'*25, '\\n')\n",
    "    \n",
    "    dataset = windows_datasets_list[subject_index]\n",
    "    \n",
    "    # Get labels directly from the dataset\n",
    "    y = np.concatenate([d.y for d in dataset.datasets])\n",
    "    \n",
    "    # Train the model\n",
    "    clfs_list[subject_index].fit(dataset, y=y, epochs=n_epochs)\n",
    "    \n",
    "    # Get validation accuracy from history\n",
    "    history = clfs_list[subject_index].history\n",
    "    # Convert to a list of dicts\n",
    "    valid_accs = [entry['valid_accuracy'] for entry in history if 'valid_accuracy' in entry]\n",
    "    \n",
    "    if valid_accs:\n",
    "        best_val_acc = max(valid_accs)\n",
    "        best_val_kappa = (2 * best_val_acc) - 1\n",
    "        print(f\"Best Cross Validation Kappa Score: {best_val_kappa:.2f}\")\n",
    "    else:\n",
    "        print(\"Validation accuracy not available in history.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGNetv4 (EEGNetv4)                                          [1, 12, 1024]             [1, 2]                    --                        --\n",
      "├─Ensure4d (ensuredims): 1-1                                 [1, 12, 1024]             [1, 12, 1024, 1]          --                        --\n",
      "├─Rearrange (dimshuffle): 1-2                                [1, 12, 1024, 1]          [1, 1, 12, 1024]          --                        --\n",
      "├─Conv2d (conv_temporal): 1-3                                [1, 1, 12, 1024]          [1, 8, 12, 1025]          512                       [1, 64]\n",
      "├─BatchNorm2d (bnorm_temporal): 1-4                          [1, 8, 12, 1025]          [1, 8, 12, 1025]          16                        --\n",
      "├─ParametrizedConv2dWithConstraint (conv_spatial): 1-5       [1, 8, 12, 1025]          [1, 16, 1, 1025]          --                        [12, 1]\n",
      "│    └─ModuleDict (parametrizations): 2-1                    --                        --                        --                        --\n",
      "│    │    └─ParametrizationList (weight): 3-1                --                        [16, 1, 12, 1]            192                       --\n",
      "├─BatchNorm2d (bnorm_1): 1-6                                 [1, 16, 1, 1025]          [1, 16, 1, 1025]          32                        --\n",
      "├─ELU (elu_1): 1-7                                           [1, 16, 1, 1025]          [1, 16, 1, 1025]          --                        --\n",
      "├─AvgPool2d (pool_1): 1-8                                    [1, 16, 1, 1025]          [1, 16, 1, 256]           --                        [1, 4]\n",
      "├─Dropout (drop_1): 1-9                                      [1, 16, 1, 256]           [1, 16, 1, 256]           --                        --\n",
      "├─Conv2d (conv_separable_depth): 1-10                        [1, 16, 1, 256]           [1, 16, 1, 257]           256                       [1, 16]\n",
      "├─Conv2d (conv_separable_point): 1-11                        [1, 16, 1, 257]           [1, 16, 1, 257]           256                       [1, 1]\n",
      "├─BatchNorm2d (bnorm_2): 1-12                                [1, 16, 1, 257]           [1, 16, 1, 257]           32                        --\n",
      "├─ELU (elu_2): 1-13                                          [1, 16, 1, 257]           [1, 16, 1, 257]           --                        --\n",
      "├─AvgPool2d (pool_2): 1-14                                   [1, 16, 1, 257]           [1, 16, 1, 32]            --                        [1, 8]\n",
      "├─Dropout (drop_2): 1-15                                     [1, 16, 1, 32]            [1, 16, 1, 32]            --                        --\n",
      "├─Sequential (final_layer): 1-16                             [1, 16, 1, 32]            [1, 2]                    --                        --\n",
      "│    └─Conv2d (conv_classifier): 2-2                         [1, 16, 1, 32]            [1, 2, 1, 1]              1,026                     [1, 32]\n",
      "│    └─Rearrange (permute_back): 2-3                         [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
      "│    └─SqueezeFinalOutput (squeeze): 2-4                     [1, 2, 1, 1]              [1, 2]                    --                        --\n",
      "│    │    └─Rearrange (squeeze): 3-2                         [1, 2, 1, 1]              [1, 2, 1]                 --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 2,322\n",
      "Trainable params: 2,322\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.43\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 1.80\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 1.86\n",
      "================================================================================================================================================================\n",
      "CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "print(clfs_list[0].module)        # show model architecture\n",
    "print(clfs_list[0].criterion)     # show loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######################### Training for Subject: 1 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m0.7113\u001b[0m       \u001b[35m0.4375\u001b[0m            \u001b[31m0.4375\u001b[0m       \u001b[94m16.4249\u001b[0m  0.0200  1.9609\n",
      "      2            0.5000        \u001b[32m0.5762\u001b[0m       0.4375            0.4375        \u001b[94m4.9803\u001b[0m  0.0199  1.4772\n",
      "      3            0.5000        \u001b[32m0.4687\u001b[0m       0.4375            0.4375       38.3219  0.0197  1.4220\n",
      "      4            0.5000        \u001b[32m0.4544\u001b[0m       0.4375            0.4375       32.1937  0.0192  1.4292\n",
      "      5            0.5000        \u001b[32m0.4319\u001b[0m       0.4375            0.4375       31.0043  0.0187  1.9089\n",
      "      6            0.5000        \u001b[32m0.4057\u001b[0m       0.4375            0.4375       28.2854  0.0179  1.9856\n",
      "      7            \u001b[36m0.5028\u001b[0m        \u001b[32m0.3802\u001b[0m       \u001b[35m0.8529\u001b[0m            \u001b[31m0.8529\u001b[0m        6.0651  0.0171  2.1531\n",
      "      8            0.5000        \u001b[32m0.3591\u001b[0m       0.5000            0.5000       10.9716  0.0161  2.0925\n",
      "      9            0.5000        \u001b[32m0.3516\u001b[0m       0.5000            0.5000       17.6196  0.0150  1.8919\n",
      "     10            0.5000        \u001b[32m0.3154\u001b[0m       0.5000            0.5000       28.9731  0.0138  1.8810\n",
      "     11            0.5000        \u001b[32m0.3040\u001b[0m       0.5000            0.5000       22.2139  0.0126  1.9560\n",
      "     12            0.5000        \u001b[32m0.2972\u001b[0m       0.5000            0.5000       22.1473  0.0113  2.0753\n",
      "     13            0.5000        \u001b[32m0.2689\u001b[0m       0.5000            0.5000       22.1607  0.0100  1.8902\n",
      "     14            0.5000        \u001b[32m0.2527\u001b[0m       0.5000            0.5000       21.0005  0.0087  1.8785\n",
      "     15            0.5000        \u001b[32m0.2312\u001b[0m       0.5000            0.5000       25.1839  0.0074  2.0431\n",
      "     16            0.5000        \u001b[32m0.1980\u001b[0m       0.5000            0.5000       23.9318  0.0062  2.0509\n",
      "     17            0.5000        \u001b[32m0.1783\u001b[0m       0.5000            0.5000       23.0430  0.0050  2.0789\n",
      "     18            0.5000        \u001b[32m0.1684\u001b[0m       0.5000            0.5000       23.3802  0.0039  2.0776\n",
      "     19            0.5000        \u001b[32m0.1654\u001b[0m       0.5000            0.5000       22.9495  0.0029  2.0682\n",
      "     20            0.5000        \u001b[32m0.1627\u001b[0m       0.5000            0.5000       21.7733  0.0021  2.0252\n",
      "     21            0.5000        0.1787       0.5000            0.5000       14.3864  0.0013  1.9472\n",
      "     22            0.5000        \u001b[32m0.1463\u001b[0m       0.5000            0.5000        9.7276  0.0008  2.1111\n",
      "     23            \u001b[36m0.5046\u001b[0m        \u001b[32m0.1294\u001b[0m       0.7537            0.7537        7.9489  0.0003  2.0500\n",
      "     24            \u001b[36m0.5257\u001b[0m        0.1386       \u001b[35m0.9081\u001b[0m            \u001b[31m0.9081\u001b[0m        7.5291  0.0001  2.1028\n",
      "     25            \u001b[36m0.5432\u001b[0m        0.1407       \u001b[35m0.9154\u001b[0m            \u001b[31m0.9154\u001b[0m        7.3715  0.0000  1.9464\n",
      "Best Cross Validation Kappa Score: 0.83\n",
      "\n",
      " ######################### Training for Subject: 2 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m1.2420\u001b[0m       \u001b[35m0.5625\u001b[0m            \u001b[31m0.5625\u001b[0m       \u001b[94m21.6436\u001b[0m  0.0200  1.8537\n",
      "      2            0.5000        \u001b[32m0.0401\u001b[0m       0.5625            0.5625       \u001b[94m17.9098\u001b[0m  0.0199  1.7849\n",
      "      3            \u001b[36m0.9982\u001b[0m        0.0456       \u001b[35m1.0000\u001b[0m            \u001b[31m1.0000\u001b[0m        \u001b[94m0.0145\u001b[0m  0.0197  1.9034\n",
      "      4            0.5487        \u001b[32m0.0191\u001b[0m       0.5625            0.5625        3.0431  0.0192  1.7169\n",
      "      5            0.9982        0.0385       0.9963            0.9963        0.0179  0.0187  1.7217\n",
      "      6            0.9706        \u001b[32m0.0187\u001b[0m       0.8640            0.8640        0.5138  0.0179  1.8125\n",
      "      7            0.5055        \u001b[32m0.0184\u001b[0m       0.5000            0.5000        8.6136  0.0171  1.9385\n",
      "      8            0.5000        \u001b[32m0.0100\u001b[0m       0.5000            0.5000       14.6763  0.0161  2.1061\n",
      "      9            0.5000        0.0241       0.5000            0.5000       16.2730  0.0150  2.0346\n",
      "     10            0.5000        \u001b[32m0.0069\u001b[0m       0.5000            0.5000       21.6081  0.0138  2.1298\n",
      "     11            0.5000        0.0148       0.5000            0.5000       21.1882  0.0126  2.2847\n",
      "     12            0.5000        0.0076       0.5000            0.5000       37.1670  0.0113  2.4801\n",
      "     13            0.5000        0.0126       0.5000            0.5000       27.7131  0.0100  1.9376\n",
      "     14            0.5377        \u001b[32m0.0054\u001b[0m       0.5000            0.5000        6.3268  0.0087  2.0055\n",
      "     15            0.5046        0.0058       0.5000            0.5000       10.4078  0.0074  1.9780\n",
      "     16            0.8686        0.0060       0.6434            0.6434        1.5055  0.0062  2.4969\n",
      "     17            \u001b[36m0.9991\u001b[0m        \u001b[32m0.0027\u001b[0m       0.9559            0.9559        0.1713  0.0050  2.3164\n",
      "     18            0.9991        0.0031       0.9559            0.9559        0.1895  0.0039  2.2029\n",
      "     19            0.8539        \u001b[32m0.0014\u001b[0m       0.6360            0.6360        1.7582  0.0029  2.4334\n",
      "     20            0.8860        \u001b[32m0.0010\u001b[0m       0.6581            0.6581        1.4597  0.0021  2.5098\n",
      "     21            0.9081        0.0015       0.7022            0.7022        1.2509  0.0013  2.5777\n",
      "     22            0.9853        \u001b[32m0.0005\u001b[0m       0.8971            0.8971        0.5574  0.0008  2.2705\n",
      "     23            0.9972        0.0035       0.9485            0.9485        0.3282  0.0003  2.2486\n",
      "     24            0.9991        0.0014       0.9522            0.9522        0.2096  0.0001  2.1396\n",
      "     25            \u001b[36m1.0000\u001b[0m        0.0026       0.9596            0.9596        0.1415  0.0000  2.0332\n",
      "Best Cross Validation Kappa Score: 1.00\n",
      "\n",
      " ######################### Training for Subject: 3 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m2.1234\u001b[0m       \u001b[35m0.4375\u001b[0m            \u001b[31m0.4375\u001b[0m       \u001b[94m31.2006\u001b[0m  0.0200  1.7988\n",
      "      2            \u001b[36m0.6443\u001b[0m        \u001b[32m0.3978\u001b[0m       \u001b[35m0.7647\u001b[0m            \u001b[31m0.7647\u001b[0m        \u001b[94m9.0182\u001b[0m  0.0199  1.9648\n",
      "      3            0.5000        \u001b[32m0.1900\u001b[0m       0.4375            0.4375       24.6449  0.0197  2.1673\n",
      "      4            \u001b[36m0.7279\u001b[0m        \u001b[32m0.1308\u001b[0m       \u001b[35m0.8088\u001b[0m            \u001b[31m0.8088\u001b[0m       12.0055  0.0192  2.5244\n",
      "      5            0.5726        \u001b[32m0.0927\u001b[0m       0.4375            0.4375       19.8303  0.0187  3.2431\n",
      "      6            0.5000        \u001b[32m0.0907\u001b[0m       0.4375            0.4375       44.2493  0.0179  3.4342\n",
      "      7            \u001b[36m0.9770\u001b[0m        0.1889       \u001b[35m0.8125\u001b[0m            \u001b[31m0.8125\u001b[0m        \u001b[94m4.5083\u001b[0m  0.0171  3.4218\n",
      "      8            0.9191        0.1577       0.5735            0.5735        8.9936  0.0161  3.6806\n",
      "      9            0.5000        0.0946       0.4375            0.4375       15.6193  0.0150  3.4018\n",
      "     10            0.8649        0.1135       0.8125            0.8125        4.7197  0.0138  3.4343\n",
      "     11            0.6250        \u001b[32m0.0706\u001b[0m       0.5478            0.5478        8.9076  0.0126  3.5923\n",
      "     12            0.8456        0.0805       0.7500            0.7500        7.8009  0.0113  3.6725\n",
      "     13            \u001b[36m0.9954\u001b[0m        0.0817       0.7904            0.7904        8.4275  0.0100  3.5949\n",
      "     14            0.8906        \u001b[32m0.0472\u001b[0m       0.7500            0.7500        6.0850  0.0087  3.5655\n",
      "     15            0.6728        0.0639       0.7904            0.7904        6.4205  0.0074  3.4715\n",
      "     16            0.8456        0.0485       0.7500            0.7500        5.5645  0.0062  3.3888\n",
      "     17            0.6388        0.0530       0.5441            0.5441       10.8900  0.0050  3.5057\n",
      "     18            0.9191        0.0523       0.7537            0.7537        6.6117  0.0039  3.4727\n",
      "     19            0.9954        \u001b[32m0.0462\u001b[0m       0.7757            0.7757        6.6779  0.0029  3.3905\n",
      "     20            0.9954        0.0542       0.7868            0.7868        5.9170  0.0021  3.5241\n",
      "     21            0.9798        \u001b[32m0.0365\u001b[0m       0.7537            0.7537        5.8779  0.0013  3.4865\n",
      "     22            0.9724        0.0412       0.7463            0.7463        6.2177  0.0008  3.4267\n",
      "     23            0.9761        \u001b[32m0.0351\u001b[0m       0.7537            0.7537        6.3248  0.0003  3.5319\n",
      "     24            0.9871        0.0430       0.7537            0.7537        6.4651  0.0001  3.4566\n",
      "     25            0.9936        0.0503       0.7610            0.7610        6.6176  0.0000  3.3492\n",
      "Best Cross Validation Kappa Score: 0.62\n",
      "\n",
      " ######################### Training for Subject: 4 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m0.6628\u001b[0m       \u001b[35m0.5000\u001b[0m            \u001b[31m0.5000\u001b[0m        \u001b[94m7.2377\u001b[0m  0.0200  3.4389\n",
      "      2            0.5000        \u001b[32m0.3197\u001b[0m       0.5000            0.5000        \u001b[94m6.9299\u001b[0m  0.0199  3.5343\n",
      "      3            \u001b[36m0.5717\u001b[0m        \u001b[32m0.2307\u001b[0m       \u001b[35m0.7904\u001b[0m            \u001b[31m0.7904\u001b[0m        \u001b[94m1.2198\u001b[0m  0.0197  3.5774\n",
      "      4            0.5184        \u001b[32m0.1792\u001b[0m       0.6838            0.6838        1.3016  0.0192  3.7424\n",
      "      5            0.5074        \u001b[32m0.1526\u001b[0m       0.5257            0.5257        2.5461  0.0187  2.7098\n",
      "      6            0.5101        \u001b[32m0.1343\u001b[0m       0.5000            0.5000       11.2099  0.0179  2.2934\n",
      "      7            0.5083        \u001b[32m0.0933\u001b[0m       0.5000            0.5000        9.9122  0.0171  1.9877\n",
      "      8            0.5018        \u001b[32m0.0806\u001b[0m       0.5000            0.5000       12.2045  0.0161  1.7850\n",
      "      9            \u001b[36m0.8585\u001b[0m        \u001b[32m0.0805\u001b[0m       0.4926            0.4926        4.2553  0.0150  1.8469\n",
      "     10            0.6314        0.0967       0.4375            0.4375        7.3460  0.0138  2.0500\n",
      "     11            \u001b[36m0.9982\u001b[0m        \u001b[32m0.0432\u001b[0m       0.5294            0.5294        5.8848  0.0126  2.0708\n",
      "     12            0.9191        \u001b[32m0.0432\u001b[0m       \u001b[35m0.8125\u001b[0m            \u001b[31m0.8125\u001b[0m        2.9935  0.0113  2.0584\n",
      "     13            0.9982        0.0542       0.5662            0.5662        4.8895  0.0100  3.4558\n",
      "     14            0.8750        0.0598       0.4669            0.4669        5.4428  0.0087  3.5363\n",
      "     15            0.9494        0.0438       0.6066            0.6066        3.1939  0.0074  3.6045\n",
      "     16            0.9752        0.0635       0.6581            0.6581        3.2765  0.0062  3.5273\n",
      "     17            0.8686        \u001b[32m0.0335\u001b[0m       0.6875            0.6875        3.0001  0.0050  3.5854\n",
      "     18            0.9899        0.0345       0.6397            0.6397        3.5461  0.0039  3.5549\n",
      "     19            0.9972        \u001b[32m0.0252\u001b[0m       0.6250            0.6250        3.9135  0.0029  3.5371\n",
      "     20            \u001b[36m0.9991\u001b[0m        0.0302       0.5919            0.5919        4.4720  0.0021  3.6231\n",
      "     21            \u001b[36m1.0000\u001b[0m        \u001b[32m0.0188\u001b[0m       0.5588            0.5588        5.2605  0.0013  3.6756\n",
      "     22            1.0000        0.0198       0.5588            0.5588        5.2295  0.0008  3.6147\n",
      "     23            1.0000        0.0355       0.5588            0.5588        5.2370  0.0003  3.4860\n",
      "     24            1.0000        0.0322       0.5588            0.5588        5.3132  0.0001  3.3829\n",
      "     25            1.0000        0.0225       0.5588            0.5588        5.3534  0.0000  3.5906\n",
      "Best Cross Validation Kappa Score: 0.62\n",
      "\n",
      " ######################### Training for Subject: 5 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6691\u001b[0m        \u001b[32m0.6370\u001b[0m       \u001b[35m0.3787\u001b[0m            \u001b[31m0.3787\u001b[0m        \u001b[94m2.3687\u001b[0m  0.0200  3.6248\n",
      "      2            0.5000        \u001b[32m0.2839\u001b[0m       \u001b[35m0.5000\u001b[0m            \u001b[31m0.5000\u001b[0m        8.2444  0.0199  3.5353\n",
      "      3            0.6562        \u001b[32m0.2526\u001b[0m       \u001b[35m0.5625\u001b[0m            \u001b[31m0.5625\u001b[0m        2.7447  0.0197  3.4864\n",
      "      4            \u001b[36m0.9320\u001b[0m        \u001b[32m0.1822\u001b[0m       0.3934            0.3934        \u001b[94m2.2623\u001b[0m  0.0192  3.4401\n",
      "      5            0.9246        \u001b[32m0.1459\u001b[0m       0.4853            0.4853        2.6950  0.0187  3.3896\n",
      "      6            0.5579        \u001b[32m0.1327\u001b[0m       0.5000            0.5000        7.6570  0.0179  3.4617\n",
      "      7            0.8520        0.1370       0.4779            0.4779        3.7111  0.0171  3.5958\n",
      "      8            0.5055        \u001b[32m0.0954\u001b[0m       0.5625            0.5625        9.5829  0.0161  3.5547\n",
      "      9            0.5699        \u001b[32m0.0786\u001b[0m       0.5625            0.5625        5.6921  0.0150  3.5576\n",
      "     10            0.5450        0.0882       0.5625            0.5625        7.1873  0.0138  3.5981\n",
      "     11            0.5662        \u001b[32m0.0626\u001b[0m       0.5625            0.5625        6.6041  0.0126  3.5591\n",
      "     12            0.7629        \u001b[32m0.0602\u001b[0m       \u001b[35m0.5772\u001b[0m            \u001b[31m0.5772\u001b[0m        3.7837  0.0113  3.5473\n",
      "     13            0.7132        \u001b[32m0.0506\u001b[0m       0.5000            0.5000        6.1328  0.0100  3.4609\n",
      "     14            0.9026        0.0614       0.4890            0.4890        4.5668  0.0087  3.4231\n",
      "     15            \u001b[36m0.9936\u001b[0m        \u001b[32m0.0355\u001b[0m       0.4485            0.4485        3.1231  0.0074  3.4582\n",
      "     16            0.7849        0.0482       0.5368            0.5368        5.4578  0.0062  3.5500\n",
      "     17            0.9844        \u001b[32m0.0268\u001b[0m       0.4743            0.4743        3.4889  0.0050  3.4580\n",
      "     18            0.9899        0.0307       0.4669            0.4669        3.4533  0.0039  3.5409\n",
      "     19            \u001b[36m1.0000\u001b[0m        0.0286       0.4522            0.4522        3.0012  0.0029  3.6703\n",
      "     20            0.9816        \u001b[32m0.0250\u001b[0m       0.5000            0.5000        3.6970  0.0021  3.5718\n",
      "     21            0.9991        0.0343       0.4338            0.4338        2.6771  0.0013  3.5122\n",
      "     22            1.0000        \u001b[32m0.0180\u001b[0m       0.4632            0.4632        2.9053  0.0008  3.5540\n",
      "     23            1.0000        0.0184       0.4559            0.4559        2.8556  0.0003  3.7462\n",
      "     24            1.0000        0.0182       0.4485            0.4485        2.7768  0.0001  3.5716\n",
      "     25            1.0000        0.0285       0.4522            0.4522        2.7566  0.0000  3.5526\n",
      "Best Cross Validation Kappa Score: 0.15\n",
      "\n",
      " ######################### Training for Subject: 6 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m0.5094\u001b[0m       \u001b[35m0.5000\u001b[0m            \u001b[31m0.5000\u001b[0m        \u001b[94m4.8746\u001b[0m  0.0200  3.4367\n",
      "      2            0.5000        \u001b[32m0.1477\u001b[0m       \u001b[35m0.5625\u001b[0m            \u001b[31m0.5625\u001b[0m        5.2970  0.0199  3.3812\n",
      "      3            \u001b[36m0.8235\u001b[0m        \u001b[32m0.1214\u001b[0m       \u001b[35m0.7757\u001b[0m            \u001b[31m0.7757\u001b[0m        \u001b[94m1.2543\u001b[0m  0.0197  3.3885\n",
      "      4            0.5404        0.1342       0.6176            0.6176        3.0095  0.0192  3.3851\n",
      "      5            0.5294        \u001b[32m0.0850\u001b[0m       0.6287            0.6287        3.3142  0.0187  3.3738\n",
      "      6            \u001b[36m0.8897\u001b[0m        \u001b[32m0.0627\u001b[0m       \u001b[35m0.7794\u001b[0m            \u001b[31m0.7794\u001b[0m        \u001b[94m0.9553\u001b[0m  0.0179  3.4578\n",
      "      7            \u001b[36m0.9173\u001b[0m        0.0741       0.4559            0.4559        4.3959  0.0171  3.7646\n",
      "      8            0.6057        \u001b[32m0.0583\u001b[0m       0.4816            0.4816        8.2643  0.0161  3.6708\n",
      "      9            0.7188        \u001b[32m0.0292\u001b[0m       0.4779            0.4779        6.1035  0.0150  3.7099\n",
      "     10            \u001b[36m0.9991\u001b[0m        0.0376       0.4890            0.4890        3.0932  0.0138  3.6993\n",
      "     11            \u001b[36m1.0000\u001b[0m        0.0488       0.5110            0.5110        3.2224  0.0126  3.4158\n",
      "     12            0.6700        0.0494       0.4706            0.4706        7.3955  0.0113  3.4302\n",
      "     13            0.9669        \u001b[32m0.0237\u001b[0m       0.4853            0.4853        3.9016  0.0100  3.5157\n",
      "     14            1.0000        0.0363       0.5110            0.5110        2.9710  0.0087  3.5798\n",
      "     15            1.0000        \u001b[32m0.0212\u001b[0m       0.5478            0.5478        2.4290  0.0074  3.5369\n",
      "     16            0.9035        \u001b[32m0.0206\u001b[0m       0.4706            0.4706        5.2288  0.0062  3.5466\n",
      "     17            0.9991        \u001b[32m0.0075\u001b[0m       0.4890            0.4890        3.4367  0.0050  3.4932\n",
      "     18            1.0000        0.0177       0.6250            0.6250        1.9650  0.0039  3.4924\n",
      "     19            0.9697        0.0153       0.4669            0.4669        4.3690  0.0029  3.5166\n",
      "     20            1.0000        0.0170       0.5625            0.5625        2.4413  0.0021  3.5900\n",
      "     21            1.0000        0.0308       0.5588            0.5588        2.5771  0.0013  3.5009\n",
      "     22            1.0000        0.0190       0.6287            0.6287        1.9417  0.0008  3.5447\n",
      "     23            1.0000        0.0133       0.6324            0.6324        1.9307  0.0003  3.5228\n",
      "     24            1.0000        0.0119       0.6397            0.6397        1.9120  0.0001  3.4236\n",
      "     25            1.0000        0.0138       0.6397            0.6397        1.8873  0.0000  3.3892\n",
      "Best Cross Validation Kappa Score: 0.56\n",
      "\n",
      " ######################### Training for Subject: 7 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m0.6555\u001b[0m       \u001b[35m0.5000\u001b[0m            \u001b[31m0.5000\u001b[0m       \u001b[94m35.6561\u001b[0m  0.0200  3.4492\n",
      "      2            0.5000        \u001b[32m0.2266\u001b[0m       0.5000            0.5000       \u001b[94m19.0908\u001b[0m  0.0199  3.5268\n",
      "      3            0.5000        \u001b[32m0.1739\u001b[0m       \u001b[35m0.5625\u001b[0m            \u001b[31m0.5625\u001b[0m       \u001b[94m13.6724\u001b[0m  0.0197  3.5326\n",
      "      4            0.5000        \u001b[32m0.1604\u001b[0m       0.5625            0.5625       \u001b[94m11.2132\u001b[0m  0.0192  3.4939\n",
      "      5            \u001b[36m0.5101\u001b[0m        0.1739       0.5625            0.5625        \u001b[94m4.3676\u001b[0m  0.0187  3.4772\n",
      "      6            \u001b[36m0.5257\u001b[0m        \u001b[32m0.1291\u001b[0m       0.5551            0.5551        5.3601  0.0179  3.3606\n",
      "      7            \u001b[36m0.9108\u001b[0m        \u001b[32m0.1016\u001b[0m       \u001b[35m0.8235\u001b[0m            \u001b[31m0.8235\u001b[0m        \u001b[94m1.1728\u001b[0m  0.0171  3.3874\n",
      "      8            0.5726        0.1323       \u001b[35m0.8309\u001b[0m            \u001b[31m0.8309\u001b[0m        1.8300  0.0161  3.3932\n",
      "      9            0.5110        \u001b[32m0.0903\u001b[0m       0.7022            0.7022        2.7524  0.0150  3.5247\n",
      "     10            0.5000        0.0930       0.5000            0.5000       15.4661  0.0138  3.5564\n",
      "     11            0.5000        0.1020       0.5000            0.5000       25.3545  0.0126  3.3961\n",
      "     12            0.5000        \u001b[32m0.0595\u001b[0m       0.5000            0.5000       31.9956  0.0113  3.4104\n",
      "     13            0.5000        0.1020       0.5000            0.5000       26.2810  0.0100  3.3976\n",
      "     14            0.5000        0.0966       0.5000            0.5000       25.8451  0.0087  3.4249\n",
      "     15            0.5000        \u001b[32m0.0554\u001b[0m       0.5000            0.5000       29.2738  0.0074  3.4585\n",
      "     16            0.5000        0.0606       0.5000            0.5000       20.2026  0.0062  3.4122\n",
      "     17            0.5000        0.0558       0.5000            0.5000       24.2695  0.0050  3.4992\n",
      "     18            0.5000        0.0607       0.5000            0.5000       14.6518  0.0039  3.4743\n",
      "     19            0.5000        \u001b[32m0.0539\u001b[0m       0.5000            0.5000       15.0469  0.0029  3.4699\n",
      "     20            0.5000        \u001b[32m0.0474\u001b[0m       0.5000            0.5000       19.9717  0.0021  3.4509\n",
      "     21            0.5000        \u001b[32m0.0439\u001b[0m       0.5000            0.5000       20.6471  0.0013  3.4164\n",
      "     22            0.5000        \u001b[32m0.0295\u001b[0m       0.5000            0.5000       15.7359  0.0008  3.3545\n",
      "     23            0.5000        0.0311       0.5000            0.5000       12.9180  0.0003  3.4021\n",
      "     24            0.5000        \u001b[32m0.0281\u001b[0m       0.5000            0.5000        8.3149  0.0001  3.4072\n",
      "     25            0.5092        0.0353       0.6360            0.6360        5.0072  0.0000  3.4229\n",
      "Best Cross Validation Kappa Score: 0.66\n",
      "\n",
      " ######################### Training for Subject: 8 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5000\u001b[0m        \u001b[32m0.6780\u001b[0m       \u001b[35m0.5000\u001b[0m            \u001b[31m0.5000\u001b[0m        \u001b[94m4.8485\u001b[0m  0.0200  3.5837\n",
      "      2            \u001b[36m0.6305\u001b[0m        \u001b[32m0.3665\u001b[0m       0.4375            0.4375        6.2981  0.0199  3.5484\n",
      "      3            0.5000        \u001b[32m0.3303\u001b[0m       0.5000            0.5000        8.3599  0.0197  3.5347\n",
      "      4            0.5000        \u001b[32m0.2904\u001b[0m       0.5000            0.5000       12.6768  0.0192  3.4428\n",
      "      5            0.5000        \u001b[32m0.2369\u001b[0m       0.5000            0.5000       27.0288  0.0187  3.6615\n",
      "      6            0.5000        0.2976       0.5000            0.5000       22.8822  0.0179  3.5583\n",
      "      7            0.5000        \u001b[32m0.2181\u001b[0m       0.5000            0.5000       25.5851  0.0171  3.4429\n",
      "      8            0.5000        \u001b[32m0.1721\u001b[0m       0.5000            0.5000       13.6206  0.0161  3.5989\n",
      "      9            \u001b[36m0.8520\u001b[0m        0.2505       0.4596            0.4596        6.8054  0.0150  3.5375\n",
      "     10            0.5000        0.1775       0.5000            0.5000       21.5460  0.0138  3.5208\n",
      "     11            0.5000        \u001b[32m0.1319\u001b[0m       0.5000            0.5000       20.3631  0.0126  3.5007\n",
      "     12            0.5000        \u001b[32m0.1053\u001b[0m       0.5000            0.5000       11.8024  0.0113  3.4589\n",
      "     13            0.5000        \u001b[32m0.0917\u001b[0m       0.5000            0.5000       22.6364  0.0100  3.4124\n",
      "     14            0.5000        \u001b[32m0.0745\u001b[0m       0.5000            0.5000       29.7421  0.0087  3.3957\n",
      "     15            0.5487        0.0763       \u001b[35m0.8897\u001b[0m            \u001b[31m0.8897\u001b[0m        7.0890  0.0074  3.5080\n",
      "     16            0.5000        \u001b[32m0.0717\u001b[0m       0.5000            0.5000       19.7117  0.0062  3.4044\n",
      "     17            0.5000        0.0834       0.5000            0.5000       14.6557  0.0050  3.4192\n",
      "     18            0.5000        \u001b[32m0.0601\u001b[0m       0.5809            0.5809        9.4948  0.0039  3.4348\n",
      "     19            0.5000        \u001b[32m0.0587\u001b[0m       0.5993            0.5993        9.3466  0.0029  3.4558\n",
      "     20            0.5000        \u001b[32m0.0431\u001b[0m       0.5000            0.5000       12.9275  0.0021  3.3747\n",
      "     21            0.5202        0.0522       0.7243            0.7243        8.4317  0.0013  3.3877\n",
      "     22            0.5000        0.0552       0.6029            0.6029        9.6585  0.0008  3.4916\n",
      "     23            0.7325        \u001b[32m0.0373\u001b[0m       0.8640            0.8640        7.5164  0.0003  3.4552\n",
      "     24            0.8097        0.0398       0.8493            0.8493        7.5894  0.0001  3.4674\n",
      "     25            \u001b[36m0.9164\u001b[0m        0.0484       0.8309            0.8309        7.7111  0.0000  3.4651\n",
      "Best Cross Validation Kappa Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "for subject_index in range(len(training_files)):\n",
    "    training_function(subject_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
